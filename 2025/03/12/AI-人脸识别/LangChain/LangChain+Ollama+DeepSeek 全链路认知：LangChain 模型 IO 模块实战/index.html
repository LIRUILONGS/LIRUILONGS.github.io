<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="google-adsense-account" content="ca-pub-5805170532312625"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>LangChain+Ollama+DeepSeek 全链路认知：LangChain 模型 IO 模块实战 - 山河已无恙</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="山河已无恙"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="山河已无恙"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="我看远山，远山悲悯"><meta property="og:type" content="blog"><meta property="og:title" content="山河已无恙"><meta property="og:url" content="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd"><meta property="og:site_name" content="山河已无恙"><meta property="og:description" content="我看远山，远山悲悯"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mp.weixin.qq.com/img/头像.jpg"><meta property="article:published_time" content="2025-03-12T02:52:50.000Z"><meta property="article:modified_time" content="2025-03-21T04:57:51.712Z"><meta property="article:author" content="LIRUILONGS"><meta property="article:tag" content="LLM"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/头像.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://liruilongs.github.io/2025/03/12/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain+Ollama+DeepSeek%20%E5%85%A8%E9%93%BE%E8%B7%AF%E8%AE%A4%E7%9F%A5%EF%BC%9ALangChain%20%E6%A8%A1%E5%9E%8B%20IO%20%E6%A8%A1%E5%9D%97%E5%AE%9E%E6%88%98/"},"headline":"山河已无恙","image":["https://liruilongs.github.io/img/og_image.png"],"datePublished":"2025-03-12T02:52:50.000Z","dateModified":"2025-03-21T04:57:51.712Z","author":{"@type":"Person","name":"山河已无恙"},"description":"我看远山，远山悲悯"}</script><link rel="canonical" href="https://liruilongs.github.io/2025/03/12/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain+Ollama+DeepSeek%20%E5%85%A8%E9%93%BE%E8%B7%AF%E8%AE%A4%E7%9F%A5%EF%BC%9ALangChain%20%E6%A8%A1%E5%9E%8B%20IO%20%E6%A8%A1%E5%9D%97%E5%AE%9E%E6%88%98/"><link rel="alternate" href="/path/to/atom.xml" title="山河已无恙" type="application/atom+xml"><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?3f06f2b732a5b1034c989f74e28d0eea";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">影音</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/self-talking">生活小记</a><a class="navbar-item" href="/message">留言墙</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/liruilonger"><i class="fab fa-git-square fa-1x"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/LIRUILONGS"><i class="fab fa-github fa-1x"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul fa-1x"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search fa-1x"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon fa-1x" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2025-03-12  <a class="commentCountImg" href="/2025/03/12/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain+Ollama+DeepSeek%20%E5%85%A8%E9%93%BE%E8%B7%AF%E8%AE%A4%E7%9F%A5%EF%BC%9ALangChain%20%E6%A8%A1%E5%9E%8B%20IO%20%E6%A8%A1%E5%9D%97%E5%AE%9E%E6%88%98/#comment-container"><span class="display-none-class">b2667027df19e00fd8417e25df5a43ac</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="b2667027df19e00fd8417e25df5a43ac">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>31 分钟  <i class="fas fa-pencil-alt"> </i>4.7 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">LangChain+Ollama+DeepSeek 全链路认知：LangChain 模型 IO 模块实战</h1><div class="content"><p><strong><font color="009688"> 我看远山，远山悲悯</strong></font></p>
<span id="more"></span>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><hr>
<ul>
<li>博文内容涉及 LangChain 模型IO 模块认知</li>
<li>以及 <code>模型包装器，提示词模版，输出解析器</code>认知以及Demo</li>
<li>理解不足小伙伴帮忙指正 :),生活加油</li>
</ul>
<p><strong><font color="009688"> 我看远山，远山悲悯</strong></font></p>
<p>持续分享技术干货，感兴趣小伙伴可以关注下 ^_^</p>
<hr>
<h1 id="Lang-Chain-模块认知-模型-IO"><a href="#Lang-Chain-模块认知-模型-IO" class="headerlink" title="Lang Chain 模块认知 模型 IO"></a>Lang Chain 模块认知 模型 IO</h1><p><code>Lang Chain</code> 是在 <code>LLM</code> 爆发之后，最早有一定知名度的开源工具，其他生态大部分工具也都基于 <code>Lang Chain</code> 的架构方式，所以通过学习 <code>Lang Chain</code> 可以了解 大部分的 AI 应用工具，今天和小伙伴分享 <code>Lang Chain</code> 模块中的 <code>模型 IO</code></p>
<p>模型 I&#x2F;O 模块作为 <code>LangChain</code> 框架的核心组件，通过封装 50 余种大语言模型的 API 接口，构建了跨平台的统一交互范式。</p>
<p>其核心设计目标在于屏蔽底层 API 差异（如 OpenAI 的文本补全接口与智谱清言的聊天式接口差异），使开发者仅需通过标准化的 LLM 和 ChatModel 包装器类即可调用各类模型。</p>
<p>这种抽象机制不仅支持云端最新模型（如 GPT-4、DeepSeek-R1）的无缝接入，还能快速集成本地部署的开源模型（通过 Ollama 加载）或 HuggingFace 社区模型，开发者仅需调整初始化参数即可完成模型切换，无需重写业务逻辑代码。</p>
<p>通过 <code>PromptTemplate</code> 标准化输入格式、<code>OutputParser</code> 结构化输出结果，该模块将复杂的 <code>API</code> 调用协议简化为 3-5 行代码即可完成的标准化流程，真正实现了”<code>一次编码，多模型适配</code>“的开发体验</p>
<p><code>模型IO</code> 的核心功能：</p>
<ul>
<li><code>模型包装器</code>:通过接口调用大语言模型</li>
<li><code>提示词模板管理</code>:将输入进行模板化，并动态地选择和管理这些模板</li>
<li><code>输出解析器</code>:从模型输出中提取信息</li>
</ul>
<p>下面我们依次看一下这三块内容</p>
<h2 id="模型包装器"><a href="#模型包装器" class="headerlink" title="模型包装器"></a>模型包装器</h2><p>模型包装器分类：</p>
<ul>
<li><code>LLM 模型包装器</code>: 通用的 <code>LLM</code> 模型包装器（返回值为 串）<code>from langchain_community.llms import Ollama</code></li>
<li><code>聊天模型包装器</code>: 专门针对聊天类型API的聊天模型(聊天模型包装器)(返回值为 <code>AIMesssage</code>)<code>from langchain_community.chat_models import ChatOllama</code></li>
</ul>
<p>分别来看一下</p>
<h3 id="LLM-模型包装器"><a href="#LLM-模型包装器" class="headerlink" title="LLM 模型包装器"></a>LLM 模型包装器</h3><p><strong>LLM模型包装器</strong></p>
<p>通过 <code>langchain_community.llms</code> 获取的模型包装器（如 OpenAI 等）均为 BaseLLM 的子类，它们通过继承统一基类的方法与属性，实现了对50余种大语言模型（如 OpenAI 的 text-davinci-003、Llama.cpp 本地模型）API 的标准化封装。</p>
<p>开发者仅需调用 <code>invoke</code> 或 <code>generate</code> 方法即可完成文本补全、代码生成等任务，无需关注底层 API 的差异化调用协议（如 OpenAI 的文本补全接口与智谱清言的聊天式接口差异）。此类包装器尤其适用于自由文本生成场景（如文案创作、代码续写），并通过 PromptTemplate 实现输入模板化，显著降低多模型切换的代码改造成本。</p>
<p>下面为一个  LLM 模型包装器的Demo</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@File    :   demo.py</span></span><br><span class="line"><span class="string">@Time    :   2025/03/09 01:13:15</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   liruilonger@gmail.com</span></span><br><span class="line"><span class="string">@Desc    :   LangChain Demo</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="comment">#pip install langchain langchain-community ollama -i https://pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单次对话</span></span><br><span class="line">response = llm.invoke(<span class="string">&quot;LLM 是什么？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;回答：&quot;</span>, response)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===========================================================&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式输出（适合长文本）</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;LLM 如何学习？&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="聊天模型包装器"><a href="#聊天模型包装器" class="headerlink" title="聊天模型包装器"></a>聊天模型包装器</h3><p><strong>聊天模型包装器</strong></p>
<p><code>langchain_community.chat_models</code> 提供的聊天模型包装器（如 <code>ChatOpenAI、ChatAnthropic</code>）专为多轮对话场景设计，通过结构化消息类型（<code>SystemMessage、HumanMessage、AIMessage</code>）实现对话状态管理。</p>
<p>此类包装器适配 <code>GPT-4、DeepSeek-R1</code> 等先进模型的 Chat 类型 API，支持以消息列表作为输入（例如系统角色设定+用户提问），并返回 <code>AIMessage</code> 类型的结构化响应。</p>
<p>其核心优势在于<code>简化复杂对话逻辑的开发流程</code>，例如客服机器人需维护的上下文记忆（Memory 模块）与多轮意图理解，开发者可通过 <code>LLMChain</code> 将聊天模型与提示词模板、输出解析器无缝串联，实现“对话即代码”的高效开发范式</p>
<p>聊天模型包装器Demo</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@File    :   demo_prompt.py</span></span><br><span class="line"><span class="string">@Time    :   2025/03/09 04:06:14</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   liruilonger@gmail.com</span></span><br><span class="line"><span class="string">@Desc    :   None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 配置本地模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;deepseek-r1:latest&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一位唐诗研究专家，用中文回答时保持古典韵味&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;请赏析&#123;poem_title&#125;的意境&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;好的，我将从以下三个方面分析：\n1. 意象运用\n2. 情感表达\n3. 历史背景&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">messages = chat_template.format_messages(</span><br><span class="line">    poem_title=<span class="string">&quot;《登鹳雀楼》&quot;</span>,</span><br><span class="line">    user_question=<span class="string">&quot;诗中&#x27;更上一层楼&#x27;有何哲学深意？&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> messages:</span><br><span class="line">    <span class="built_in">print</span>(chat_model.invoke(messages))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="提示词模板"><a href="#提示词模板" class="headerlink" title="提示词模板"></a>提示词模板</h2><p><code>提示词模板（PromptTemplate）</code>是AI交互中的结构化生成工具，其本质是<code>通过预定义模板字符串（含占位符）动态生成适配场景的提示词</code>。</p>
<p>例如，使用<code>&#123;变量&#125;</code>占位符可将<code>用户输入、任务指令、示例数据</code>等元素动态注入模板，实现<code>“一次设计，多次复用”</code>的工程化开发模式,其核心价值在于将复杂提示逻辑抽象为标准化的代码组件，开发者可通过调整输入变量（如<code>input_variables=[&quot;style&quot;,&quot;topic&quot;]</code>）快速切换任务场景，无需重写底层逻辑。</p>
<p><code>提示词模板</code>的<code>三层结构化设计</code></p>
<p><strong>​指令层（Instruction Layer）​</strong></p>
<p><code>明确的指令定义任务目标与执行规则</code>，例如 “你是一名数据科学家，请用时间序列模型预测销售额”即为典型指令。此类指令通过<code>角色设定</code>（role）、<code>任务说明</code>（task）和<code>格式约束</code>（如“输出表格”），<code>强制对齐模型输出与业务需求</code>。</p>
<p><strong>​示例层（Few-shot Layer）</strong></p>
<p><code>少量示例（Few-shot Learning）可显著提升模型理解能力</code>。例如通过投喂<code>“SPD项目需求描述+预期输出框架”</code>的示例对，引导模型生成符合行业规范的方案。这种<code>“输入-输出”</code>示例对可视为模板中的<code>静态知识库</code>，用于激活模型的<code>类比推理能力</code>。</p>
<p><strong>​动态输入层（Dynamic Input Layer）</strong></p>
<p>用户输入变量（如topic&#x3D;”人工智能”）作为模板的动态参数，决定生成内容的细粒度。比如 <code>社团活动策划案例</code>中，“预算限制”“目标人群”等变量被注入模板，使AI输出的策划案兼具通用框架与个性化细节。支持链式调用，例如通过<code>LLMChain</code>串联多个模板实现多轮对话。</p>
<p>从技术实现看，提示词模板常封装为可复用类，其核心方法包括：</p>
<ul>
<li><code>变量声明</code>：通过<code>input_variables</code>定义占位符参数类型；</li>
<li><code>模板加载</code>：支持从外部文件读取模板，实现代码与内容分离；</li>
<li><code>格式控制</code>：强制输出结构化内容（如Markdown表格、JSON），降低后续数据解析成本</li>
</ul>
<p>下面我们看一些常见的模版</p>
<h3 id="基础提示模板-PromptTemplate"><a href="#基础提示模板-PromptTemplate" class="headerlink" title="基础提示模板 (PromptTemplate)"></a><strong>基础提示模板 (PromptTemplate)</strong></h3><p>单变量，多变量带格式控制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@File    :   demo_prompt.py</span></span><br><span class="line"><span class="string">@Time    :   2025/03/09 04:06:14</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   liruilonger@gmail.com</span></span><br><span class="line"><span class="string">@Desc    :   None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单变量模板</span></span><br><span class="line">simple_template = <span class="string">&quot;&quot;&quot;你是一个资深&#123;role&#125;，请用中文回答：</span></span><br><span class="line"><span class="string">问题：&#123;question&#125;</span></span><br><span class="line"><span class="string">答案：&quot;&quot;&quot;</span></span><br><span class="line">prompt = PromptTemplate.from_template(simple_template)</span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(role=<span class="string">&quot;算法工程师&quot;</span>, question=<span class="string">&quot;如何优化快速排序？&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chain =  llm</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(prompt.<span class="built_in">format</span>(role=<span class="string">&quot;算法工程师&quot;</span>, question=<span class="string">&quot;如何优化快速排序？&quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多变量带格式控制</span></span><br><span class="line">advanced_template = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;language&quot;</span>, <span class="string">&quot;task&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    请用&#123;language&#125;编写一个&#123;task&#125;的代码示例，</span></span><br><span class="line"><span class="string">    要求包含详细的注释和异常处理。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(advanced_template.<span class="built_in">format</span>(language=<span class="string">&quot;Python&quot;</span>, task=<span class="string">&quot;文件读写操作&quot;</span>)))</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="少量示例模板-FewShotPromptTemplate"><a href="#少量示例模板-FewShotPromptTemplate" class="headerlink" title="少量示例模板 (FewShotPromptTemplate)"></a><strong>少量示例模板 (FewShotPromptTemplate)</strong></h3><p>顾名思义，在推理前提供几个推理Demo，我们在最开始也讲到这种提示模版</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据集</span></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;高兴&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;笑容如春风拂面，眼中闪烁着星辰般的光芒&quot;</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;悲伤&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;眼角低垂似凋零的花瓣，双肩微微颤动如秋叶飘零&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个示例模板</span></span><br><span class="line">example_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输入情感：&#123;input&#125;</span></span><br><span class="line"><span class="string">文学化描述：&#123;output&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建完整模板</span></span><br><span class="line">few_shot_prompt = FewShotPromptTemplate(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=PromptTemplate(</span><br><span class="line">        input_variables=[<span class="string">&quot;input&quot;</span>, <span class="string">&quot;output&quot;</span>], </span><br><span class="line">        template=example_template</span><br><span class="line">    ),</span><br><span class="line">    suffix=<span class="string">&quot;请将以下情感转化为文学描述：\n情感：&#123;input&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(llm.invoke(few_shot_prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;愤怒&quot;</span>)))</span><br></pre></td></tr></table></figure>

<h3 id="聊天提示模板-ChatPromptTemplate"><a href="#聊天提示模板-ChatPromptTemplate" class="headerlink" title="聊天提示模板 (ChatPromptTemplate)"></a><strong>聊天提示模板 (ChatPromptTemplate)</strong></h3><p>聊天提示模版，<code>ChatPromptTemplate</code> 能整合不同角色的消息（系统、用户、AI），形成连贯的对话上下文</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@File    :   demo_prompt.py</span></span><br><span class="line"><span class="string">@Time    :   2025/03/09 04:06:14</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   liruilonger@gmail.com</span></span><br><span class="line"><span class="string">@Desc    :   None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 配置本地模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;deepseek-r1:latest&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一位唐诗研究专家，用中文回答时保持古典韵味&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;请赏析&#123;poem_title&#125;的意境&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;好的，我将从以下三个方面分析：\n1. 意象运用\n2. 情感表达\n3. 历史背景&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">messages = chat_template.format_messages(</span><br><span class="line">    poem_title=<span class="string">&quot;《登鹳雀楼》&quot;</span>,</span><br><span class="line">    user_question=<span class="string">&quot;诗中&#x27;更上一层楼&#x27;有何哲学深意？&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> messages:</span><br><span class="line">    <span class="built_in">print</span>(chat_model.invoke(messages))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="组合模板-PipelinePromptTemplate"><a href="#组合模板-PipelinePromptTemplate" class="headerlink" title="组合模板 (PipelinePromptTemplate)"></a><strong>组合模板 (PipelinePromptTemplate)</strong></h3><p>PipelinePromptTemplate 是 LangChain 框架中用于组合复杂提示词流程的核心工具，特别适用于需要分阶段处理或多模块协作的场景。以下是其核心特性与用法详解</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@File    :   demo_prompt.py</span></span><br><span class="line"><span class="string">@Time    :   2025/03/09 04:06:14</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   liruilonger@gmail.com</span></span><br><span class="line"><span class="string">@Desc    :   None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span>  PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PipelinePromptTemplate</span><br><span class="line"><span class="comment"># 初始化 Ollama 连接</span></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础模板</span></span><br><span class="line">base_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;concept&#125;（&#123;year&#125;年提出）的核心思想是：</span></span><br><span class="line"><span class="string">&#123;summary&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 详细说明模板</span></span><br><span class="line">detail_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">请用中文分点说明&#123;concept&#125;：</span></span><br><span class="line"><span class="string">1. 基本定义</span></span><br><span class="line"><span class="string">2. 主要应用场景</span></span><br><span class="line"><span class="string">3. 最新发展（截至&#123;year&#125;）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">combined_prompt = PipelinePromptTemplate(</span><br><span class="line">    final_prompt=PromptTemplate.from_template(base_template),</span><br><span class="line">    pipeline_prompts=[</span><br><span class="line">        (<span class="string">&quot;summary&quot;</span>, PromptTemplate.from_template(detail_template))</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(llm.invoke(combined_prompt.<span class="built_in">format</span>(</span><br><span class="line">    concept=<span class="string">&quot;注意力机制&quot;</span>, </span><br><span class="line">    year=<span class="number">2023</span></span><br><span class="line">)))</span><br></pre></td></tr></table></figure>

<h3 id="自定义模板-Custom-Template"><a href="#自定义模板-Custom-Template" class="headerlink" title="自定义模板 (Custom Template)"></a><strong>自定义模板 (Custom Template)</strong></h3><p>通过继承StringPromptTemplate 实习动态模版参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> StringPromptTemplate</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CodePrompt</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    language: <span class="built_in">str</span></span><br><span class="line">    framework: <span class="built_in">str</span> = <span class="string">&quot;无框架&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CodeTemplate</span>(<span class="params">StringPromptTemplate</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">format</span>(<span class="params">self, **kwargs</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        # 代码生成助手</span></span><br><span class="line"><span class="string">        语言：<span class="subst">&#123;kwargs[<span class="string">&#x27;language&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">        框架：<span class="subst">&#123;kwargs.get(<span class="string">&#x27;framework&#x27;</span>, <span class="string">&#x27;标准库&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">        功能需求：<span class="subst">&#123;kwargs[<span class="string">&#x27;requirement&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">        附加要求：<span class="subst">&#123;kwargs.get(<span class="string">&#x27;constraint&#x27;</span>, <span class="string">&#x27;无&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> prompt.replace(<span class="string">&quot;        &quot;</span>, <span class="string">&quot;&quot;</span>)  <span class="comment"># 清理缩进</span></span><br><span class="line"></span><br><span class="line">template = CodeTemplate(input_variables=[<span class="string">&quot;language&quot;</span>, <span class="string">&quot;framework&quot;</span>, <span class="string">&quot;requirement&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(template.<span class="built_in">format</span>(</span><br><span class="line">    language=<span class="string">&quot;Python&quot;</span>,</span><br><span class="line">    framework=<span class="string">&quot;FastAPI&quot;</span>,</span><br><span class="line">    requirement=<span class="string">&quot;创建文件上传接口&quot;</span>,</span><br><span class="line">    constraint=<span class="string">&quot;限制文件大小为10MB&quot;</span></span><br><span class="line">))</span><br></pre></td></tr></table></figure>

<h3 id="文件加载模板-load-prompt"><a href="#文件加载模板-load-prompt" class="headerlink" title="文件加载模板 (load_prompt)"></a><strong>文件加载模板 (load_prompt)</strong></h3><p>类似运维剧本中的 模版文件，熟悉 Ansible 的小伙伴对这个应该不陌生</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建模板文件 prompt.yaml</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">_type: prompt</span></span><br><span class="line"><span class="string">input_variables: [&quot;country&quot;]</span></span><br><span class="line"><span class="string">template: </span></span><br><span class="line"><span class="string">  请用中文介绍&#123;country&#125;的：</span></span><br><span class="line"><span class="string">  1. 历史沿革</span></span><br><span class="line"><span class="string">  2. 文化特色</span></span><br><span class="line"><span class="string">  3. 现代发展</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> load_prompt</span><br><span class="line"></span><br><span class="line">loaded_prompt = load_prompt(<span class="string">&quot;prompt.yaml&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(loaded_prompt.<span class="built_in">format</span>(country=<span class="string">&quot;意大利&quot;</span>))</span><br></pre></td></tr></table></figure>



<p><strong>模板选择参考</strong></p>
<table>
<thead>
<tr>
<th>模板类型</th>
<th>适用场景</th>
<th>优势</th>
</tr>
</thead>
<tbody><tr>
<td><code>PromptTemplate</code></td>
<td>简单问答、代码生成</td>
<td>快速构建基础提示</td>
</tr>
<tr>
<td><code>ChatPromptTemplate</code></td>
<td>对话系统</td>
<td>支持多角色消息</td>
</tr>
<tr>
<td><code>FewShotPromptTemplate</code></td>
<td>需要示例引导的任务</td>
<td>提升模型输出一致性</td>
</tr>
<tr>
<td><code>PipelinePromptTemplate</code></td>
<td>复杂逻辑分解</td>
<td>实现提示的模块化组合</td>
</tr>
<tr>
<td>自定义模板</td>
<td>特殊格式要求</td>
<td>完全控制提示结构</td>
</tr>
</tbody></table>
<hr>
<p>通过组合这些模板，可以构建适应各种复杂场景的提示工程系统。建议根据具体任务复杂度选择适当模板，必要时结合 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/expression_language/">LangChain Expression Language</a> 构建工作流。</p>
<h2 id="输出解析器"><a href="#输出解析器" class="headerlink" title="输出解析器"></a>输出解析器</h2><p>输出解析器，顾名思义将模型生成的输出格式<code>转化为可以在代码中直接使用的格式</code>。对于这个问题，通常使用LangChain 的输出解析器(OutputParsers)工具来解决</p>
<p>使用 LangChain 输出解析器（Output Parsers）的常见场景 Demo 示例，涵盖结构化数据、JSON、列表等格式的自动转换：</p>
<h3 id="基础解析器：Pydantic-模型结构化输出"><a href="#基础解析器：Pydantic-模型结构化输出" class="headerlink" title="基础解析器：Pydantic 模型结构化输出"></a>基础解析器：Pydantic 模型结构化输出</h3><p>将 LLM 输出转换为符合预定义结构的 Python 对象  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.pydantic_v1 <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> PydanticOutputParser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义数据结构模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Book</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    title: <span class="built_in">str</span> = Field(description=<span class="string">&quot;书名&quot;</span>)</span><br><span class="line">    author: <span class="built_in">str</span> = Field(description=<span class="string">&quot;作者&quot;</span>)</span><br><span class="line">    year: <span class="built_in">int</span> = Field(description=<span class="string">&quot;出版年份&quot;</span>)</span><br><span class="line">    genres: <span class="built_in">list</span>[<span class="built_in">str</span>] = Field(description=<span class="string">&quot;书籍分类&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建解析器</span></span><br><span class="line">parser = PydanticOutputParser(pydantic_object=Book)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 自动生成格式指令（注入提示词）</span></span><br><span class="line">format_instructions = parser.get_format_instructions()</span><br><span class="line"><span class="built_in">print</span>(format_instructions)</span><br><span class="line"><span class="comment"># 输出示例：</span></span><br><span class="line"><span class="comment"># &quot;请用以下JSON格式输出...属性包括 title, author, year, genres...&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 组合提示词模板</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;请根据描述生成书籍信息：&#123;query&#125;\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;query&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 调用模型并解析</span></span><br><span class="line">chain = prompt | llm | parser</span><br><span class="line">result = chain.invoke(&#123;<span class="string">&quot;query&quot;</span>: <span class="string">&quot;鲁迅的第一本小说集&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result))  <span class="comment"># &lt;class &#x27;__main__.Book&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(result.title)  <span class="comment"># 《呐喊》</span></span><br></pre></td></tr></table></figure>

<h3 id="JSON-格式解析器"><a href="#JSON-格式解析器" class="headerlink" title="JSON 格式解析器"></a>JSON 格式解析器</h3><p>直接解析模型返回的 JSON 字符串为 Python 字典  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义解析器</span></span><br><span class="line">parser = JsonOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 提示词模板（自动包含JSON格式要求）</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;生成包含姓名、年龄和兴趣的用户信息：&#123;input&#125;\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: parser.get_format_instructions()&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 调用并解析,通过表达式的方式</span></span><br><span class="line">chain = prompt | llm | parser</span><br><span class="line">data = chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;一个热爱AI的00后开发者&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"><span class="comment"># 输出示例：</span></span><br><span class="line"><span class="comment"># &#123;&#x27;name&#x27;: &#x27;张晓明&#x27;, &#x27;age&#x27;: 24, &#x27;interests&#x27;: [&#x27;人工智能&#x27;, &#x27;编程&#x27;]&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="列表解析器"><a href="#列表解析器" class="headerlink" title="列表解析器"></a>列表解析器</h3><p>将模型输出的无序文本转换为有序列表  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> CommaSeparatedListOutputParser</span><br><span class="line"></span><br><span class="line">parser = CommaSeparatedListOutputParser()</span><br><span class="line">format_instructions = parser.get_format_instructions()  <span class="comment"># &quot;用逗号分隔的列表&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;列举5个&#123;theme&#125;相关的关键技术：\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;theme&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = prompt | llm | parser</span><br><span class="line">tech_list = chain.invoke(&#123;<span class="string">&quot;theme&quot;</span>: <span class="string">&quot;自动驾驶&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(tech_list)</span><br><span class="line"><span class="comment"># 输出示例：</span></span><br><span class="line"><span class="comment"># [&#x27;激光雷达&#x27;, &#x27;计算机视觉&#x27;, &#x27;高精地图&#x27;, &#x27;路径规划&#x27;, &#x27;V2X通信&#x27;]</span></span><br></pre></td></tr></table></figure>

<h3 id="结构化文本解析器"><a href="#结构化文本解析器" class="headerlink" title="结构化文本解析器"></a>结构化文本解析器</h3><p>提取文本中的关键字段（类似键值对）  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StructuredOutputParser, ResponseSchema</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义响应字段</span></span><br><span class="line">response_schemas = [</span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;company&quot;</span>, description=<span class="string">&quot;公司名称&quot;</span>),</span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;industry&quot;</span>, description=<span class="string">&quot;所属行业&quot;</span>),</span><br><span class="line">    ResponseSchema(name=<span class="string">&quot;revenue&quot;</span>, description=<span class="string">&quot;年营收（单位：亿元）&quot;</span>, <span class="built_in">type</span>=<span class="string">&quot;float&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建解析器</span></span><br><span class="line">parser = StructuredOutputParser.from_response_schemas(response_schemas)</span><br><span class="line">format_instructions = parser.get_format_instructions()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 组合提示词</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;分析以下企业：&#123;text&#125;\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 执行解析</span></span><br><span class="line">chain = prompt | llm | parser</span><br><span class="line">output = chain.invoke(&#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;华为2023年营收超过7000亿元&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># &#123;&#x27;company&#x27;: &#x27;华为&#x27;, &#x27;industry&#x27;: &#x27;信息与通信技术&#x27;, &#x27;revenue&#x27;: 7000.0&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="日期时间解析器"><a href="#日期时间解析器" class="headerlink" title="日期时间解析器"></a>日期时间解析器</h3><p>自动解析文本中的日期时间  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> DatetimeOutputParser</span><br><span class="line"></span><br><span class="line">parser = DatetimeOutputParser()</span><br><span class="line">format_instructions = parser.get_format_instructions()  <span class="comment"># 要求输出ISO 8601格式</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;将以下日期转换为标准格式：&#123;date&#125;\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;date&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: format_instructions&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line">llm = Ollama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,  <span class="comment"># Ollama 默认端口</span></span><br><span class="line">    model=<span class="string">&quot;deepseek-r1:latest&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.3</span>,     <span class="comment"># 控制创造性（0-1）</span></span><br><span class="line">    num_ctx=<span class="number">4096</span>         <span class="comment"># 上下文长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = prompt | llm | parser</span><br><span class="line">result = chain.invoke(&#123;<span class="string">&quot;date&quot;</span>: <span class="string">&quot;明年端午节&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(result.strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>))  <span class="comment"># 2025-05-31（假设当前是2024年）</span></span><br></pre></td></tr></table></figure>

<h3 id="自动重试解析器"><a href="#自动重试解析器" class="headerlink" title="自动重试解析器"></a>自动重试解析器</h3><p>当解析失败时自动重试  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> RetryOutputParser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 包裹基础解析器（以JSON为例）</span></span><br><span class="line">base_parser = JsonOutputParser()</span><br><span class="line">parser = RetryOutputParser.from_llm(parser=base_parser, llm=llm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例（当第一次解析失败时自动调整提示）</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    data = parser.parse(<span class="string">&quot;非标准回答：&#123;name: &#x27;AI助手&#x27;&#125;&quot;</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="comment"># 自动触发重试逻辑</span></span><br><span class="line">    fixed_data = parser.parse_with_prompt(<span class="string">&quot;...&quot;</span>, original_prompt)</span><br></pre></td></tr></table></figure>

<p>通过组合不同的输出解析器，可以轻松实现从自由文本到程序可消费数据结构的无缝衔接。具体选择取决于业务场景是否需要强结构（Pydantic）、弱结构（JSON）或简单列表等格式。</p>
<h2 id="博文部分内容参考"><a href="#博文部分内容参考" class="headerlink" title="博文部分内容参考"></a>博文部分内容参考</h2><p>© 文中涉及参考链接内容版权归原作者所有，如有侵权请告知 :)</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/">https://python.langchain.com/docs/</a></p>
<p>《LangChain 入门指南构建高可复用、可扩展的 LLM 应用程序》</p>
<hr>
<p>© 2018-至今 <a href="mailto:&#108;&#x69;&#x72;&#x75;&#105;&#x6c;&#111;&#x6e;&#x67;&#101;&#114;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#99;&#111;&#x6d;">&#108;&#x69;&#x72;&#x75;&#105;&#x6c;&#111;&#x6e;&#x67;&#101;&#114;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#99;&#111;&#x6d;</a>, 保持署名-非商用-相同方式共享(CC BY-NC-SA 4.0)</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>LangChain+Ollama+DeepSeek 全链路认知：LangChain 模型 IO 模块实战</p><p><a href="https://liruilongs.github.io/2025/03/12/AI-人脸识别/LangChain/LangChain+Ollama+DeepSeek 全链路认知：LangChain 模型 IO 模块实战/">https://liruilongs.github.io/2025/03/12/AI-人脸识别/LangChain/LangChain+Ollama+DeepSeek 全链路认知：LangChain 模型 IO 模块实战/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://liruilongs.github.io"><p>山河已无恙</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-03-12</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-03-21</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2025/04/13/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%B0%B7%E6%AD%8C68%E9%A1%B5%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E5%AF%86%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%A6%82%E4%BD%95%E9%87%8D%E5%A1%91AI%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91/" target="_blank">谷歌68页白皮书解密：提示工程如何重塑AI交互逻辑</a><br></span><span>  2.<a class="is-size-6" href="/2025/03/26/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%A8%A1%E5%9D%97-Ollama-DeepSeek-R1-%E6%9E%84%E5%BB%BA-K8s-%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93Demo/" target="_blank">本地化智能运维助手：基于 LangChain 数据增强 和 DeepSeek-R1 的K8s运维文档检索与问答系统 Demo</a><br></span><span>  3.<a class="is-size-6" href="/2025/03/10/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain-Ollama-DeepSeek-%E5%85%A8%E9%93%BE%E8%B7%AF%E8%AE%A4%E7%9F%A5%EF%BC%9A%E4%BB%8E%E6%A8%A1%E5%9E%8B%E5%8C%85%E8%A3%85%E5%99%A8%E5%88%B0%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E7%89%88-Agent-Demo/" target="_blank">LangChain + Ollama + DeepSeek 全链路认知：从模型包装器到提示词模版 Agent Demo</a><br></span><span>  4.<a class="is-size-6" href="/2025/03/03/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8DeepSeek-R1%EF%BC%9A%E6%8E%A8%E7%90%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A0%B8%E5%BF%83%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97/" target="_blank">如何高效使用DeepSeek-R1：推理大模型核心调优指南</a><br></span><span>  5.<a class="is-size-6" href="/2025/02/23/%E5%BE%85%E5%8F%91%E5%B8%83/LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E6%9C%AF%E8%AF%AD%E8%AE%A4%E7%9F%A5/" target="_blank">LLM 大语言模型定义以及关键技术术语认知</a><br></span></div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 推荐文章</span><br><span>  1.<a class="is-size-6" href="/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" target="_blank">《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记</a><br></span><span>  2.<a class="is-size-6" href="/2024/10/10/Git/Git-%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81-reference-broken-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/" target="_blank">Git 提交代码 reference broken 问题处理</a><br></span><span>  3.<a class="is-size-6" href="/2022/11/19/Git/%E5%85%B3%E4%BA%8E-Git-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于 Git 重写历史的一些笔记</a><br></span><span>  4.<a class="is-size-6" href="/2022/08/02/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%8F%98%E5%9F%BA%E6%93%8D%E4%BD%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支变基操作的一些笔记</a><br></span><span>  5.<a class="is-size-6" href="/2022/07/26/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支基础知识的一些笔记</a><br></span><span>  6.<a class="is-size-6" href="/2022/08/02/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支工作流的一些笔记</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay%EF%BF%A5.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat%EF%BF%A5.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/03/21/Java/SpringBoot-SSE-rabbitMQ-%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B9%BF%E6%92%AD%E6%8E%A8%E9%80%81/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">SpringBoot + SSE + rabbitMQ 实现服务端分布式广播推送</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2025/03/10/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/LangChain/LangChain-Ollama-DeepSeek-%E5%85%A8%E9%93%BE%E8%B7%AF%E8%AE%A4%E7%9F%A5%EF%BC%9A%E4%BB%8E%E6%A8%A1%E5%9E%8B%E5%8C%85%E8%A3%85%E5%99%A8%E5%88%B0%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E7%89%88-Agent-Demo/"><span class="level-item">LangChain + Ollama + DeepSeek 全链路认知：从模型包装器到提示词模版 Agent Demo</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: 'b2667027df19e00fd8417e25df5a43ac',
            repo: 'blog_comment',
            owner: 'LIRUILONGS',
            clientID: '9fdc9739266d48d5f62e',
            clientSecret: 'c1cc33697d099a2197650ec9dadcb16bd4904655',
            admin: ["LIRUILONGS"],
            createIssueManually: true,
            distractionFreeMode: true,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><ul class="menu-list"><li><a class="is-flex is-mobile" href="#写在前面"><span class="mr-2">1.1</span><span>写在前面</span></a></li></ul><li><a class="is-flex is-mobile" href="#Lang-Chain-模块认知-模型-IO"><span class="mr-2">2</span><span>Lang Chain 模块认知 模型 IO</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#模型包装器"><span class="mr-2">2.1</span><span>模型包装器</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#LLM-模型包装器"><span class="mr-2">2.1.1</span><span>LLM 模型包装器</span></a></li><li><a class="is-flex is-mobile" href="#聊天模型包装器"><span class="mr-2">2.1.2</span><span>聊天模型包装器</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#提示词模板"><span class="mr-2">2.2</span><span>提示词模板</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#基础提示模板-PromptTemplate"><span class="mr-2">2.2.1</span><span>基础提示模板 (PromptTemplate)</span></a></li><li><a class="is-flex is-mobile" href="#少量示例模板-FewShotPromptTemplate"><span class="mr-2">2.2.2</span><span>少量示例模板 (FewShotPromptTemplate)</span></a></li><li><a class="is-flex is-mobile" href="#聊天提示模板-ChatPromptTemplate"><span class="mr-2">2.2.3</span><span>聊天提示模板 (ChatPromptTemplate)</span></a></li><li><a class="is-flex is-mobile" href="#组合模板-PipelinePromptTemplate"><span class="mr-2">2.2.4</span><span>组合模板 (PipelinePromptTemplate)</span></a></li><li><a class="is-flex is-mobile" href="#自定义模板-Custom-Template"><span class="mr-2">2.2.5</span><span>自定义模板 (Custom Template)</span></a></li><li><a class="is-flex is-mobile" href="#文件加载模板-load-prompt"><span class="mr-2">2.2.6</span><span>文件加载模板 (load_prompt)</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#输出解析器"><span class="mr-2">2.3</span><span>输出解析器</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#基础解析器：Pydantic-模型结构化输出"><span class="mr-2">2.3.1</span><span>基础解析器：Pydantic 模型结构化输出</span></a></li><li><a class="is-flex is-mobile" href="#JSON-格式解析器"><span class="mr-2">2.3.2</span><span>JSON 格式解析器</span></a></li><li><a class="is-flex is-mobile" href="#列表解析器"><span class="mr-2">2.3.3</span><span>列表解析器</span></a></li><li><a class="is-flex is-mobile" href="#结构化文本解析器"><span class="mr-2">2.3.4</span><span>结构化文本解析器</span></a></li><li><a class="is-flex is-mobile" href="#日期时间解析器"><span class="mr-2">2.3.5</span><span>日期时间解析器</span></a></li><li><a class="is-flex is-mobile" href="#自动重试解析器"><span class="mr-2">2.3.6</span><span>自动重试解析器</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#博文部分内容参考"><span class="mr-2">2.4</span><span>博文部分内容参考</span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class=""><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7.jpg" alt="山河已无恙"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">山河已无恙</p><p class="is-size-6 is-block">爱自己，是终生浪漫的开始</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国·呼和浩特</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">443</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">144</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">191</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/LIRUILONGS"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="https://liruilong.blog.csdn.net/"><i class="fa fa-code"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:1224965096@qq.com"><i class="fa fa-envelope"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://liruilong.blog.csdn.net/?t=1&amp;type=blog" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">liruilong.blog.csdn.net</span></span></a></li><li><a class="level is-mobile" href="https://www.cnblogs.com/liruilong/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">博客园</span></span><span class="level-right"><span class="level-item tag">www.cnblogs.com</span></span></a></li><li><a class="level is-mobile" href="https://github.com/LIRUILONGS" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Githup</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://gitee.com/liruilonger" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">码云</span></span><span class="level-right"><span class="level-item tag">gitee.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-26T02:38:57.000Z">2025-05-26</time></p><p class="title"><a href="/2025/05/26/%E5%BE%85%E5%8F%91%E5%B8%83/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-BPF-%E5%88%86%E6%9E%90-Linux-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%EF%BC%8CLinux-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B-BPF-%E5%88%86%E6%9E%90%E5%86%85%E6%A0%B8%E6%80%81%E3%80%81%E7%94%A8%E6%88%B7%E6%80%81%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/">如何使用 BPF 分析 Linux 内存泄漏，Linux 性能调优之 BPF 分析内核态、用户态内存泄漏</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-22T03:12:56.000Z">2025-05-22</time></p><p class="title"><a href="/2025/05/22/%E5%BE%85%E5%8F%91%E5%B8%83/%E5%BC%B1%E5%85%89%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A6%82%E4%BD%95%E6%89%8B%E6%8C%81%E7%9B%B8%E6%9C%BA%E6%8B%8D%E6%91%84%E9%9D%99%E7%89%A9%EF%BC%9A%E6%91%84%E5%BD%B1%E6%9B%9D%E5%85%89%E4%B9%8B%E7%AD%89%E6%95%88%E6%9B%9D%E5%85%89%E8%AE%A4%E7%9F%A5/">弱光环境下如何手持相机拍摄静物：摄影曝光之等效曝光认知</a></p><p class="categories"><a href="/categories/%E6%91%84%E5%BD%B1%E6%9B%9D%E5%85%89/">摄影曝光</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-17T23:32:10.000Z">2025-04-18</time></p><p class="title"><a href="/2025/04/18/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%AE%A4%E8%AF%86%20Linux%20%E5%86%85%E5%AD%98%E6%9E%84%E6%88%90%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E9%A1%B5%E8%A1%A8%E3%80%81TLB%E3%80%81%E5%A4%A7%E9%A1%B5%E8%AE%A4%E7%9F%A5/">认识 Linux 内存构成：Linux 内存调优之页表、TLB、缺页异常、大页认知</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-13T14:50:54.000Z">2025-04-13</time></p><p class="title"><a href="/2025/04/13/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%B0%B7%E6%AD%8C68%E9%A1%B5%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E5%AF%86%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%A6%82%E4%BD%95%E9%87%8D%E5%A1%91AI%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91/">谷歌68页白皮书解密：提示工程如何重塑AI交互逻辑</a></p><p class="categories"><a href="/categories/LLM/">LLM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-11T11:38:12.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%E5%BE%85%E5%8F%91%E5%B8%83/Linux%20%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E5%85%A8%E9%9D%A2%E7%9B%91%E6%8E%A7/">Linux 系统内存监控：Linux 内存调优之系统内存全面监控</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AdaFace/"><span class="level-start"><span class="level-item">AdaFace</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ajax/"><span class="level-start"><span class="level-item">Ajax</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ansible/"><span class="level-start"><span class="level-item">Ansible</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AppCube/"><span class="level-start"><span class="level-item">AppCube</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/BPF/"><span class="level-start"><span class="level-item">BPF</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Bind9/"><span class="level-start"><span class="level-item">Bind9</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CI-CD/"><span class="level-start"><span class="level-item">CI/CD</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ceph/"><span class="level-start"><span class="level-item">Ceph</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Kubernetes/"><span class="tag">Kubernetes</span><span class="tag is-grey-lightest">98</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag is-grey-lightest">58</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ansible/"><span class="tag">Ansible</span><span class="tag is-grey-lightest">25</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ceph/"><span class="tag">Ceph</span><span class="tag is-grey-lightest">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JAVA/"><span class="tag">JAVA</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%8E%E4%B8%BA%E4%BA%91/"><span class="tag">华为云</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BPF/"><span class="tag">BPF</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mysql/"><span class="tag">Mysql</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenShift/"><span class="tag">OpenShift</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%91%84%E5%BD%B1%E6%9B%9D%E5%85%89/"><span class="tag">摄影曝光</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"><span class="tag">程序人生</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNS/"><span class="tag">DNS</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OKD/"><span class="tag">OKD</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/selenium/"><span class="tag">selenium</span><span class="tag is-grey-lightest">4</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a><p class="size-small"><span>&copy; 2025 山河已无恙</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© <a href="http://www.beian.miit.gov.cn/" target="_blank">备案中</a><br></span><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2021/6/26 21:27:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>