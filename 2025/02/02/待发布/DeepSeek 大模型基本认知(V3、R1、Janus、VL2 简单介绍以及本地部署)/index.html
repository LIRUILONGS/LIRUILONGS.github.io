<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>DeepSeek 大模型基本认知(V3、R1、Janus、VL2 简单介绍以及本地部署) - 山河已无恙</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="山河已无恙"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="山河已无恙"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="“以开源精神和长期主义追求普惠 AGI” 是 DeepSeek 一直以来的坚定信念"><meta property="og:type" content="blog"><meta property="og:title" content="山河已无恙"><meta property="og:url" content="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd"><meta property="og:site_name" content="山河已无恙"><meta property="og:description" content="“以开源精神和长期主义追求普惠 AGI” 是 DeepSeek 一直以来的坚定信念"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mp.weixin.qq.com/img/头像.jpg"><meta property="article:published_time" content="2025-02-02T05:32:31.000Z"><meta property="article:modified_time" content="2025-02-04T02:43:58.568Z"><meta property="article:author" content="LIRUILONGS"><meta property="article:tag" content="DeepSeek"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/头像.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://liruilongs.github.io/2025/02/02/%E5%BE%85%E5%8F%91%E5%B8%83/DeepSeek%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E6%9C%AC%E8%AE%A4%E7%9F%A5(V3%E3%80%81R1%E3%80%81Janus%E3%80%81VL2%20%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2)/"},"headline":"山河已无恙","image":["https://i-blog.csdnimg.cn/direct/53a0ff76d05642b1bd3d0d9217ec231e.png","https://i-blog.csdnimg.cn/direct/f373c126eae84cceafa484eb6d10ed32.png","https://i-blog.csdnimg.cn/direct/781717f8321240ae9273d1f48360d00f.png","https://i-blog.csdnimg.cn/direct/03eb2bdf787e4f5496eff224681110d0.png","https://i-blog.csdnimg.cn/direct/e29df01d3b424734ac54a7a51194b6b2.png","https://i-blog.csdnimg.cn/direct/96ecf0fdc7e544499e66c62ed10145cb.png","https://i-blog.csdnimg.cn/direct/663ab5f8f77c4dc7b9b4b9b0b3a0a92f.png","https://i-blog.csdnimg.cn/direct/61151cf6548c47e0893ca85b6394dbda.png","https://i-blog.csdnimg.cn/direct/fa95805675384eb4913fb785f8f0d454.png","https://i-blog.csdnimg.cn/direct/ed962478594e43b6a1bdce26da9b233c.png"],"datePublished":"2025-02-02T05:32:31.000Z","dateModified":"2025-02-04T02:43:58.568Z","author":{"@type":"Person","name":"山河已无恙"},"description":"“以开源精神和长期主义追求普惠 AGI” 是 DeepSeek 一直以来的坚定信念"}</script><link rel="canonical" href="https://liruilongs.github.io/2025/02/02/%E5%BE%85%E5%8F%91%E5%B8%83/DeepSeek%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E6%9C%AC%E8%AE%A4%E7%9F%A5(V3%E3%80%81R1%E3%80%81Janus%E3%80%81VL2%20%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2)/"><link rel="alternate" href="/path/to/atom.xml" title="山河已无恙" type="application/atom+xml"><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?3f06f2b732a5b1034c989f74e28d0eea";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">影音</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/self-talking">生活小记</a><a class="navbar-item" href="/message">留言墙</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/liruilonger"><i class="fab fa-git-square fa-1x"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/LIRUILONGS"><i class="fab fa-github fa-1x"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul fa-1x"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search fa-1x"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon fa-1x" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2025-02-02  <a class="commentCountImg" href="/2025/02/02/%E5%BE%85%E5%8F%91%E5%B8%83/DeepSeek%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E6%9C%AC%E8%AE%A4%E7%9F%A5(V3%E3%80%81R1%E3%80%81Janus%E3%80%81VL2%20%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2)/#comment-container"><span class="display-none-class">c9c706b72f139354d8cf61c5158442da</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="c9c706b72f139354d8cf61c5158442da">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>1 小时  <i class="fas fa-pencil-alt"> </i>8.6 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">DeepSeek 大模型基本认知(V3、R1、Janus、VL2 简单介绍以及本地部署)</h1><div class="content"><p><strong><font color="009688"> “以开源精神和长期主义追求普惠 AGI” 是 DeepSeek 一直以来的坚定信念</strong></font></p>
<span id="more"></span>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><hr>
<ul>
<li>看到好多人都在讨论，简单认识一下</li>
<li>博文内容涉及 DeepSeek AI 大模型 V3、R1、Janus、VL2 简单介绍以及本地部署</li>
<li>理解不足小伙伴帮忙指正 :),生活加油</li>
</ul>
<p><strong><font color="009688"> “以开源精神和长期主义追求普惠 AGI” 是 DeepSeek 一直以来的坚定信念</strong></font></p>
<p>持续分享技术干货，感兴趣小伙伴可以关注下 ^_^</p>
<hr>
<p>关于 DeepSeek 是什么不多讲了，我们直接看模型吧 ^_^</p>
<p>项目地址：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/">https://github.com/deepseek-ai/</a></p>
<p>公开的模型地址：</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/deepseek-ai">https://huggingface.co/deepseek-ai</a></p>
<h2 id="DeepSeek-V3-系列"><a href="#DeepSeek-V3-系列" class="headerlink" title="DeepSeek-V3 系列"></a><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3 系列</a></h2><p><code>DeepSeek-V3</code>  是 <code>DeepSeek-V2</code> 之后有一个新的版本，一个超大规模的 “混合专家”模型（MoE），671B 参数，激活 37B，在 14.8T token 上进行了预训练。它专为高效训练和推理设计，<code>既能生成高质量文本，又能节省计算资源</code>。用更低的成本（时间和算力）实现顶级性能，对标甚至超越闭源模型（如 GPT-4）。通俗的话讲专注文本任务，规模更大、效率更高,节省资源</p>
<p>项目地址 <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3">https://github.com/deepseek-ai/DeepSeek-V3</a></p>
<p>发布公告： <a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/zh-cn/news/news1226">https://api-docs.deepseek.com/zh-cn/news/news1226</a></p>
<p>用一句话讲 <code>DeepSeek-V3</code> 系列大模型 专注于 <code>文本生成和理解，比如对话、问答、写作、翻译等</code>任务。</p>
<h3 id="在线体验"><a href="#在线体验" class="headerlink" title="在线体验"></a>在线体验</h3><p><a target="_blank" rel="noopener" href="https://chat.deepseek.com/sign_in">https://chat.deepseek.com/sign_in</a></p>
<p>需要注册一个账号，直接问问题就可以</p>
<p><img src="https://i-blog.csdnimg.cn/direct/53a0ff76d05642b1bd3d0d9217ec231e.png" alt="在这里插入图片描述"></p>
<h3 id="本地部署算力要求"><a href="#本地部署算力要求" class="headerlink" title="本地部署算力要求"></a>本地部署算力要求</h3><p>这个需要算力环境，我当前的机器部署不了， 项目的 <code>readme</code> 文件里面也没有写算力要求,而且模型特别大</p>
<p>可以通过 <code>ollama</code> 来部署， 671b 参数 400 多G</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator&gt; ollama run deepseek-v3</span><br><span class="line">pulling manifest</span><br><span class="line">pulling d83c18fb2a2c...   0% ▕                                                        ▏ 814 MB/404 GB   25 MB/s   4h27m</span><br></pre></td></tr></table></figure>

<p>sglang 的部署 readme 里面有个硬件推荐 <strong>8 个 NVIDIA H200 GPU</strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3">https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3</a></p>
<p>主要是显存，同时需要考虑<code>模型精度</code>，我在这个 <code>issues</code> 下面看到的算力讨论, <code>DeepSeek-V3</code> 采用 <code>FP8</code> 训练，并开源了原生 FP8 权重。，<code>SGLang 和 LMDeploy</code> 第一时间支持了 <code>V3</code> 模型的原生 FP8 推理，同时 <code>TensorRT-LLM 和 MindIE</code> 则实现了 <code>BF16</code> 推理。同时提供了从 <code>FP8</code> 到 <code>BF16</code> 的转换脚本。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/InternLM/lmdeploy/issues/2960">https://github.com/InternLM/lmdeploy/issues/2960</a></p>
<p>DeepSeekV3 有 671B 个参数，显存要求为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">对于 FP8：~671GB （671B × 1GB/B） ~ 83-84 * 8 = 672</span><br><span class="line">对于 BF16：~1,342GB（671B × 2GB/B）</span><br></pre></td></tr></table></figure>

<p><code>DeepSeek-V2</code> 版本有个算力要求可以参考，236B 参数，要使用<code>BF16</code>格式的<code>DeepSeek-V2</code>进行推理，需要<code>80GB*8 GPU</code>。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V2?tab=readme-ov-file#8-how-to-run-locally">https://github.com/deepseek-ai/DeepSeek-V2?tab=readme-ov-file#8-how-to-run-locally</a></p>
<h2 id="DeepSeek-R1-系列"><a href="#DeepSeek-R1-系列" class="headerlink" title="DeepSeek-R1 系列"></a><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1 系列</a></h2><p>DeepSeek-R1 是一个<code>基于强化学习(RL)</code>训练的<code>大型语言模型(LLM)</code>, <strong>旨在提高其推理能力</strong> 。它通过两个RL阶段和两个监督微调(SFT)阶段进行训练,以发现更好的推理模式并与人类偏好保持一致。此外,<code>DeepSeek-R1</code>还展示了将大型模型的推理模式蒸馏到较小模型的能力,从而获得更好的性能。该项目还开源了<code>DeepSeek-R1-Zero、DeepSeek-R1</code>以及<code>基于Llama和Qwen的6个密集型模型</code>,为研究社区提供支持。</p>
<p>包含以下核心模型：</p>
<ul>
<li><code>DeepSeek-R1-Zero</code>：通过纯强化学习（RL）训练的基础模型，无监督微调（SFT）阶段，探索性强但存在输出不稳定问题。</li>
<li><code>DeepSeek-R1</code>：在 <code>R1-Zero</code> 基础上引入冷启动数据（少量 SFT）优化后的版本，解决输出问题并提升推理能力。</li>
<li><code>DeepSeek-R1-Distill</code>：从 <code>R1</code> 蒸馏到小型开源模型（如 Qwen、Llama）的轻量级推理模型，性能接近原版但更易部署。</li>
</ul>
<p><strong>DeepSeek-R1-Zero 和 DeepSeek-R1 基于 DeepSeek-V3-Base 进行训练，DeepSeek-R1-Distill 模型基于开源模型使用 DeepSeek-R1 生成的样本进行微调</strong></p>
<p>项目地址： <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-R1">https://github.com/deepseek-ai/DeepSeek-R1</a></p>
<p>发布公告： <a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/zh-cn/news/news250120">https://api-docs.deepseek.com/zh-cn/news/news250120</a></p>
<p>用一句话讲 <code>DeepSeek-R1</code> 系列是专注于 <code>复杂推理任务（如数学、代码、逻辑推理）</code>的模型家族</p>
<h3 id="在线体验-1"><a href="#在线体验-1" class="headerlink" title="在线体验"></a>在线体验</h3><p><a target="_blank" rel="noopener" href="https://chat.deepseek.com/sign_in">https://chat.deepseek.com/sign_in</a></p>
<p>需要注册一个账号，然后选择 <strong>深度思考 R1</strong></p>
<p><img src="https://i-blog.csdnimg.cn/direct/f373c126eae84cceafa484eb6d10ed32.png" alt="在这里插入图片描述"></p>
<h3 id="本地部署"><a href="#本地部署" class="headerlink" title="本地部署"></a>本地部署</h3><p>我当前的机器可以本地部署  <code>DeepSeek-R1-Distill</code> 系列的小模型</p>
<ul>
<li><code>DeepSeek-R1-Distill-Qwen-1.5B</code></li>
<li><code>DeepSeek-R1-Distill-Qwen-7B</code></li>
<li><code>DeepSeek-R1-Distill-Llama-8B</code></li>
<li><code>DeepSeek-R1-Distill-Qwen-14B</code></li>
<li><code>DeepSeek-R1-Distill-Qwen-32B</code></li>
<li><code>DeepSeek-R1-Distill-Llama-70B</code></li>
</ul>
<p>下载 ollama：之后直接安装就可以</p>
<p><a target="_blank" rel="noopener" href="https://ollama.com/download">https://ollama.com/download</a></p>
<p>安装成功会自动配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator&gt; ollama -h</span><br><span class="line">Large language model runner</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  ollama [flags]</span><br><span class="line">  ollama [<span class="built_in">command</span>]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  serve       Start ollama</span><br><span class="line">  create      Create a model from a Modelfile</span><br><span class="line">  show        Show information <span class="keyword">for</span> a model</span><br><span class="line">  run         Run a model</span><br><span class="line">  stop        Stop a running model</span><br><span class="line">  pull        Pull a model from a registry</span><br><span class="line">  push        Push a model to a registry</span><br><span class="line">  list        List models</span><br><span class="line">  ps          List running models</span><br><span class="line">  cp          Copy a model</span><br><span class="line">  rm          Remove a model</span><br><span class="line">  <span class="built_in">help</span>        Help about any <span class="built_in">command</span></span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">  -h, --<span class="built_in">help</span>      <span class="built_in">help</span> <span class="keyword">for</span> ollama</span><br><span class="line">  -v, --version   Show version information</span><br><span class="line"></span><br><span class="line">Use <span class="string">&quot;ollama [command] --help&quot;</span> <span class="keyword">for</span> more information about a <span class="built_in">command</span>.</span><br><span class="line">PS C:\Users\Administrator&gt;</span><br></pre></td></tr></table></figure>

<p>通过下面的地址选择对应的参数的模型即可：</p>
<p><a target="_blank" rel="noopener" href="https://ollama.com/library/deepseek-r1">https://ollama.com/library/deepseek-r1</a></p>
<p><img src="https://i-blog.csdnimg.cn/direct/781717f8321240ae9273d1f48360d00f.png" alt="在这里插入图片描述"></p>
<p>模型下载成功就可以用了，默认会自动下载 <code>DeepSeek-R1-Distill-Qwen-7B</code> 模型</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator&gt; ollama run deepseek-r1</span><br><span class="line">pulling manifest</span><br><span class="line">pulling 96c415656d37... 100% ▕████████████████████████████████████████████████████████▏ 4.7 GB</span><br><span class="line">pulling 369ca498f347... 100% ▕████████████████████████████████████████████████████████▏  387 B</span><br><span class="line">pulling 6e4c38e1172f... 100% ▕████████████████████████████████████████████████████████▏ 1.1 KB</span><br><span class="line">pulling f4d24e9138dd... 100% ▕████████████████████████████████████████████████████████▏  148 B</span><br><span class="line">pulling 40fb844194b2... 100% ▕████████████████████████████████████████████████████████▏  487 B</span><br><span class="line">verifying sha256 digest</span><br><span class="line">writing manifest</span><br><span class="line">success</span><br></pre></td></tr></table></figure>

<p>直接命令行就可以交互了，算一道数学题</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator&gt; ollama run deepseek-r1</span><br><span class="line">&gt;&gt;&gt; 1+2+3+4+54654+213=？</span><br><span class="line">&lt;think&gt;</span><br><span class="line">To solve the equation \(1 + 2 + 3 + 4 + 54654 + 213\), I will follow these steps:</span><br><span class="line"></span><br><span class="line">First, add the numbers from 1 to 4.</span><br><span class="line"></span><br><span class="line">Next, add the result to 54654.</span><br><span class="line"></span><br><span class="line">Finally, add this sum to 213 to get the final answer.</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">To solve the equation \(1 + 2 + 3 + 4 + 54654 + 213\), follow these steps:</span><br><span class="line"></span><br><span class="line">1. **Add the numbers from 1 to 4:**</span><br><span class="line"></span><br><span class="line">   \[</span><br><span class="line">   1 + 2 + 3 + 4 = 10</span><br><span class="line">   \]</span><br><span class="line"></span><br><span class="line">2. **Add this sum to 54654:**</span><br><span class="line"></span><br><span class="line">   \[</span><br><span class="line">   10 + 54654 = 54664</span><br><span class="line">   \]</span><br><span class="line"></span><br><span class="line">3. **Finally, add the result to 213:**</span><br><span class="line"></span><br><span class="line">   \[</span><br><span class="line">   54664 + 213 = 54877</span><br><span class="line">   \]</span><br><span class="line"></span><br><span class="line">**Final Answer:**</span><br><span class="line"></span><br><span class="line">\boxed&#123;54877&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Send a message</span><br></pre></td></tr></table></figure>

<p>需要面板工具的可以接 <code>Chatbox</code> 或者 <code>open-webui</code>,下面为  <code>open-webui</code> 的项目地址，时间关系，小伙伴可以自行尝试。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a></p>
<h2 id="Janus-系列"><a href="#Janus-系列" class="headerlink" title="Janus 系列"></a><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/Janus">Janus 系列</a></h2><p>项目地址： <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/Janus">https://github.com/deepseek-ai/Janus</a></p>
<p><code>Janus</code> 系列模型都支持<code>文本和图像的多模态任务</code>，既能<code>理解图文内容，也能生成图文内容</code>。它们都采用了一种统一的框架，将<code>多模态理解和生成任务</code>整合到一个模型中，避免了传统方法中需要多个专用模型的复杂性。<code>DeepSeek</code> 将这些模型开源，支持学术界和工业界的研究和应用。</p>
<p>用一句话讲， Janus 系列模型用于，通过<code>图片分析内容生成文字，以及通过文字描述生成图片</code>。</p>
<p>模型简单介绍：</p>
<ul>
<li><code>Janus</code>基础版多模态模型，专注于统一多模态理解和生成。通过解耦视觉编码，解决了传统模型中视觉编码器在理解和生成任务中的冲突。简单、灵活且高效，性能优于之前的统一模型，甚至媲美专用模型。适用场景：适合需要同时处理图文理解和生成的任务，比如图像描述生成、视觉问答等。</li>
<li><code>Janus-Pro</code>：Janus 的升级版，性能更强，功能更全面。优化了训练策略。使用了更多的训练数据。模型规模更大（如 Janus-Pro-7B）。在多模态理解和文本到图像的指令跟随能力上有显著提升。生成图像的质量和稳定性更好。适用场景：适合对图文理解和生成要求更高的任务，比如高质量的文本到图像生成、复杂的多模态推理等。</li>
<li><code>JanusFlow</code>: 结合了自回归模型和Rectified Flow（一种先进的生成建模方法）的新模型。使用极简架构，无需复杂的修改即可在大型语言模型框架中训练 Rectified Flow。在生成任务中表现优异，媲美甚至超越专用模型。适用场景：适合需要高质量图像生成和多模态理解的任务，比如艺术创作、设计辅助等。</li>
</ul>
<p>下面为 最新的模型 <code>Janus-Pro</code> 的在线体验和本地部署Demo</p>
<h3 id="在线体验-2"><a href="#在线体验-2" class="headerlink" title="在线体验"></a>在线体验</h3><p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/deepseek-ai/Janus-Pro-7B">https://huggingface.co/spaces/deepseek-ai/Janus-Pro-7B</a></p>
<p><img src="https://i-blog.csdnimg.cn/direct/03eb2bdf787e4f5496eff224681110d0.png"></p>
<h3 id="本地部署问题解决"><a href="#本地部署问题解决" class="headerlink" title="本地部署问题解决"></a>本地部署问题解决</h3><p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/Janus?tab=readme-ov-file#janus-pro">https://github.com/deepseek-ai/Janus?tab=readme-ov-file#janus-pro</a></p>
<p>直接按照readme文档操作就行，克隆项目，创建虚拟环境，install 依赖，如果需要UI 交互，选择  <code>gradio</code> 版本，然后就会自己下模型</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\Janus&gt; pip install -e .[gradio]</span><br><span class="line">Obtaining file:///C:/Users/Administrator/Documents/GitHub/Janus</span><br><span class="line">  Installing build dependencies ... <span class="keyword">done</span></span><br><span class="line">  Checking <span class="keyword">if</span> build backend supports build_editable ... <span class="keyword">done</span></span><br><span class="line">  Getting requirements to build editable ... <span class="keyword">done</span></span><br><span class="line">  Preparing editable metadata (pyproject.toml) ... <span class="keyword">done</span></span><br><span class="line">  ........................</span><br><span class="line">Building wheels <span class="keyword">for</span> collected packages: janus</span><br><span class="line">  Building editable <span class="keyword">for</span> janus (pyproject.toml) ... <span class="keyword">done</span></span><br><span class="line">  Created wheel <span class="keyword">for</span> janus: filename=janus-1.0.0-0.editable-py3-none-any.whl size=16002 sha256=00f8a57fbcefb148efcfd23b83693d260c751b746d7baa5ffa8d17981c908f7c</span><br><span class="line">  Stored <span class="keyword">in</span> directory: D:\Temp\pip-ephem-wheel-cache-k1hkfs8g\wheels\dd\84\9f\ec544ec10f9f6d18b0043de3566fbc47b75c06c5ec8eb88bc1</span><br><span class="line">Successfully built janus</span><br><span class="line">Installing collected packages: janus</span><br><span class="line">  Attempting uninstall: janus</span><br><span class="line">    Found existing installation: janus 1.0.0</span><br><span class="line">    Uninstalling janus-1.0.0:</span><br><span class="line">      Successfully uninstalled janus-1.0.0</span><br><span class="line">Successfully installed janus-1.0.0</span><br></pre></td></tr></table></figure>

<p>运行Demo</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\Janus&gt; python demo/app_januspro.py</span><br><span class="line">Python version is above 3.10, patching the collections module.</span><br><span class="line">C:\Users\Administrator\Documents\GitHub\Janus\.venv\lib\site-packages\torchvision\datapoints\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we <span class="keyword">do</span> not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have <span class="keyword">in</span> this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().</span><br><span class="line">  warnings.warn(_BETA_TRANSFORMS_WARNING)</span><br><span class="line">C:\Users\Administrator\Documents\GitHub\Janus\.venv\lib\site-packages\torchvision\transforms\v2\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we <span class="keyword">do</span> not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have <span class="keyword">in</span> this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().</span><br><span class="line">  warnings.warn(_BETA_TRANSFORMS_WARNING)</span><br><span class="line">C:\Users\Administrator\Documents\GitHub\Janus\.venv\lib\site-packages\transformers\models\auto\image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed <span class="keyword">in</span> v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead</span><br><span class="line">  warnings.warn(</span><br><span class="line">config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.28k/1.28k [00:00&lt;?, ?B/s]</span><br><span class="line">pytorch_model.bin.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89.0k/89.0k [00:00&lt;00:00, 252kB/s]</span><br><span class="line">model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92.8k/92.8k [00:00&lt;00:00, 243kB/s]</span><br><span class="line">pytorch_model-00001-of-00002.bin:   0%|                                                                                                              | 10.5M/9.99G [00:02&lt;33:41, 4.94MB/s] </span><br><span class="line">pytorch_model-00001-of-00002.bin:   2%|█▋                                                                                                             | 157M/9.99G [00:13&lt;11:13, 14.6MB/s]  </span><br><span class="line">。。。。。。。。。。。。。。。。。。</span><br><span class="line">tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 285/285 [00:00&lt;00:00, 272kB/s]</span><br><span class="line">tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.72M/4.72M [00:00&lt;00:00, 7.59MB/s]</span><br><span class="line">special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 344/344 [00:00&lt;?, ?B/s]</span><br><span class="line">You are using the default legacy behaviour of the &lt;class <span class="string">&#x27;transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast&#x27;</span>&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes <span class="keyword">for</span> you. If you want to use the new behaviour, <span class="built_in">set</span> `legacy=False`. This should only be <span class="built_in">set</span> <span class="keyword">if</span> you understand what it means, and thoroughly <span class="built_in">read</span> the reason why this was added as explained <span class="keyword">in</span> https://github.com/huggingface/transformers/pull/24565 - <span class="keyword">if</span> you loaded a llama tokenizer from a GGUF file you can ignore this message.</span><br><span class="line">processor_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 210/210 [00:00&lt;?, ?B/s]</span><br><span class="line">Some kwargs <span class="keyword">in</span> processor config are unused and will not have any effect: ignore_id, add_special_token, num_image_tokens, mask_prompt, image_tag, sft_format.</span><br><span class="line">Running on <span class="built_in">local</span> URL:  http://127.0.0.1:7860</span><br><span class="line">IMPORTANT: You are using gradio version 3.48.0, however version 4.44.1 is available, please upgrade.</span><br><span class="line">--------</span><br><span class="line">Running on public URL: https://8f307516dd497d1b07.gradio.live</span><br><span class="line"></span><br><span class="line">This share link expires <span class="keyword">in</span> 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)</span><br></pre></td></tr></table></figure>

<p>install 过程需要 VPN ，没有VPN 报下来类似的报错</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OSError: We couldn<span class="string">&#x27;t connect to &#x27;</span>https://huggingface.co<span class="string">&#x27; to load this file, couldn&#x27;</span>t find it <span class="keyword">in</span> the cached files and it looks like deepseek-ai/Janus-Pro-7B is not the path to a directory containing a file named preprocessor_config.json.</span><br><span class="line">Checkout your internet connection or see how to run the library <span class="keyword">in</span> offline mode at <span class="string">&#x27;https://huggingface.co/docs/transformers/installation#offline-mode&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>上传图片识别报错</p>
<p><img src="https://i-blog.csdnimg.cn/direct/e29df01d3b424734ac54a7a51194b6b2.png" alt="在这里插入图片描述"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\Janus\demo\app_januspro.py&quot;</span>, line 58, <span class="keyword">in</span> multimodal_understanding</span><br><span class="line">  inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)</span><br><span class="line">File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\Janus\janus\models\modeling_vlm.py&quot;</span>, line 246, <span class="keyword">in</span> prepare_inputs_embeds</span><br><span class="line">  images_embeds = self.aligner(self.vision_model(images))</span><br><span class="line">。。。。。。。。。。。。。。。。。。。。。。。。。</span><br><span class="line">RuntimeError: <span class="string">&quot;slow_conv2d_cpu&quot;</span> not implemented <span class="keyword">for</span> <span class="string">&#x27;Half&#x27;</span>  </span><br></pre></td></tr></table></figure>

<p>这个 <code>issues</code> 下面有解决办法</p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/Janus/issues/121">https://github.com/deepseek-ai/Janus/issues/121</a></p>
<p>确认下使用的CPU 还是GPU</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cuda_device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用了那个： &quot;</span>,cuda_device)</span><br></pre></td></tr></table></figure>

<h4 id="GPU-修改"><a href="#GPU-修改" class="headerlink" title="GPU 修改"></a>GPU 修改</h4><p>如果用 GPU 跑，需要重新install GPU 的 torch。需要注意低版本不支持 <code>float16</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\Janus&gt; pip uninstall torch                                                              </span><br><span class="line">WARNING: Skipping torch as it is not installed.</span><br><span class="line">PS C:\Users\Administrator\Documents\GitHub\Janus&gt; pip install torch==2.2.2+cu118 --index-url https://download.pytorch.org/whl/cu118</span><br><span class="line">Looking <span class="keyword">in</span> indexes: https://download.pytorch.org/whl/cu118</span><br><span class="line">Collecting torch==2.2.2+cu118</span><br><span class="line">  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp310-cp310-win_amd64.whl (2704.2 MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 GB 10.1 MB/s eta 0:00:00</span><br></pre></td></tr></table></figure>

<p>GPU 我的机器需要 30 秒左右</p>
<p><img src="https://i-blog.csdnimg.cn/direct/96ecf0fdc7e544499e66c62ed10145cb.png" alt="在这里插入图片描述"></p>
<p><img src="https://i-blog.csdnimg.cn/direct/663ab5f8f77c4dc7b9b4b9b0b3a0a92f.png" alt="在这里插入图片描述"></p>
<h4 id="CPU-修改"><a href="#CPU-修改" class="headerlink" title="CPU 修改"></a>CPU 修改</h4><p>如果没有显卡，只用 CPU 跑，需要修改这两个地方</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    <span class="comment">#vl_gpt = vl_gpt.to(torch.bfloat16).cuda()</span></span><br><span class="line">    vl_gpt = vl_gpt.to(torch.bfloat32).cuda()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment">#vl_gpt = vl_gpt.to(torch.float16)</span></span><br><span class="line">    vl_gpt = vl_gpt.to(torch.float32)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pil_images = [Image.fromarray(image)]</span><br><span class="line">prepare_inputs = vl_chat_processor(</span><br><span class="line">    conversations=conversation, images=pil_images, force_batchify=<span class="literal">True</span></span><br><span class="line"><span class="comment">#).to(cuda_device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16)</span></span><br><span class="line">).to(cuda_device, dtype=torch.bfloat32 <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.float32)</span><br></pre></td></tr></table></figure>

<p>CPU 超级慢，下面的分析用了 200 多秒，但是内容更多，应该和精度有关系</p>
<p><img src="https://i-blog.csdnimg.cn/direct/61151cf6548c47e0893ca85b6394dbda.png" alt="在这里插入图片描述"></p>
<h2 id="DeepSeek-VL2-系列"><a href="#DeepSeek-VL2-系列" class="headerlink" title="DeepSeek-VL2 系列"></a><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-VL2">DeepSeek-VL2 系列</a></h2><p>DeepSeek-VL2 是一个<code>大型混合专家(MoE)视觉语言模型</code>系列,显著改进了其前身<code>DeepSeek-VL</code>。<code>DeepSeek-VL2</code>在各种任务中表现出色,包括但不限于<code>视觉问答、光学字符识别、文档/表格/图表理解和视觉定位</code>。</p>
<p>项目地址：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-VL2">https://github.com/deepseek-ai/DeepSeek-VL2</a></p>
<p>用一句话讲，DeepSeek-VL2 用于<code>处理视觉问答、光学字符识别和文档理解等</code>任务</p>
<p>该模型系列包括三个变体:</p>
<ul>
<li><code>DeepSeek-VL2-Tiny</code>: 10亿 个激活参数</li>
<li><code>DeepSeek-VL2-Small</code>： 28亿个激活参数</li>
<li><code>DeepSeek-VL2</code>,45亿个激活参数</li>
</ul>
<p>需要<code>80GB GPU</code>内存才能使用 <code>deepseek-vl2-small</code> 运行，对于 <code>deepseek-vl2</code>，可能需要更大的内存。与现有的开源密集型和基于MoE的模型相比,<code>DeepSeek-VL2</code>在性能上具有竞争力或达到最先进水平,同时使用的激活参数更少或相当。</p>
<p><code>DeepSeek-VL2</code> 没有找到对应的在线体验版本</p>
<h3 id="本地部署-1"><a href="#本地部署-1" class="headerlink" title="本地部署"></a>本地部署</h3><p>这里尝试着部署 <code>DeepSeek-VL2-Tiny</code>, 直接按照readme文档操作就行，克隆项目，创建虚拟环境，install 依赖，如果需要UI 交互，选择  <code>gradio</code> 版本，然后就会自己下模型</p>
<p>目前只支持 GPU 部署</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; pip install -e .[gradio]</span><br></pre></td></tr></table></figure>

<p>然后根据 显存大小选择合适的命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vl2-tiny, 3.37B-MoE in total, activated 1B, can be run on a single GPU &lt; 40GB</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=2 python web_demo.py \</span><br><span class="line">--model_name <span class="string">&quot;deepseek-ai/deepseek-vl2-tiny&quot;</span>  \</span><br><span class="line">--port 37914</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># vl2-small, 16.1B-MoE in total, activated 2.4B</span></span><br><span class="line"><span class="comment"># If run on A100 40GB GPU, you need to set the `--chunk_size 512` for incremental prefilling for saving memory and it might be slow.</span></span><br><span class="line"><span class="comment"># If run on &gt; 40GB GPU, you can ignore the `--chunk_size 512` for faster response.</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=2 python web_demo.py \</span><br><span class="line">--model_name <span class="string">&quot;deepseek-ai/deepseek-vl2-small&quot;</span>  \</span><br><span class="line">--port 37914 \</span><br><span class="line">--chunk_size 512</span><br><span class="line"></span><br><span class="line"><span class="comment"># # vl27.5-MoE in total, activated 4.2B</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=2 python web_demo.py \</span><br><span class="line">--model_name <span class="string">&quot;deepseek-ai/deepseek-vl2&quot;</span>  \</span><br><span class="line">--port 37914</span><br></pre></td></tr></table></figure>

<p>第一次执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; python web_demo.py --model_name <span class="string">&quot;deepseek-ai/deepseek-vl2-tiny&quot;</span>  --port 37914</span><br><span class="line">Python version is above 3.10, patching the collections module.</span><br><span class="line">C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torchvision\io\image.py:13: UserWarning: Failed to load image Python extension: <span class="string">&#x27;[WinError 127] 找不到指定的程序。&#x27;</span>If you don<span class="string">&#x27;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?</span></span><br><span class="line"><span class="string">  warn(</span></span><br><span class="line"><span class="string">WARNING[XFORMERS]: xFormers can&#x27;</span>t load C++/CUDA extensions. xFormers was built <span class="keyword">for</span>:</span><br><span class="line">    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.6.0+cpu)</span><br><span class="line">    Python  3.10.11 (you have 3.10.11)</span><br><span class="line">  Please reinstall xformers (see https://github.com/facebookresearch/xformers<span class="comment">#installing-xformers)</span></span><br><span class="line">  Memory-efficient attention, SwiGLU, sparse and more won<span class="string">&#x27;t be available.</span></span><br><span class="line"><span class="string">  Set XFORMERS_MORE_DETAILS=1 for more details</span></span><br><span class="line"><span class="string">deepseek-ai/deepseek-vl2-tiny is loading...</span></span><br><span class="line"><span class="string">C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\huggingface_hub\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.</span></span><br><span class="line"><span class="string">  warnings.warn(</span></span><br><span class="line"><span class="string">tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 165k/165k [00:00&lt;00:00, 412kB/s]</span></span><br><span class="line"><span class="string">tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.27M/6.27M [00:01&lt;00:00, 6.26MB/s]</span></span><br><span class="line"><span class="string">special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:00&lt;?, ?B/s]</span></span><br><span class="line"><span class="string">Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</span></span><br><span class="line"><span class="string">processor_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.23k/1.23k [00:00&lt;?, ?B/s]</span></span><br><span class="line"><span class="string">Add pad token = [&#x27;</span>&lt;｜▁pad▁｜&gt;<span class="string">&#x27;] to the tokenizer</span></span><br><span class="line"><span class="string">&lt;｜▁pad▁｜&gt;:2</span></span><br><span class="line"><span class="string">Add image token = [&#x27;</span>&lt;image&gt;<span class="string">&#x27;] to the tokenizer</span></span><br><span class="line"><span class="string">&lt;image&gt;:128815</span></span><br><span class="line"><span class="string">Add grounding-related tokens = [&#x27;</span>&lt;|ref|&gt;<span class="string">&#x27;, &#x27;</span>&lt;|/ref|&gt;<span class="string">&#x27;, &#x27;</span>&lt;|det|&gt;<span class="string">&#x27;, &#x27;</span>&lt;|/det|&gt;<span class="string">&#x27;, &#x27;</span>&lt;|grounding|&gt;<span class="string">&#x27;] to the tokenizer with input_ids</span></span><br><span class="line"><span class="string">&lt;|ref|&gt;:128816</span></span><br><span class="line"><span class="string">&lt;|/ref|&gt;:128817</span></span><br><span class="line"><span class="string">&lt;|det|&gt;:128818</span></span><br><span class="line"><span class="string">&lt;|/det|&gt;:128819</span></span><br><span class="line"><span class="string">&lt;|grounding|&gt;:128820</span></span><br><span class="line"><span class="string">Add chat tokens = [&#x27;</span>&lt;|User|&gt;<span class="string">&#x27;, &#x27;</span>&lt;|Assistant|&gt;<span class="string">&#x27;] to the tokenizer with input_ids</span></span><br><span class="line"><span class="string">&lt;|User|&gt;:128821</span></span><br><span class="line"><span class="string">&lt;|Assistant|&gt;:128822</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.29k/2.29k [00:00&lt;00:00, 2.29MB/s]</span></span><br><span class="line"><span class="string">model.safetensors.index.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 247k/247k [00:00&lt;00:00, 5.26MB/s]</span></span><br><span class="line"><span class="string">Downloading shards:   0%|                                                                                                                                                                                                                                                                                                                                 | 0/1 [00:00&lt;?, ?it/s]</span></span><br><span class="line"><span class="string">model-00001-of-000001.safetensors:  11%|█████████████████████</span></span><br></pre></td></tr></table></figure>

<p>如果报 cuda 相关的错，类似下面这边，需要下载对应的版本的 <code>torch</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 662, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    demo = build_demo(args)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 471, <span class="keyword">in</span> build_demo</span><br><span class="line">    fetch_model(args.model_name)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 143, <span class="keyword">in</span> fetch_model</span><br><span class="line">    DEPLOY_MODELS[model_name] = load_model(model_path, dtype=dtype)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\deepseek_vl2\serve\inference.py&quot;</span>, line 44, <span class="keyword">in</span> load_model</span><br><span class="line">    vl_gpt = vl_gpt.cuda().<span class="built_in">eval</span>()</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\modeling_utils.py&quot;</span>, line 2528, <span class="keyword">in</span> cuda</span><br><span class="line">    <span class="built_in">return</span> super().cuda(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 1053, <span class="keyword">in</span> cuda</span><br><span class="line">    <span class="built_in">return</span> self._apply(lambda t: t.cuda(device))</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 903, <span class="keyword">in</span> _apply</span><br><span class="line">    module._apply(fn)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 903, <span class="keyword">in</span> _apply</span><br><span class="line">    module._apply(fn)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 903, <span class="keyword">in</span> _apply</span><br><span class="line">    module._apply(fn)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 930, <span class="keyword">in</span> _apply</span><br><span class="line">    param_applied = fn(param)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line 1053, <span class="keyword">in</span> &lt;lambda&gt;</span><br><span class="line">    <span class="built_in">return</span> self._apply(lambda t: t.cuda(device))</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\cuda\__init__.py&quot;</span>, line 310, <span class="keyword">in</span> _lazy_init</span><br><span class="line">    raise AssertionError(<span class="string">&quot;Torch not compiled with CUDA enabled&quot;</span>)</span><br><span class="line">AssertionError: Torch not compiled with CUDA enabled</span><br><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; </span><br></pre></td></tr></table></figure>

<p>安照提示下载对应的版本</p>
<p>先卸载，在安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; pip uninstall torch torchvision torchaudio</span><br><span class="line">&gt;&gt; pip install torch==2.6.0+cu124  torchvision torchaudio      --index-url https://download.pytorch.org/whl/cu124</span><br></pre></td></tr></table></figure>

<p>再次运行，会报文件不存在的报错。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; python web_demo.py --model_name <span class="string">&quot;deepseek-ai/deepseek-vl2-tiny&quot;</span>  --port 37914</span><br><span class="line">Python version is above 3.10, patching the collections module.</span><br><span class="line">A matching Triton is not available, some optimizations will not be enabled</span><br><span class="line">。。。。。。。。。。。。。。。。。。。。。。</span><br><span class="line"></span><br><span class="line">Load deepseek-ai/deepseek-vl2-tiny successfully...</span><br><span class="line">IMPORTANT: You are using gradio version 3.48.0, however version 4.44.1 is available, please upgrade.</span><br><span class="line">--------</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 662, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    demo = build_demo(args)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 582, <span class="keyword">in</span> build_demo</span><br><span class="line">    examples=format_examples(examples_list),</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\web_demo.py&quot;</span>, line 577, <span class="keyword">in</span> format_examples</span><br><span class="line">    examples.append([images, display_example(images), texts])</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2\deepseek_vl2\serve\app_modules\utils.py&quot;</span>, line 319, <span class="keyword">in</span> display_example</span><br><span class="line">    image = Image.open(img_path)</span><br><span class="line">  File <span class="string">&quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py&quot;</span>, line 3431, <span class="keyword">in</span> open</span><br><span class="line">    fp = builtins.open(filename, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">FileNotFoundError: [Errno 2] No such file or directory: <span class="string">&#x27;C:\\Users\\Administrator\\Documents\\GitHub\\DeepSeek-VL2\\images\\mi_2.jpeg&#x27;</span></span><br></pre></td></tr></table></figure>

<p>找到对应的 Demo 文件，发现路径不对，需要修改一下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># multi-images</span></span><br><span class="line">    [</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;images/multi_image_1.jpeg&quot;</span>,</span><br><span class="line">            <span class="string">&quot;images/mi_2.jpeg&quot;</span>,</span><br><span class="line">            <span class="string">&quot;images/mi_3.jpeg&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;能帮我用这几个食材做一道菜吗?&quot;</span>,</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>

<p>更正为：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># multi-images</span></span><br><span class="line">    [</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;images/multi_image_1.jpeg&quot;</span>,</span><br><span class="line">            <span class="string">&quot;images/multi_image_2.jpeg&quot;</span>,</span><br><span class="line">            <span class="string">&quot;images/multi_image_3.jpeg&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;能帮我用这几个食材做一道菜吗?&quot;</span>,</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>

<p>重新运行，面板启动了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\Administrator\Documents\GitHub\DeepSeek-VL2&gt; python web_demo.py --model_name <span class="string">&quot;deepseek-ai/deepseek-vl2-tiny&quot;</span>  --port 37914</span><br><span class="line">.............................</span><br><span class="line">Load deepseek-ai/deepseek-vl2-tiny successfully...</span><br><span class="line">IMPORTANT: You are using gradio version 3.48.0, however version 4.44.1 is available, please upgrade.</span><br><span class="line">--------</span><br><span class="line">Reloading javascript...</span><br><span class="line">Running on <span class="built_in">local</span> URL:  http://0.0.0.0:37914</span><br><span class="line">Running on public URL: https://55c3f30e0730a00cc1.gradio.live</span><br><span class="line"></span><br><span class="line">This share link expires <span class="keyword">in</span> 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)</span><br></pre></td></tr></table></figure>

<p>浏览器访问</p>
<p><img src="https://i-blog.csdnimg.cn/direct/fa95805675384eb4913fb785f8f0d454.png" alt="在这里插入图片描述"></p>
<p>用一个 Demo 试一下，上传一张图片，找出后面的长颈鹿</p>
<p><img src="https://i-blog.csdnimg.cn/direct/ed962478594e43b6a1bdce26da9b233c.png" alt="在这里插入图片描述"></p>
<p>相对来说时间蛮快的，关于 deepseek 的大模型基本认知分析到这里，我的机器配置，Windows 11 + RTX 3060 12G + i7-12700 + 64G</p>
<h2 id="博文部分内容参考"><a href="#博文部分内容参考" class="headerlink" title="博文部分内容参考"></a>博文部分内容参考</h2><p>© 文中涉及参考链接内容版权归原作者所有，如有侵权请告知 :)</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/">https://github.com/deepseek-ai/</a></p>
<hr>
<p>© 2018-至今 <a href="mailto:&#108;&#105;&#x72;&#x75;&#105;&#108;&#x6f;&#x6e;&#103;&#101;&#114;&#64;&#x67;&#x6d;&#x61;&#105;&#108;&#46;&#x63;&#x6f;&#109;">&#108;&#105;&#x72;&#x75;&#105;&#108;&#x6f;&#x6e;&#103;&#101;&#114;&#64;&#x67;&#x6d;&#x61;&#105;&#108;&#46;&#x63;&#x6f;&#109;</a>, 保持署名-非商用-相同方式共享(CC BY-NC-SA 4.0)</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>DeepSeek 大模型基本认知(V3、R1、Janus、VL2 简单介绍以及本地部署)</p><p><a href="https://liruilongs.github.io/2025/02/02/待发布/DeepSeek 大模型基本认知(V3、R1、Janus、VL2 简单介绍以及本地部署)/">https://liruilongs.github.io/2025/02/02/待发布/DeepSeek 大模型基本认知(V3、R1、Janus、VL2 简单介绍以及本地部署)/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://liruilongs.github.io"><p>山河已无恙</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-02-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-02-04</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 推荐文章</span><br><span>  1.<a class="is-size-6" href="/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" target="_blank">《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记</a><br></span><span>  2.<a class="is-size-6" href="/2023/06/17/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/AdaFace%EF%BC%9A-%E9%80%9A%E8%BF%87AdaFace%E5%AE%9E%E7%8E%B0%E4%BD%8E%E8%B4%A8%E9%87%8F%E9%9D%A2%E9%83%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%B2%BE%E5%87%86%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" target="_blank">AdaFace(CVPR(2022))：通过AdaFace实现低质量面部数据集的人脸识别</a><br></span><span>  3.<a class="is-size-6" href="/2023/06/15/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/Nvidia%203060%20%E6%98%BE%E5%8D%A1%20CUDA%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Ubuntu22.04+Nvidia%20510+Cuda11.6+cudnn8.8)/" target="_blank">Nvidia 3060 显卡 CUDA 环境搭建(Ubuntu22.04+Nvidia 510+Cuda11.6+cudnn8.8)</a><br></span><span>  4.<a class="is-size-6" href="/2023/05/04/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/DeepFace%EF%BC%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%BA%93%20DeepFace%20%E7%AE%80%E5%8D%95%E8%AE%A4%E7%9F%A5/" target="_blank">DeepFace：人脸识别库 DeepFace 简单认知</a><br></span><span>  5.<a class="is-size-6" href="/2023/12/19/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/Stable-Diffusion-Windows%E9%83%A8%E7%BD%B2%E7%AE%80%E7%AD%94%E8%AE%A4%E7%9F%A5/" target="_blank">Stable Diffusion 简单认知 Windows 部署</a><br></span><span>  6.<a class="is-size-6" href="/2023/07/24/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/%E4%BD%BF%E7%94%A8-OpenCV-%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E5%BA%A6%E6%A3%80%E6%B5%8B-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E6%96%B9%E5%B7%AE%E6%96%B9%E6%B3%95/" target="_blank">使用 OpenCV 进行图像模糊度检测(拉普拉斯方差方法)</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay%EF%BF%A5.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat%EF%BF%A5.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/02/06/%E5%BE%85%E5%8F%91%E5%B8%83/SpringBoot%20%E6%8E%A5%E5%8F%A3%E5%86%85%E5%AE%B9%E5%8A%A0%E5%AF%86%E6%96%B9%E6%A1%88(RSA+AES+HMAC%E6%A0%A1%E9%AA%8C)%E8%AE%A4%E7%9F%A5/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">SpringBoot 接口内容加密方案(RSA+AES+HMAC校验)认知</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2025/01/26/%E5%BE%85%E5%8F%91%E5%B8%83/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%9C%AC%E6%B5%81%E5%A6%82%E4%BD%95%E6%8C%81%E7%BB%AD%E5%90%90%E5%88%B0%E5%89%8D%E7%AB%AF%EF%BC%8CBS%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1%E7%9A%84%E6%8A%80%E6%9C%AF%20SSE(Server-Sent%20Events)%20%E8%AE%A4%E7%9F%A5/"><span class="level-item">AI大模型的文本流如何持续吐到前端，服务端实时通信技术 SSE(Server-Sent Events) 认知</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: 'c9c706b72f139354d8cf61c5158442da',
            repo: 'blog_comment',
            owner: 'LIRUILONGS',
            clientID: '9fdc9739266d48d5f62e',
            clientSecret: 'c1cc33697d099a2197650ec9dadcb16bd4904655',
            admin: ["LIRUILONGS"],
            createIssueManually: true,
            distractionFreeMode: true,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex is-mobile" href="#写在前面"><span class="mr-2">1</span><span>写在前面</span></a></li><li><a class="is-flex is-mobile" href="#DeepSeek-V3-系列"><span class="mr-2">2</span><span>DeepSeek-V3 系列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#在线体验"><span class="mr-2">2.1</span><span>在线体验</span></a></li><li><a class="is-flex is-mobile" href="#本地部署算力要求"><span class="mr-2">2.2</span><span>本地部署算力要求</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#DeepSeek-R1-系列"><span class="mr-2">3</span><span>DeepSeek-R1 系列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#在线体验-1"><span class="mr-2">3.1</span><span>在线体验</span></a></li><li><a class="is-flex is-mobile" href="#本地部署"><span class="mr-2">3.2</span><span>本地部署</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#Janus-系列"><span class="mr-2">4</span><span>Janus 系列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#在线体验-2"><span class="mr-2">4.1</span><span>在线体验</span></a></li><li><a class="is-flex is-mobile" href="#本地部署问题解决"><span class="mr-2">4.2</span><span>本地部署问题解决</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#GPU-修改"><span class="mr-2">4.2.1</span><span>GPU 修改</span></a></li><li><a class="is-flex is-mobile" href="#CPU-修改"><span class="mr-2">4.2.2</span><span>CPU 修改</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#DeepSeek-VL2-系列"><span class="mr-2">5</span><span>DeepSeek-VL2 系列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#本地部署-1"><span class="mr-2">5.1</span><span>本地部署</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#博文部分内容参考"><span class="mr-2">6</span><span>博文部分内容参考</span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class=""><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7.jpg" alt="山河已无恙"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">山河已无恙</p><p class="is-size-6 is-block">爱自己，是终生浪漫的开始</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国·呼和浩特</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">439</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">144</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">191</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/LIRUILONGS"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="https://liruilong.blog.csdn.net/"><i class="fa fa-code"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:1224965096@qq.com"><i class="fa fa-envelope"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://liruilong.blog.csdn.net/?t=1&amp;type=blog" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">liruilong.blog.csdn.net</span></span></a></li><li><a class="level is-mobile" href="https://www.cnblogs.com/liruilong/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">博客园</span></span><span class="level-right"><span class="level-item tag">www.cnblogs.com</span></span></a></li><li><a class="level is-mobile" href="https://github.com/LIRUILONGS" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Githup</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://gitee.com/liruilonger" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">码云</span></span><span class="level-right"><span class="level-item tag">gitee.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-13T14:50:54.000Z">2025-04-13</time></p><p class="title"><a href="/2025/04/13/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%B0%B7%E6%AD%8C68%E9%A1%B5%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E5%AF%86%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%A6%82%E4%BD%95%E9%87%8D%E5%A1%91AI%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91/">谷歌68页白皮书解密：提示工程如何重塑AI交互逻辑</a></p><p class="categories"><a href="/categories/LLM/">LLM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-11T11:38:12.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%E5%BE%85%E5%8F%91%E5%B8%83/Linux%20%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E5%85%A8%E9%9D%A2%E7%9B%91%E6%8E%A7/">Linux 系统内存监控：Linux 内存调优之系统内存全面监控</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-11T11:38:12.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%E5%BE%85%E5%8F%91%E5%B8%83/Linux-%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%EF%BC%9ALinux-%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E6%B7%B1%E5%BA%A6%E7%9B%91%E6%8E%A7/">Linux 进程内存监控：Linux 内存调优之进程内存深度监控</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-07T23:32:10.000Z">2025-04-08</time></p><p class="title"><a href="/2025/04/08/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%AE%A4%E8%AF%86%20Linux%20%E5%86%85%E5%AD%98%E6%9E%84%E6%88%90%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E4%B8%8E%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98/">认识 Linux 内存构成：Linux 内存调优之虚拟内存与物理内存</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-06T23:32:10.000Z">2025-04-07</time></p><p class="title"><a href="/2025/04/07/%E5%BE%85%E5%8F%91%E5%B8%83/Linux%20%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8BCPU%E8%B0%83%E4%BC%98%E8%AE%A4%E7%9F%A5/">Linux 性能调优之CPU调优认知</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AdaFace/"><span class="level-start"><span class="level-item">AdaFace</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ajax/"><span class="level-start"><span class="level-item">Ajax</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ansible/"><span class="level-start"><span class="level-item">Ansible</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AppCube/"><span class="level-start"><span class="level-item">AppCube</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/BPF/"><span class="level-start"><span class="level-item">BPF</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Bind9/"><span class="level-start"><span class="level-item">Bind9</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CI-CD/"><span class="level-start"><span class="level-item">CI/CD</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ceph/"><span class="level-start"><span class="level-item">Ceph</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Kubernetes/"><span class="tag">Kubernetes</span><span class="tag is-grey-lightest">98</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag is-grey-lightest">55</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ansible/"><span class="tag">Ansible</span><span class="tag is-grey-lightest">25</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ceph/"><span class="tag">Ceph</span><span class="tag is-grey-lightest">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JAVA/"><span class="tag">JAVA</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%8E%E4%B8%BA%E4%BA%91/"><span class="tag">华为云</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mysql/"><span class="tag">Mysql</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BPF/"><span class="tag">BPF</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenShift/"><span class="tag">OpenShift</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"><span class="tag">程序人生</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNS/"><span class="tag">DNS</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OKD/"><span class="tag">OKD</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%91%84%E5%BD%B1%E6%9B%9D%E5%85%89/"><span class="tag">摄影曝光</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/selenium/"><span class="tag">selenium</span><span class="tag is-grey-lightest">4</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a><p class="size-small"><span>&copy; 2025 山河已无恙</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© <a href="http://www.beian.miit.gov.cn/" target="_blank">备案中</a><br></span><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2021/6/26 21:27:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>