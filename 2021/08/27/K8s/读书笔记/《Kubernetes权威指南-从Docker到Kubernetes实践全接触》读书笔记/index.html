<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="google-adsense-account" content="ca-pub-5805170532312625"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记 - 山河已无恙</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="山河已无恙"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="山河已无恙"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧        ——赫尔曼·黑塞《德米安》"><meta property="og:type" content="blog"><meta property="og:title" content="山河已无恙"><meta property="og:url" content="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd"><meta property="og:site_name" content="山河已无恙"><meta property="og:description" content="对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧        ——赫尔曼·黑塞《德米安》"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mp.weixin.qq.com/img/头像.jpg"><meta property="article:published_time" content="2021-08-27T11:14:35.000Z"><meta property="article:modified_time" content="2023-06-21T11:25:59.079Z"><meta property="article:author" content="LIRUILONGS"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Docker"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/头像.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://liruilongs.github.io/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},"headline":"山河已无恙","image":["https://img-blog.csdnimg.cn/2d9e7e7523af4399b773e2fa61cca095.png","https://img-blog.csdnimg.cn/92bcd18c1e1d45b894c798a1ee66856d.png","https://img-blog.csdnimg.cn/f63d1b9f0db147f598d8e3b5eae1933c.png","https://img-blog.csdnimg.cn/03f58f40be0a4d3295b6722a07003e8b.png","https://img-blog.csdnimg.cn/ac42ec0d6d414773926177142f008a8e.png","https://img-blog.csdnimg.cn/a548d8af45da46808f33d303e2d3d9ef.png","https://img-blog.csdnimg.cn/cad706c5f70646f78855c51256174b64.png","https://img-blog.csdnimg.cn/9a01ebbbdcd645f28f09083f85d34e59.png","https://img-blog.csdnimg.cn/8aaf37331ff4433a9fd59bab6085fd1c.png","https://img-blog.csdnimg.cn/a75a5340152e491b98e429b336a38fec.png","https://img-blog.csdnimg.cn/b94176e1e73f4bc194ef27fbefab55dc.png","https://img-blog.csdnimg.cn/392c0879011a4819b4ea3dc3f97eb5b5.png","https://img-blog.csdnimg.cn/406f766b5b144b70a0fcf4daf4d142ea.png","https://img-blog.csdnimg.cn/96fb379fe6d9499da0b85bb1b09d71be.png","https://img-blog.csdnimg.cn/2630a47aea9f41299dca9ced5b2654b8.png","https://img-blog.csdnimg.cn/e7a34c8d752c4177a319240ff356274a.png","https://img-blog.csdnimg.cn/5de69263cac44aa798dd1c1e99476ee0.png"],"datePublished":"2021-08-27T11:14:35.000Z","dateModified":"2023-06-21T11:25:59.079Z","author":{"@type":"Person","name":"山河已无恙"},"description":"对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧        ——赫尔曼·黑塞《德米安》"}</script><link rel="canonical" href="https://liruilongs.github.io/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><link rel="alternate" href="/path/to/atom.xml" title="山河已无恙" type="application/atom+xml"><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?3f06f2b732a5b1034c989f74e28d0eea";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">影音</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/self-talking">生活小记</a><a class="navbar-item" href="/message">留言墙</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/liruilonger"><i class="fab fa-git-square fa-1x"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/LIRUILONGS"><i class="fab fa-github fa-1x"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul fa-1x"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search fa-1x"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon fa-1x" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-27  <a class="commentCountImg" href="/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/#comment-container"><span class="display-none-class">9860c87552756116972caa40ec7ebf6e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="9860c87552756116972caa40ec7ebf6e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>4 小时  <i class="fas fa-pencil-alt"> </i>33.6 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记</h1><div class="content"><p><strong><font color="009688">对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧        ——赫尔曼·黑塞《德米安》</font></strong></p>
<span id="more"></span>

<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><ul>
<li>之前简单的了解过，但是机器的原因，只有单机，因为安装Docker的原因，本机VM上的红帽节点起不来了。懂得不多，视频上都是多节点的，所以教学视屏上的所以Demo没法搞。</li>
<li>前些时间公司的一个用K8s搞得项目要做安全测试，结果连服务也停不了。很无力。所以刷这本书，系统学习下。</li>
<li>博客主要是读书笔记。在更新。。。。。。</li>
<li>书很不错,有条件的小伙伴可以支持作者一波</li>
</ul>
<p><strong><font color="009688">对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧        ——赫尔曼·黑塞《德米安》</font></strong></p>
<hr>
<h1 id="第1章Kubernetes入门"><a href="#第1章Kubernetes入门" class="headerlink" title="第1章Kubernetes入门"></a><font color="009688">第1章<code>Kubernetes</code>入门</font></h1><h2 id="1-1-Kubernetes是什么"><a href="#1-1-Kubernetes是什么" class="headerlink" title="1.1 Kubernetes是什么?"></a>1.1 <code>Kubernetes</code>是什么?</h2><p>首先,它是一个全新的<code>基于容器技术的分布式架构</code>领先方案。这个方案虽然还很新,但它是谷歌十几年以来大规模应用容器技术的经验积累和升华的一个重要成果。</p>
<p>使用<code>Kubernetes</code>提供的解决方案,我们不仅节省了不少于30%的开发成本,同时可以将精力更加集中于<code>业务本身</code>,而且由于<code>Kubernetes</code>提供了强大的自动化机制,所以系统后期的运维难度和运维成本大幅度降低。</p>
<p>Kubermetes平台对现有的编程语言、编程框架、中间件没有任何侵入性,因此现有的系统也很容易改造升级并迁移到<code>Kubernetes</code>平台上。</p>
<p>最后, Kubermetes是一个完备的分布式系统支撑平台。<code>Kubernetes</code>具有完备的集群管理能力,包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制,以及多粒度的资源配额管理能力。</p>
<p>Kubermetes提供了完善的管理工具,这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节</p>
<p><code>Kubernetes</code>是一个全新的<code>基于容器技术</code>的<code>分布式架构解决方案</code>,并且是一个<code>一站式的完备的分布式系统开发和支撑平台</code>。</p>
<blockquote>
<p>Kubermetes的一些基本知识,在Kubermetes 中, Service (服务)是分布式集群架构的核心,一个Service对象拥有如下关键特征。</p>
</blockquote>
<table>
<thead>
<tr>
<th>关键特征</th>
</tr>
</thead>
<tbody><tr>
<td>拥有一个唯一指定的名字(比如mysgq-server).</td>
</tr>
<tr>
<td>拥有一个虚拟IP (Cluster IP, Service IP或VIP)和端口号。</td>
</tr>
<tr>
<td>能够提供某种远程服务能力。</td>
</tr>
<tr>
<td>被映射到了提供这种服务能力的一组容器应用上。</td>
</tr>
</tbody></table>
<p>Kubemetes能够让我们通过Service (虚拟Cluster IP +Service Port)连接到指定的Service上。有了<code>Kubernetes</code>内建的<code>透明负载均衡</code>和<code>故障恢复机制</code>,不管后端有多少服务进程,也不管某个服务进程是否会由于发生故障而重新部署到其他机器,都不会影响到我们对服务的正常调用。</p>
<p>容器提供了强大的隔离功能，所以有必要把为 Service 提供服务的这组进程放入容器中进行隔离。为此， Kubemetes 设计了<code>Pod</code> 对象，将每个服务进程包装到相应的<code>Pod</code>中，使其成为<code> Pod</code>中运行的<code>一个容器</code>( Container )。</p>
<p>为了建立 Service &amp;&amp;Pod 间的关联关系， Kubemetes 首先给每Pod 贴上 个标签(Label),类似于html中，给元素定义属性。然后给相应的 <code>Service </code>定义标签选择器( Label Selector )，比如 MySQL Service 的标签选择器的选择条件为 name&#x3D;mysql ，意为该 Service 要作用于所有包含 name&#x3D;mysql的<br>Label Pod 这样 来，就巧妙地解决了 Service Pod 的关联问题</p>
<blockquote>
<p>到 <code>Pod </code>，我们这里先简单说说其概念：</p>
</blockquote>
<table>
<thead>
<tr>
<th>Pod概念</th>
</tr>
</thead>
<tbody><tr>
<td><code>Pod</code> 运行在一个我们称之为节点<code>(Node)</code>的环境中，这个节点既可以是<code>物理机</code>，也可以是<code>私有云</code>或者<code>公有云中的虚拟机</code>，通常在一个节点上运行几百个<code> Pod</code> ：</td>
</tr>
<tr>
<td>每个 <code>Pod</code> 里运行着 个特殊的被称之为 <code>Pause</code> 的容器，其他容器则为<code>业务容器</code>，这些<code>业务容器共享</code> Pause <code>容器</code>的<code>网络栈</code>和<code> Volume 挂载卷</code>因此它们之间的通信和数据交换更为高效，在设计时我们可以充分利用这特性将一组密切相关的服务进程放入同一 Pod 中。</td>
</tr>
<tr>
<td>并不是每个 Pod 和它里面运行的容器都能“映射”到Service 上，只有那些提供服务(无论是对内还是对外)的 Pod 才会被“映射”成服务。</td>
</tr>
</tbody></table>
<blockquote>
<p>在<code>集群管理</code>方面， Kubemetes 将集群中的机器划分为<code> Master节点</code>和一群<code>工作节点(Node)</code></p>
</blockquote>
<table>
<thead>
<tr>
<th>集群管理</th>
</tr>
</thead>
<tbody><tr>
<td>在<code> Master 节点</code>上运行着集群管理相关的组进程 <code>kube-apiserver </code>,<code>kube-controller-manager</code>,<code>kube-scheduler</code> ，这些进程实现了整个集群的资源管理、 Pod 调度、弹性伸缩、安全控制、系统监控和纠错等管理功能，且都是全自动完成的。</td>
</tr>
<tr>
<td>Node 作为集群中的工作节点，运行真正的应用程序，在 Node上 Kubemetes 管理的最小运行单元是 Pod ，Node 上运行着 Kubemetes的<code>kubelet</code>, <code>kube-proxy</code> 服务进程，这些服务进<code>程负责 Pod 的创建、启动、监控、重启、销毁，以及实现软件模式的负载均衡器。</code></td>
</tr>
</tbody></table>
<blockquote>
<p>传统的 IT 系统中<code>服务扩容</code>和<code>服务升级</code>这两个难题在k8s中的解决</p>
</blockquote>
<p>Kubemetes 集群中，你只需为需要扩容的 Service 关联的 Pod 创建一个 RC(Replication Conoiler )，则该 Service 的扩容以至于后来的 Service 升级等头疼问题都迎刃而解 .</p>
<blockquote>
<p>RC定义文件中包括以下 3 个关键信息。</p>
</blockquote>
<table>
<thead>
<tr>
<th>RC定义文件</th>
</tr>
</thead>
<tbody><tr>
<td>目标 Pod 的定义</td>
</tr>
<tr>
<td>目标 Pod 需要运行的副本数量(Replicas )。</td>
</tr>
<tr>
<td>要监控的目标 Pod 的标签( Label)</td>
</tr>
</tbody></table>
<blockquote>
<p>在创建好RC (系统将自动创建好Pod)后, Kubernetes会通过RC中定义的Label筛选出对应的Pod实例并实时监控其状态和数量,如果实例数量少于定义的副本数量(Replicas),则·会根据RC中定义的Pod模板来创建一个新的Pod,然后将此Pod调度到合适的Node上启动运行,直到Pod实例的数量达到预定目标。这个过程完全是自动化的,. 服务的扩容就变成了一个纯粹的简单数字游戏了，只要修改 RC 中的副本数量即可。后续的Service 升级也将通过修改 RC 来自动完成。</p>
</blockquote>
<h2 id="1-2-为什么要用-Kubernetes"><a href="#1-2-为什么要用-Kubernetes" class="headerlink" title="1.2 为什么要用 Kubernetes"></a>1.2 为什么要用 Kubernetes</h2><p>使用 Kubemetes 的理由很多，最根本的一个理由就是： IT 从来都是 个由新技术驱动的行业。</p>
<p>Kubemetes 作为当前唯一被业界广泛认可和看好的Docker 分布式系统解决方案，</p>
<blockquote>
<p>使用了 Kubemetes 又会收获哪些好处呢？</p>
</blockquote>
<table>
<thead>
<tr>
<th>Kubemetes好處</th>
</tr>
</thead>
<tbody><tr>
<td>在采用Kubemetes 解决方案之后，只需个1精悍的小团队就能轻松应对</td>
</tr>
<tr>
<td>使用 Kubemetes 就是在全面拥抱微服务架构。微服务架构的核心是将 个巨大的单体应用分解为很多小的互相连接的微服务，一个微服务背后可能有多个实例副本在支撑，副本的数量可能会随着系统的负荷变化而进行调整，内嵌的负载均衡器在这里发挥了重要作用</td>
</tr>
<tr>
<td>系统可以随时随地整体“搬迁”到公有云上。</td>
</tr>
<tr>
<td>Kubemetes 系统架构具备了超强的横向扩容能力。利用 <code>ubemetes</code> 提供的工具，甚至可以在线完成集群扩容 只要我们的微服务设计得好，结合硬件或者公有云资源的线性增加，系统就能够承受大 用户并发访问所带来的巨大压力。</td>
</tr>
</tbody></table>
<h2 id="1-3-从一个简单的例子开始"><a href="#1-3-从一个简单的例子开始" class="headerlink" title="1.3 从一个简单的例子开始"></a><font color=red>1.3 从一个简单的例子开始</font></h2><p>Java Web 应用的结构比较简单，是一个运行在 Tomcat 里的 Web App。</p>
<p>此应用需要启动两个容器: Web App容器和MySQL容器,并且Web App容器需要访问MySQL容器。</p>
<blockquote>
<p>在Docker时代,假设我们在一个宿主机上启动了这两个容器,<code>则我们需要把MySQL容器的IP地址通过环境变量的方式注入Web App容器里</code>;同时,<code>需要将Web App容器的8080端口映射到宿主机的8080端口</code>,以便能在外部访问。</p>
</blockquote>
<blockquote>
<p>在Kubernetes时代是如何完成这个目标的。 </p>
</blockquote>
<h3 id="1-3-1环境准备"><a href="#1-3-1环境准备" class="headerlink" title="1.3.1环境准备"></a><font color=amber>1.3.1环境准备</font></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭CentoS自带的防火墙服务:</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld --now</span><br><span class="line">systemctl status firewalld</span><br><span class="line"><span class="comment"># 安装etcd和Kubernetes软件(会自动安装Docker软件): </span></span><br><span class="line">yum install -y etcd kubernetes</span><br><span class="line"><span class="comment">#按顺序启动所有的服务:</span></span><br><span class="line">systemctl start etcd </span><br><span class="line">systemctl start docker </span><br><span class="line">systemctl start kube-apiserver </span><br><span class="line">systemctl start kube-controller-manager </span><br><span class="line">systemctl start kube-scheduler </span><br><span class="line">systemctl start kubelet </span><br><span class="line">systemctl start kube-proxy</span><br><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">systemctl status etcd docker kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>至此,一个单机版的Kubernetes集群环境就安装启动完成了。接下来,我们可以在这个单机版的Kubernetes集群中上手练习了。 </p>
<p>书里镜像相关地址： <a target="_blank" rel="noopener" href="https://hub.docker.com/u/kubeguide/">https://hub.docker.com/u/kubeguide/</a>.</p>
<h3 id="1-3-2启动MySQL服务"><a href="#1-3-2启动MySQL服务" class="headerlink" title="1.3.2启动MySQL服务"></a><font color=chocolate>1.3.2启动MySQL服务</font></h3><blockquote>
<p>首先为MySQL服务创建一个<code>RC</code>定义文件:<code> mysql-rc.yaml</code>,文件的完整内容和解释;</p>
</blockquote>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span> <span class="comment">#副本控制器RC</span></span><br><span class="line"><span class="attr">metadata:</span>                   <span class="comment"># RC的名称,全局唯一</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span>               <span class="comment"># Pod副本期待数量</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span>                  <span class="comment"># 符合目标的Pod拥有此标签</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span>               <span class="comment"># 根据此模板创建Pod的副本(实例).</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span>                 <span class="comment">#Pod副本拥有的标签,对应RC的Selector</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span>                    <span class="comment"># Pod内容器的定义部分</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span>                <span class="comment"># 容器的名称,容器对应的Docker Image</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">mysql</span></span><br><span class="line">          <span class="attr">ports:</span>                     <span class="comment">#容器应用监听的端口号</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">          <span class="attr">env:</span>                       <span class="comment">#注入容器内的环境变量</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;123456&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/72e6190dbb3c44f5b0346e25645734a2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<blockquote>
<p><code>yaml</code>定义文件中</p>
</blockquote>
<table>
<thead>
<tr>
<th><code>yaml</code>定义文件</th>
</tr>
</thead>
<tbody><tr>
<td><code>kind属性</code>,用来表明此资源对象的类型,比如这里的值为”ReplicationController”,表示这是一个RC:</td>
</tr>
<tr>
<td><code>spec一节</code>中是RC的相关属性定义,比如<code>spec.selector是RC的Pod标签(Label)选择器</code>,即监控和管理拥有这些标签的Pod实例,确保当前集群上始终<code>有且仅有replicas个Pod实例在运行</code>,这里我们设置<code>replicas=1</code>表示只能运行一个MySQL Pod实例。</td>
</tr>
<tr>
<td>当集群中运行的<code>Pod数量</code>小于<code>replicas</code>时, RC会根据<code>spec.template</code>一节中定义的<code>Pod</code>模板来生成一个新的<code>Pod</code>实例, <code>spec.template.metadata.labels</code>指定了该<code>Pod</code>的标签.</td>
</tr>
<tr>
<td>需要特别注意的是:这里的<code>labels必须匹配之前的spec.selector</code>,否则此<code>RC每次创建了一个无法匹配Label的Pod</code>,就会不停地<code>尝试创建新的Pod</code>。</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># kubectl create -f mysql-rc.yaml</span></span><br><span class="line">replicationcontroller <span class="string">&quot;mysql&quot;</span> created</span><br><span class="line">E:\docker&gt;ssh  root@39.97.241.18</span><br><span class="line">Last login: Sun Aug 29 13:00:58 2021 from 121.56.4.34</span><br><span class="line"></span><br><span class="line">Welcome to Alibaba Cloud Elastic Compute Service !</span><br><span class="line"></span><br><span class="line">^[[AHow would you spend your life?.I don t know, but I will cherish every minute to live.</span><br><span class="line">[root@liruilong ~]<span class="comment"># kubectl  get rc</span></span><br><span class="line">NAME      DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql     1         1         1         1d</span><br><span class="line">[root@liruilong ~]<span class="comment"># kubectl  get pods</span></span><br><span class="line">NAME          READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-q7802   1/1       Running   0          1d</span><br><span class="line">[root@liruilong ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><font color=purple>嗯，这里刚开始搞得的时候是有问题的，<code>pod</code>一直没办法创建成功，第一次启动容器时，STATUS一直显示CONTAINERCREATING,我用的是阿里云ESC单核2G+40G云盘，我最开始以为系统核数的问题,因为看其他的教程写的需要双核，但是后来发现不是，网上找了解决办法，一顿操作猛如虎，后来不知道怎么就好了。</font></p>
</blockquote>
<ul>
<li>有说基础镜像外网拉不了，只能用 docker Hub的，有说 ，权限的问题，还有说少包的问题，反正都试了，这里列出几个靠谱的解决方案<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/gezilan/article/details/80011905">https://blog.csdn.net/gezilan/article/details/80011905</a></li>
<li><a target="_blank" rel="noopener" href="https://www.freesion.com/article/8438814614/">https://www.freesion.com/article/8438814614/</a></li>
</ul>
</li>
</ul>
<p>K8s 根据mysqlde RC的定义自动创建的Pod。由于Pod的调度和创建需要花费一定的时间,比如需要一定的时间来确定调度到哪个节点上,以及下载Pod里容器的镜像需要一段时间,所以一开始我们看到Pod的状态将显示为<code>Pending</code>。当Pod成功创建完成以后,状态最终会被更新为<code>Running</code>我们通过<code>docker ps</code>指令查看正在运行的容器,发现提供MySQL服务的Pod容器已经创建并正常运行了,此外,你会发现MySQL Pod对应的容器还多创建了一个来自谷歌的<code>pause</code>容器,这就是<code>Pod的“根容器&quot;</code>.</p>
<p>我们创建一个与之关联的<code>Kubernetes Service</code> 的定义文件 <code>mysql-sve.yaml</code></p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span>  <span class="comment"># 表明是Kubernetes Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span>  <span class="comment"># Service的全局唯一名称</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3306</span> <span class="comment">#service提供服务的端口号</span></span><br><span class="line">  <span class="attr">selector:</span>      <span class="comment">#Service对应的Pod拥有这里定义的标签</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br></pre></td></tr></table></figure>

<p>我们通过<code>kubectl create</code>命令创建<code>Service</code>对象。运行kubectl命令:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># kubectl create -f mysql-svc.yaml</span></span><br><span class="line">service <span class="string">&quot;mysql&quot;</span> created</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl  get svc</span></span><br><span class="line">NAME         CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">mysql        10.254.155.86   &lt;none&gt;        3306/TCP   1m</span><br><span class="line">[root@liruilong k8s]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>注意到<code>MySQL</code>服务被分配了一个值为10.254.155.86的<code>Cluster IP</code>地址,这是一个虚地址,随后, <code>Kubernetes集群</code>中其他新创建的<code>Pod</code>就可以通过<code>Service</code>的<code>Cluster IP</code>+端口号<code>3306</code>来连接和访问它了。</p>
<p>在通常情况下, <code>Cluster IP</code>是在Service创建后由<code>Kubernetes</code>系统自动分配的,其他<code>Pod</code>无法预先知道某个<code>Service的Cluster IP地址</code>,因此需要一个<code>服务发现机制</code>来找到<code>这个服</code>务。</p>
<p>为此,最初时, <code>Kubernetes</code>巧妙地使用了<code>Linux</code>环境变量(Environment Variable)来解决这个问题,后面会详细说明其机制。现在我们只需知道,根据<code>Service</code>的唯一名字,容器可以从环境变量中获取到<code>Service对应的Cluster IP地址和端口,从而发起TCP/IP连接请求了</code>。</p>
<h3 id="1-3-3启动Tomcat应用"><a href="#1-3-3启动Tomcat应用" class="headerlink" title="1.3.3启动Tomcat应用"></a><font color=chocolate>1.3.3启动Tomcat应用</font></h3><p>创建对应的 <code>RC </code>文件 <code>myweb-rc.yaml </code></p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span> </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">kubeguide/tomcat-app:v1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span>   </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/26ba99682f974214a2f5ce37b515e2d3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># vim myweb-rc.yaml</span></span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl create -f myweb-rc.yaml</span></span><br><span class="line">replicationcontroller <span class="string">&quot;myweb&quot;</span> created</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get rc</span></span><br><span class="line">NAME      DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql     1         1         1         1d</span><br><span class="line">myweb     2         2         0         20s</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS              RESTARTS   AGE</span><br><span class="line">mysql-q7802   1/1       Running             0          1d</span><br><span class="line">myweb-53r32   0/1       ContainerCreating   0          28s</span><br><span class="line">myweb-609w4   0/1       ContainerCreating   0          28s</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-q7802   1/1       Running   0          1d</span><br><span class="line">myweb-53r32   1/1       Running   0          1m</span><br><span class="line">myweb-609w4   1/1       Running   0          1m</span><br><span class="line">[root@liruilong k8s]<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<p>最后，创建对应的 <code>Service</code> 。以下是完整<code>yaml</code>定义文件 <code>myweb-svc.yaml</code>:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30001</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myweb</span>    </span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/933adef70d3149b7ae61c42a43dc2105.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># vim myweb-svc.yaml</span></span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl create -f  myweb-svc.yaml</span></span><br><span class="line">service <span class="string">&quot;myweb&quot;</span> created</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get services</span></span><br><span class="line">NAME         CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes   10.254.0.1      &lt;none&gt;        443/TCP          2d</span><br><span class="line">mysql        10.254.155.86   &lt;none&gt;        3306/TCP         5h</span><br><span class="line">myweb        10.254.122.63   &lt;nodes&gt;       8080:30001/TCP   54s</span><br><span class="line">[root@liruilong k8s]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<h3 id="1-3-4通过浏览器访问网页"><a href="#1-3-4通过浏览器访问网页" class="headerlink" title="1.3.4通过浏览器访问网页 "></a><font color=purple>1.3.4通过浏览器访问网页 </font></h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]# curl http://127.0.0.1:30001/demo/</span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;</span> <span class="meta-string">&quot;http://www.w3.org/TR/html4/loose.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Content-Type&quot;</span> <span class="attr">content</span>=<span class="string">&quot;text/html; charset=utf-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>HPE University Docker&amp;Kubernetes Learning<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>  <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">h3</span>&gt;</span> Error:com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Could not create connection to database server.<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><font color=orange>数据库连接有问题，这里百度发现是<code>mysql驱动版本</code>问题</font></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># docker logs a05d16ec69ff</span></span><br><span class="line">[root@liruilong k8s]<span class="comment"># vim mysql-rc.yaml</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span> <span class="comment">#副本控制器RC</span></span><br><span class="line"><span class="attr">metadata:</span>                   <span class="comment"># RC的名称,全局唯一</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span>               <span class="comment"># Pod副本期待数量</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span>                  <span class="comment"># 符合目标的Pod拥有此标签</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span>               <span class="comment"># 根据此模板创建Pod的副本(实例).</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span>                 <span class="comment">#Pod副本拥有的标签,对应RC的Selector</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span>                    <span class="comment"># Pod内容器的定义部分</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span>                <span class="comment"># 容器的名称,容器对应的Docker Image</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">mysql:5.7</span></span><br><span class="line">          <span class="attr">ports:</span>                     <span class="comment">#容器应用监听的端口号</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">          <span class="attr">env:</span>                       <span class="comment">#注入容器内的环境变量</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;123456&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># kubectl delete -f mysql-rc.yaml</span></span><br><span class="line">replicationcontroller <span class="string">&quot;mysql&quot;</span> deleted</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl create -f mysql-rc.yaml</span></span><br><span class="line">replicationcontroller <span class="string">&quot;mysql&quot;</span> created</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get rc</span></span><br><span class="line">NAME      DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql     1         1         0         10s</span><br><span class="line">myweb     2         2         2         4h</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS              RESTARTS   AGE</span><br><span class="line">mysql-2cpt9   0/1       ContainerCreating   0          15s</span><br><span class="line">myweb-53r32   1/1       Running             0          4h</span><br><span class="line">myweb-609w4   1/1       Running             1          4h</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS              RESTARTS   AGE</span><br><span class="line">mysql-2cpt9   0/1       ContainerCreating   0          32s</span><br><span class="line">myweb-53r32   1/1       Running             0          4h</span><br><span class="line">myweb-609w4   1/1       Running             1          4h</span><br><span class="line">[root@liruilong k8s]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Digest: sha256:7cf2e7d7ff876f93c8601406a5aa17484e6623875e64e7acc71432ad8e0a3d7e</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> docker.io/mysql:5.7</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-2cpt9   1/1       Running   0          31m</span><br><span class="line">myweb-53r32   1/1       Running   0          5h</span><br><span class="line">myweb-609w4   1/1       Running   1          5h</span><br><span class="line">[root@liruilong k8s]<span class="comment"># curl http://127.0.0.1:30001/demo/</span></span><br></pre></td></tr></table></figure>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;</span> <span class="meta-string">&quot;http://www.w3.org/TR/html4/loose.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Content-Type&quot;</span> <span class="attr">content</span>=<span class="string">&quot;text/html; charset=utf-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>HPE University Docker&amp;Kubernetes Learning<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>  <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">h2</span>&gt;</span>Congratulations!!<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;/<span class="name">br</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Add...&quot;</span> <span class="attr">onclick</span>=<span class="string">&quot;location.href=&#x27;input.html&#x27;&quot;</span> &gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;/<span class="name">br</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TABLE</span> <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>  <span class="attr">border</span>=<span class="string">&quot;1&quot;</span> <span class="attr">width</span>=<span class="string">&quot;600px&quot;</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>Name<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>Level(Score)<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>google<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>docker<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>teacher<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>HPE<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>our team<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">TR</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>me<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TD</span>&gt;</span>100<span class="tag">&lt;/<span class="name">TD</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">TR</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">TABLE</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="1-4-Kubernetes基本概念和术语"><a href="#1-4-Kubernetes基本概念和术语" class="headerlink" title="1.4 Kubernetes基本概念和术语"></a><font color=orange>1.4 Kubernetes基本概念和术语</font></h2><p><code>Kubernetes</code>中的大部分概念如<code>Node</code>, <code>Pod</code>,<code>Replication Controller</code>, <code>Service</code>等都可以看作一种“<code>资源对象</code>”,几乎所有的资源对象都可以通过<code>Kubernetes</code>提供的<code>kubect</code>工具(或者<code>API</code>编程调用)执行增、删、改、查等操作并将其保存在<code>etcd</code>中持久化存储。从这个角度来看,<code> Kubernetes</code>其实是一个<code>高度自动化的资源控制系统</code>,它通过<code>跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。</code></p>
<blockquote>
<p>Kubernetes集群的两种管理角色: <code>Master</code>和<code>Node</code>.</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20210614223114358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nhbmhld3V5YW5n,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-4-1-Master"><a href="#1-4-1-Master" class="headerlink" title="1.4.1 Master"></a><font color=plum>1.4.1 Master</font></h3><p>Kubernetes里的Master指的是<code>集群控制节点</code>,<strong><font color=yellowgreen>每个Kubernetes集群里需要有一个Master节点来负责整个集群的管理和控制,基本上Kubernetes的所有控制命令都发给它,它来负责具体的执行过程,我们后面执行的所有命令基本都是在Master节点上运行的。</font></strong></p>
<p><code>Master节点通常会占据一个独立的服务器</code>(高可用部署建议用3台服务器),其主要原因是它太重要了,是整个集群的“<code>首脑</code>”,如果宕机或者不可用,那么对集群内容器应用的管理都将失效。<code>Master节点上运行着以下一组关键进程。</code></p>
<table>
<thead>
<tr>
<th>Master节点上关键进程</th>
</tr>
</thead>
<tbody><tr>
<td><code>Kubernetes API Server (kube-apiserver)</code>:提供了HTTP Rest接口的关键服务进程,是Kubernetes里所有资源的增、删、改、查等操作的唯一入口,也是集群控制的入口进程。</td>
</tr>
<tr>
<td><code>Kubernetes Controller Manager (kube-controller-manager)</code>: Kubernetes里所有资源对象的自动化控制中心,可以理解为资源对象的“大总管”。</td>
</tr>
<tr>
<td><code>Kubernetes Scheduler (kube-scheduler)</code>:负责资源调度(Pod调度)的进程,相当于公交公司的“调度室”。</td>
</tr>
<tr>
<td>另外,在Master节点上还需要启动一个<code>etcd</code>服务,因为<code>Kubernetes</code>里的所有资源对象的数据全部是保存在<code>etcd</code>中的。</td>
</tr>
</tbody></table>
<blockquote>
<p>除了Master,<font color=purple> Kubernetes集群中的其他机器被称为Node节点</font></p>
</blockquote>
<p>总结一下，我们要操作<code>k8s</code>，在管理节点那我们怎么操作，我们通过<code>kube-apiserver</code>来接受用户的请求，通过<code>kubu-scheduler</code>来负责资源的调度，是使用work1计算节点来处理还是使用work2计算节点来处理，然后在每个节点上要运行一个代理服务kubelet，用来控制每个节点的操作，但是每个节点的状态，是否健康我们不知道，这里我们需要<code>kube-controller-manager</code></p>
<h3 id="1-4-2-Node"><a href="#1-4-2-Node" class="headerlink" title="1.4.2 Node"></a><font color=red>1.4.2 Node</font></h3><p>在较早的版本中也被称为Miniono与Master一样, Node节点可以是一台物理主机,也可以是一台虚拟机。 <strong><font color=plum>Node节点才是Kubermetes集群中的工作负载节点,每个Node都会被Master分配一些工作负载(Docker容器),当某个Node宕机时,其上的工作负载会被Master自动转移到其他节点上去。</font></strong> 每个Node节点上都运行着以下一组关键进程。</p>
<table>
<thead>
<tr>
<th>每个Node节点上都运行关键进程</th>
</tr>
</thead>
<tbody><tr>
<td><code>kubelet</code>:负责Pod对应的容器的创建、启停等任务,同时与Master节点密切协作,实现集群管理的基本功能。</td>
</tr>
<tr>
<td><code>kube-proxy</code>:实现<code>Kubernetes Service</code>的<code>通信与负载均衡机制</code>的重要组件。)</td>
</tr>
<tr>
<td><code>Docker Engine</code> (docker): <code>Docker引擎</code>,负责本机的容器创建和管理工作。</td>
</tr>
</tbody></table>
<p><code>Node节点可以在运行期间动态增加到Kubernetes集群中</code>,前提是这个节点上已经正确安装、配置和启动了上述关键进程,**<font color=seagreen>在默认情况下kubelet会向Master注册自己,这也是Kubernetes推荐的Node管理方式</font>**。</p>
<p>一旦Node被纳入集群管理范围, kubelet进程就会定时向Master节点汇报自身的情报,例如操作系统、Docker版本、机器的CPU和内存情况,以及当前有哪些Pod在运行等,这样Master可以获知每个Node的资源使用情况,并实现高效均衡的资源调度策略。<code>而某个Node超过指定时间不上报信息时,会被Master判定为“失联&quot;, Node的状态被标记为不可用(Not Ready),随后Master会触发“工作负载大转移”的自动流程。</code></p>
<blockquote>
<p>查看集群中的Node节点和节点的详细信息</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">[root@liruilong k8s]<span class="comment"># kubectl  get nodes</span></span><br><span class="line">NAME        STATUS    AGE</span><br><span class="line">127.0.0.1   Ready     2d</span><br><span class="line">[root@liruilong k8s]<span class="comment"># kubectl describe node 127.0.0.1</span></span><br><span class="line"><span class="comment"># Node基本信息:名称、标签、创建时间等。</span></span><br><span class="line">Name:                   127.0.0.1</span><br><span class="line">Role:</span><br><span class="line">Labels:                 beta.kubernetes.io/arch=amd64</span><br><span class="line">                        beta.kubernetes.io/os=linux</span><br><span class="line">                        kubernetes.io/hostname=127.0.0.1</span><br><span class="line">Taints:                 &lt;none&gt;</span><br><span class="line">CreationTimestamp:      Fri, 27 Aug 2021 00:07:09 +0800</span><br><span class="line">Phase:</span><br><span class="line"><span class="comment"># Node当前的运行状态, Node启动以后会做一系列的自检工作:</span></span><br><span class="line"><span class="comment"># 比如磁盘是否满了,如果满了就标注OutODisk=True</span></span><br><span class="line"><span class="comment"># 否则继续检查内存是否不足(如果内存不足,就标注MemoryPressure=True)</span></span><br><span class="line"><span class="comment"># 最后一切正常,就设置为Ready状态(Ready=True)</span></span><br><span class="line"><span class="comment"># 该状态表示Node处于健康状态, Master将可以在其上调度新的任务了(如启动Pod)</span></span><br><span class="line">Conditions:</span><br><span class="line">  Type                  Status  LastHeartbeatTime                       LastTransitionTime                      Reason                          Message</span><br><span class="line">  ----                  ------  -----------------                       ------------------                      ------                          -------</span><br><span class="line">  OutOfDisk             False   Sun, 29 Aug 2021 23:05:53 +0800         Sat, 28 Aug 2021 00:30:35 +0800         KubeletHasSufficientDisk        kubelet has sufficient disk space available</span><br><span class="line">  MemoryPressure        False   Sun, 29 Aug 2021 23:05:53 +0800         Fri, 27 Aug 2021 00:07:09 +0800         KubeletHasSufficientMemory      kubelet has sufficient memory available</span><br><span class="line">  DiskPressure          False   Sun, 29 Aug 2021 23:05:53 +0800         Fri, 27 Aug 2021 00:07:09 +0800         KubeletHasNoDiskPressure        kubelet has no disk pressure</span><br><span class="line">  Ready                 True    Sun, 29 Aug 2021 23:05:53 +0800         Sat, 28 Aug 2021 00:30:35 +0800         KubeletReady                    kubelet is posting ready status</span><br><span class="line"><span class="comment"># Node的主机地址与主机名。</span></span><br><span class="line">Addresses:              127.0.0.1,127.0.0.1,127.0.0.1</span><br><span class="line"><span class="comment"># Node上的资源总量:描述Node可用的系统资源,包括CPU、内存数量、最大可调度Pod数量等,注意到目前Kubernetes已经实验性地支持GPU资源分配了(alpha.kubernetes.io/nvidia-gpu=0)</span></span><br><span class="line">Capacity:</span><br><span class="line"> alpha.kubernetes.io/nvidia-gpu:        0</span><br><span class="line"> cpu:                                   1</span><br><span class="line"> memory:                                1882012Ki</span><br><span class="line"> pods:                                  110</span><br><span class="line"><span class="comment"># Node可分配资源量:描述Node当前可用于分配的资源量。</span></span><br><span class="line">Allocatable:</span><br><span class="line"> alpha.kubernetes.io/nvidia-gpu:        0</span><br><span class="line"> cpu:                                   1</span><br><span class="line"> memory:                                1882012Ki</span><br><span class="line"> pods:                                  110</span><br><span class="line"><span class="comment"># 主机系统信息:包括主机的唯一标识UUID, Linux kernel版本号、操作系统类型与版本、Kubernetes版本号、kubelet与kube-proxy的版本号等。  </span></span><br><span class="line">System Info:</span><br><span class="line"> Machine ID:                    963c2c41b08343f7b063dddac6b2e486</span><br><span class="line"> System UUID:                   EB90EDC4-404C-410B-800F-3C65816C0E2D</span><br><span class="line"> Boot ID:                       4a9349b0-ce4b-4b4a-8766-c5c4256bb80b</span><br><span class="line"> Kernel Version:                3.10.0-1160.15.2.el7.x86_64</span><br><span class="line"> OS Image:                      CentOS Linux 7 (Core)</span><br><span class="line"> Operating System:              linux</span><br><span class="line"> Architecture:                  amd64</span><br><span class="line"> Container Runtime Version:     docker://1.13.1</span><br><span class="line"> Kubelet Version:               v1.5.2</span><br><span class="line"> Kube-Proxy Version:            v1.5.2</span><br><span class="line">ExternalID:                     127.0.0.1</span><br><span class="line"><span class="comment"># 当前正在运行的Pod列表概要信息</span></span><br><span class="line">Non-terminated Pods:            (3 <span class="keyword">in</span> total)</span><br><span class="line">  Namespace                     Name                    CPU Requests    CPU Limits      Memory Requests Memory Limits</span><br><span class="line">  ---------                     ----                    ------------    ----------      --------------- -------------</span><br><span class="line">  default                       mysql-2cpt9             0 (0%)          0 (0%)          0 (0%)          0 (0%)</span><br><span class="line">  default                       myweb-53r32             0 (0%)          0 (0%)          0 (0%)          0 (0%)</span><br><span class="line">  default                       myweb-609w4             0 (0%)          0 (0%)          0 (0%)          0 (0%)</span><br><span class="line"><span class="comment"># 已分配的资源使用概要信息,例如资源申请的最低、最大允许使用量占系统总量的百分比。</span></span><br><span class="line">Allocated resources:</span><br><span class="line">  (Total limits may be over 100 percent, i.e., overcommitted.</span><br><span class="line">  CPU Requests  CPU Limits      Memory Requests Memory Limits</span><br><span class="line">  ------------  ----------      --------------- -------------</span><br><span class="line">  0 (0%)        0 (0%)          0 (0%)          0 (0%)</span><br><span class="line"><span class="comment"># Node相关的Event信息。</span></span><br><span class="line">Events:</span><br><span class="line">  FirstSeen     LastSeen        Count   From                    SubObjectPath   Type            Reason                  Message</span><br><span class="line">  ---------     --------        -----   ----                    -------------   --------        ------                  -------</span><br><span class="line">  4h            27m             3       &#123;kubelet 127.0.0.1&#125;                     Warning         MissingClusterDNS       kubelet does not have ClusterDNS IP configured and cannot create Pod using <span class="string">&quot;ClusterFirst&quot;</span> policy. pod: <span class="string">&quot;myweb-609w4_default(01d719dd-08b1-11ec-9d6a-00163e1220cb)&quot;</span>. Falling back to DNSDefault policy.</span><br><span class="line">  25m           25m             1       &#123;kubelet 127.0.0.1&#125;                     Warning         MissingClusterDNS       kubelet does not have ClusterDNS IP configured and cannot create Pod using <span class="string">&quot;ClusterFirst&quot;</span> policy. pod: <span class="string">&quot;mysql-2cpt9_default(1c9353ba-08d7-11ec-9d6a-00163e1220cb)&quot;</span>. Falling back to DNSDefault policy.</span><br><span class="line"></span><br><span class="line">[root@liruilong k8s]<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<h3 id="1-4-3-Pod"><a href="#1-4-3-Pod" class="headerlink" title="1.4.3 Pod"></a><font color=plum>1.4.3 Pod</font></h3><blockquote>
<p>Pod是Kubernetes的最重要也最基本的概念,</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/de1c25cd2cf843f492934bef9a4d53d6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p><strong><font color=amber>每个Pod都有一个特殊的被称为“根容器”的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分,除了Pause容器,每个Pod还包含一个或多个紧密相关的用户业务容器。</font></strong></p>
<table>
<thead>
<tr>
<th>为什么<code>Kubernetes</code>会设计出一个全新的<code>Pod</code>的概念并且<code>Pod</code>有这样特殊的组成结构?</th>
</tr>
</thead>
<tbody><tr>
<td>原因之一:在<code>一组容器作为一个单元</code>的情况下,我们难以对“整体”简单地进行判断及有效地进行行动。引入业务无关并且不易死亡的Pause容器作为Pod的根容器,<code>以它的状态代表整个容器组的状态</code>,就简单、巧妙地解决了这个难题。</td>
</tr>
<tr>
<td>原因之二: <code>Pod</code>里的<code>多个业务容器共享Pause容器的IP</code>,共享<code>Pause容器</code>挂接的<code>Volume</code>,这样既简化了<code>密切关联</code>的<code>业务容器之间的通信</code>问题,也很好地解决了它们之间的<code>文件共享</code>问题。</td>
</tr>
</tbody></table>
<p><code>Kubernetes</code> 为每个<code>Pod</code>都分配了<code>唯一的IP地址</code>,称之为<code>Pod IP</code>,一个Pod里的多个容器共享<code>Pod IP</code>地址。 Kuberetes要求底层网络支持集群内任意两个Pod之间的TCP&#x2F;P直接通信,这通常采用<code>虚拟二层网络技术来实现</code>(网桥),</p>
<blockquote>
<p>在<code>Kubernetes</code>里,一个<code>Pod</code>里的容器与另外主机上的<code>Pod</code>容器能够直接通信。</p>
</blockquote>
<p>Pod其实有两种类型:<code>普通的Pod</code>及<code>静态Pod (Static Pod)</code></p>
<table>
<thead>
<tr>
<th>Pod两种类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>静态Pod (Static Pod)</code></td>
<td>并不存放在Kubernetes的etcd存储里,而是存放在某个具体的Node上的一个具体文件中,并且只在此Node上启动运行。</td>
</tr>
<tr>
<td><code>普通的Pod</code></td>
<td>一旦被创建,就会被放入到<code>etcd</code>中存储,随后会被<code>Kubernetes Masten</code>调度到某个具体的<code>Node</code>上并进行绑定(Binding),<code>随后该Pod被对应的Node上的kubelet进程实例化成一组相关的Docker容器并启动起来</code>。</td>
</tr>
</tbody></table>
<blockquote>
<p>在默认情况下,当<code>Pod</code>里的某个容器停止时,<code>Kubernetes</code>会自动检测到这个问题并且重新启动这个<code>Pod </code>(重启Pod里的所有容器),如果Pod所在的<code>Node</code>宕机,则会将这个Node上的所有Pod重新调度到其他节点上.</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/acad80eb71974739b5e8aaf34ad20607.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p><code>Kubernetes</code>里的所有资源对象都可以采用<code>yaml或者JSON</code>格式的文件来定义或描述,下面是我们在之前<code>Hello World例子里用到的myweb</code>这个<code>Pod</code>的资源定义文件:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span>                <span class="comment"># Pod 定义</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span>            <span class="comment"># Pod 名字</span></span><br><span class="line">  <span class="attr">lables:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span>                    <span class="comment"># 包含的容器组</span></span><br><span class="line">  <span class="attr">containers:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">kubeguide/tomcat-app:v1</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span>   </span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_HOST</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&#x27;mysql&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PORT</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&#x27;3306&#x27;</span>   </span><br></pre></td></tr></table></figure>
<p><strong><font color=green><code>Kubernetes</code>的<code>Event</code>概念, <code>Event</code>是一个事件的记录,<code>记录了事件的最早产生时间、最后重现时间、重复次数、发起者、类型,以及导致此事件的原因等众多信息。</code>Event通常会关联到某个具体的资源对象上,是排查故障的重要参考信息,<br></font></strong></p>
<p>Pod同样有Event记录,当我们发现某个Pod迟迟无法创建时,可以用<code>kubectl describe pod xxxx</code>来查看它的描述信息,用来定位问题的原因</p>
<p>在<code>Kubernetes</code>里,一个计算资源进行配额限定需要设定以下两个参数。</p>
<table>
<thead>
<tr>
<th>计算资源进行配额限定</th>
</tr>
</thead>
<tbody><tr>
<td>Requests:该资源的最小申请量,系统必须满足要求。</td>
</tr>
<tr>
<td>Limits:该资源最大允许使用的量,不能被突破,当容器试图使用超过这个量的资源时,可能会被Kubernetes Kill并重启。</td>
</tr>
</tbody></table>
<p>通常我们会把Request设置为一个比较小的数值,符合容器平时的工作负载情况下的资源需求,而把Limit设置为峰值负载情况下资源占用的最大量。</p>
<p>比如下面这段定义,表明MysQL容器申请最少0.25个CPU及64MiB内存,在运行过程中MySQL容器所能使用的资源配额为0.5个CPU及128MiB内存: </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">....</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;64Mi&quot;</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;128Mi&quot;</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span>  </span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Pod Pod 周边对象的示意图</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/2c4694ab71954408af55a1252d00573c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="1-4-4-Lable-标签"><a href="#1-4-4-Lable-标签" class="headerlink" title="1.4.4 Lable 标签"></a><font color=orange>1.4.4 Lable 标签</font></h3><p>Label是Kubernetes系统中另外一个核心概念。<code>一个Label是一个key-value的键值对</code>。其中key与value由用户自己指定。</p>
<p><code>Label可以附加到各种资源对象上,例如Node、Pod、Service、RC等</code>,<strong><font color=yellowgreen>一个资源对象可以定义任意数量的Label,同一个Label也可以被添加到任意数量的资源对象上去, Label通常在资源对象定义时确定,也可以在对象创建后动态添加,或者删除。</font></strong></p>
<p>可以通过<code>给指定的资源对象捆绑一个或多个不同的Label</code>来实现多维度的资源分组管理功能,以便于灵活、方便地进行资源分配、调度、配置、部署等管理工作。</p>
<p>例如:部署不同版本的应用到不同的环境中;或者监控和分析应用(日志记录、监控、告警)等。一些常用的Label示例如下。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">版本标签: <span class="string">&quot;release&quot;</span> : <span class="string">&quot;stable&quot;</span>, <span class="string">&quot;release&quot;</span>:<span class="string">&quot;canary&quot;</span>....</span><br><span class="line">环境标签: <span class="string">&quot;environment&quot;</span>:<span class="string">&quot;dev&quot;</span>, <span class="string">&quot;environment&quot;</span>:<span class="string">&quot;ga&quot;</span>,<span class="string">&quot;environment&quot;</span>:<span class="string">&quot;production&quot;</span>·</span><br><span class="line">架构标签: <span class="string">&quot;ier&quot;</span>:<span class="string">&quot;frontend,&quot;</span> <span class="string">&quot;tier&quot;</span>:<span class="string">&quot;backend&quot;</span>, <span class="string">&quot;tier&quot;</span>:<span class="string">&quot;midleware&quot;</span></span><br><span class="line">分区标签: <span class="string">&quot;artition&quot;</span>:<span class="string">&quot;customerA&quot;</span>, <span class="string">&quot;partition&quot;</span>: <span class="string">&quot;customerB&quot;</span>.</span><br><span class="line">质量管控标签: <span class="string">&quot;track&quot;</span>: <span class="string">&quot;daily&quot;</span>,<span class="string">&quot;track&quot;</span>:<span class="string">&quot;weeky&quot;</span> </span><br></pre></td></tr></table></figure>
<p>可以通过多个<code>Label Selector</code>表达式的组合实现复杂的条件选择,<code>多个表达式之间用“,”进行分隔即可</code>,<strong>几个条件之间是“AND”的关系,即同时满足多个条件</strong>,比如下面的例子:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">name<span class="operator">=</span>标签名</span><br><span class="line">env <span class="operator">!=</span> 标签名</span><br><span class="line">name <span class="keyword">in</span> (标签<span class="number">1</span>，标签<span class="number">2</span>)</span><br><span class="line">name <span class="keyword">not</span> <span class="keyword">in</span>(标签<span class="number">1</span>)</span><br><span class="line">name <span class="keyword">in</span> (redis<span class="operator">-</span>master, redis<span class="operator">-</span>slave):匹配所有具有标签`name<span class="operator">=</span>redis<span class="operator">-</span>master`或者`name<span class="operator">=</span>redis<span class="operator">-</span>slave`的资源对象。</span><br><span class="line">name <span class="keyword">not</span> <span class="keyword">in</span> (phn<span class="operator">-</span>frontend):匹配所有不具有标签name<span class="operator">=</span>php<span class="operator">-</span>frontend的资源对象。</span><br><span class="line">name<span class="operator">=</span>redis<span class="operator">-</span>slave, env<span class="operator">!=</span>production</span><br><span class="line">name notin (php<span class="operator">-</span>frontend),env<span class="operator">!=</span>production</span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">  <span class="attr">lables:</span> </span><br><span class="line">    <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line"><span class="comment"># 管理对象RC和Service 在 spec 中定义Selector 与 Pod 进行关联。</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">  <span class="string">...略...</span></span><br><span class="line"><span class="string">apiVersion&quot;</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>新出现的管理对象如<code>Deployment</code>, <code>ReplicaSet</code>, <code>DaemonSet</code>和<code>Job</code>则可以在<code>Selector</code>中使用基于集合的筛选条件定义,例如: </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">selector:</span></span><br><span class="line">  <span class="attr">matchLabels:</span></span><br><span class="line">     <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">  <span class="attr">matchExpressions:</span></span><br><span class="line">     <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">tire</span>,<span class="attr">operator:</span> <span class="string">In</span>,<span class="attr">values:</span> [<span class="string">frontend</span>]&#125;</span><br><span class="line">     <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">environment</span>, <span class="attr">operator:</span> <span class="string">NotIn</span>, <span class="attr">values:</span> [<span class="string">dev</span>]&#125;</span><br><span class="line">     </span><br></pre></td></tr></table></figure>
<p>matchLabels用于定义一组Label,与直接写在Selector中作用相同; matchExpressions用于定义一组基于集合的筛选条件,可用的条件运算符包括: <code>In, NotIn, Exists和DoesNotExist</code>.</p>
<p>如果同时设置了matchLabels和matchExpressions,则两组条件为<code>&quot;AND&quot;</code>关系,即所有条件需要同时满足才能完成<code>Selector的筛选</code>。 </p>
<p><code>Label Selector</code>在<code>Kubernetes</code>中的重要使用场景有以下几处:</p>
<p><code>kube-controller</code>进程通过资源对象<code>RC</code>上定义的<code>Label Selector</code>来<code>筛选要监控的Pod副本的数量</code>,从而实现Pod副本的数量始终符合预期设定的全自动控制流程</p>
<p><code>kube-proxy</code>进程<code>通过Service的Label Selector来选择对应的Pod</code>, 自动建立起<code>每个Service到对应Pod的请求转发路由表</code>,从而实现<code>Service的智能负载均衡机制</code></p>
<p>通过对某些<code>Node定义特定的Label</code>,并且在<code>Pod定义文件中使用NodeSelector这种标签调度策略</code>, <code>kube-scheduler</code>进程可以实现<code>Pod “定向调度”的特性</code>。 </p>
<h3 id="1-4-5-Replication-Controller"><a href="#1-4-5-Replication-Controller" class="headerlink" title="1.4.5 Replication Controller"></a><font color=plum>1.4.5 Replication Controller</font></h3><p><code>RC是Kubernetes系统中的核心概念之一</code>,简单来说,它其实是<code>定义了一个期望的场景,即声明某种Pod的副本数量在任意时刻都符合某个预期值</code>,所以RC的定义包括如下几个部分。</p>
<table>
<thead>
<tr>
<th>RC</th>
</tr>
</thead>
<tbody><tr>
<td><code>Pod </code>期待的副本数(replicas)</td>
</tr>
<tr>
<td>用于筛选目标<code>Pod</code>的<code>Label Selector</code></td>
</tr>
<tr>
<td>当<code>Pod</code>的副本数量小于预期数量时,用于创建新Pod的Pod模板(template)。</td>
</tr>
</tbody></table>
<p>下面是一个完整的RC定义的例子,即确保拥有<code>tier-frontend</code>标签的这个<code>Pod (运行Tomcat容器)</code>在整个Kubernetes集群中始终<font color=green>只有一个副本:</font> </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">template:</span> </span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">app-demo</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat-demo</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tomcat</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">dns</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>当我们<code>定义了一个RC并提交到Kubernetes集群</code>中以后, <code>Master节点上的Controller Manager组件</code>就得到通知,定期巡检系统中当前<code>存活的目标Pod</code>,并确保<code>目标Pod实例的数量刚好等于此RC的期望值</code>,如果有过多的Pod副本在运行,系统就会停掉一些Pod,否则系统就会再自动创建一些Pod,</p>
<p><strong><font color=green>通过RC, Kubernetes实现了用户应用集群的高可用性,并且大大减少了系统管理员在传统IT环境中需要完成的许多手工运维工作(如主机监控脚本、应用监控脚本、故障恢复脚本等</font></strong>)</p>
<p>下面我们以<code>3个Node节点的集群</code>为例,说明<code>Kubernetes如何通过RC来实现Pod副本数量自动控制的机制</code>。假如我们的RC里定义redis-slave这个Pod需要保持3个副本,系统将可能在其中的两个Node上创建Pod,图1.9描述了在两个Node上创建redis-slave Pod的情形。<br><img src="https://img-blog.csdnimg.cn/7ebf5696cf04482e98b767be02730d46.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p><strong><font color=red>在运行时,我们可以通过 <strong><font color=chocolate>修改RC的副本数量,来实现Pod的动态缩放(Scaling)功能</font></strong>,这可以通过执行<code>kubectl scale</code>命令来一键完成:</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale rc redsi-slave --replicas=3</span><br></pre></td></tr></table></figure>
<p><strong><font color=chocolate>需要注意的是</font></strong>,<strong><font color=chocolate>删除RC并不会影响通过该RC已创建好的Pod,为了删除所有Pod,可以设置replicas的值为0,然后更新该RC。另外, kubectl提供了stop和delete命令来一次性删除RC和RC控制的全部Pod。</font></strong></p>
<p><strong><font color=chocolate>应用升级时</font></strong>,通常会通过Build一个新的Docker镜像,并用新的镜像版本来替代旧的版本的方式达到目的。在系统升级的过程中,我们希望是平滑的方式,比如当前系统中10个对应的旧版本的Pod,最佳的方式是旧版本的Pod每次停止一个,同时创建一个新版本的Pod,在整个升级过程中,此消彼长,而运行中的Pod数量始终是10个,通过RC的机制, Kubernetes很容易就实现了这种高级实用的特性,<strong><font color=brown>被称为“滚动升级” (Rolling Update)</font></strong></p>
<h3 id="1-4-6-Deployment"><a href="#1-4-6-Deployment" class="headerlink" title="1.4.6 Deployment"></a><font color=orange>1.4.6 Deployment</font></h3><p>Deployment是Kubernetes v1.2引入的新概念,引入的目的是为了更好地解决Pod的编排问题。</p>
<p>**<font color=green>Deployment相对于RC的一个最大升级是我们可以随时知道当前Pod “部署”的进度</font>**。实际上由于一个Pod的创建、调度、绑定节点及在目标Node上启动对应的容器这一完整过程需要一定的时间,所以我们期待系统启动N个Pod副本的目标状态,实际上是一个连续变化的“部署过程”导致的最终状态。</p>
<p>Deployment的典型使用场景有以下几个。</p>
<table>
<thead>
<tr>
<th>Deployment的典型使用场景</th>
</tr>
</thead>
<tbody><tr>
<td>创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。</td>
</tr>
<tr>
<td>检查Deployment的状态来看部署动作是否完成(Pod副本的数量是否达到预期的值)</td>
</tr>
<tr>
<td>更新Deployment以创++建新的Pod (比如镜像升级)。</td>
</tr>
<tr>
<td>如果当前Deployment不稳定,则回滚到一个早先的Deployment版本。</td>
</tr>
<tr>
<td>暂停Deployment以便于一次性修改多个PodTemplateSpec的配置项,之后再恢复Deployment,进行新的发布。</td>
</tr>
<tr>
<td>扩展Deployment以应对高负载。</td>
</tr>
<tr>
<td>查看Deployment的状态,以此作为发布是否成功的指标。</td>
</tr>
<tr>
<td>清理不再需要的旧版本ReplicaSets。</td>
</tr>
</tbody></table>
<p>Deployment的定义与Replica Set的定义很类似,除了API声明与Kind类型等有所区别:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiversion: extensions/vlbetal       apiversion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind: Deployment                     kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:                            metadata:</span></span><br><span class="line">  <span class="attr">name: nginx-deployment               name:</span> <span class="string">nginx-repset</span></span><br></pre></td></tr></table></figure>
<p>创建一个 <code>tomcat-deployment.yaml </code> Deployment 描述文件:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1betal</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span> </span><br><span class="line">  <span class="attr">matchLabels:</span> </span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">matchExpressions:</span></span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">tier</span>, <span class="attr">operator:</span> <span class="string">In</span>,<span class="attr">value:</span> [<span class="string">frontend</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">app-demo</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat-demo</span></span><br><span class="line">        <span class="attr">images:</span> <span class="string">tomcat</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span>  <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span>  </span><br></pre></td></tr></table></figure>
<p>运行如下命令创建 Deployment：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">tomcat-deploment.yaml</span></span><br></pre></td></tr></table></figure>

<p>对上述输出中涉及的数量解释如下。</p>
<table>
<thead>
<tr>
<th>数量</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>DESIRED</td>
<td>Pod副本数量的期望值,即Deployment里定义的Replica.</td>
</tr>
<tr>
<td>CURRENT</td>
<td>当前Replica的值,实际上是Deployment所创建的Replica Set里的Replica值,这个值不断增加,直到达到DESIRED为止,表明整个部署过程完成。</td>
</tr>
<tr>
<td>UP-TO-DATE</td>
<td>最新版本的Pod的副本数量,用于指示在滚动升级的过程中,有多少个Pod副本已经成功升级。</td>
</tr>
<tr>
<td>AVAILABLE</td>
<td>当前集群中可用的Pod副本数量,即集群中当前存活的Pod数量。</td>
</tr>
</tbody></table>
<p>运行下述命令查看对应的<code>Replica Set</code>,我们看到它的命名与<code>Deployment</code>的名字有关系:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br></pre></td></tr></table></figure>


<h3 id="1-4-7-Horizontal-Pod-Autoscaler"><a href="#1-4-7-Horizontal-Pod-Autoscaler" class="headerlink" title="1.4.7 Horizontal Pod Autoscaler"></a><font color=royalblue>1.4.7 Horizontal Pod Autoscaler</font></h3><p>**<font color=camel>HPA与之前的RC、 Deployment一样,也属于一种Kubernetes资源对象</font>**。通过 <strong><font color=seagreen>追踪分析RC控制的所有目标Pod的负载变化情况,来确定是否需要针对性地调整目标Pod的副本数,这是HPA的实现原理</font></strong> 。当前, HPA可以有以下两种方式作为Pod负载的度量指标。</p>
<table>
<thead>
<tr>
<th>Horizontal Pod Autoscaler</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=red>CPUUtilizationPercentage</font></strong>.</td>
</tr>
<tr>
<td><strong>应用程序自定义的度量指标,比如服务在每秒内的相应的请求数(TPS或QPS)</strong></td>
</tr>
</tbody></table>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiversion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">php-apache</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="string">spec</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span> </span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">php-apache</span> </span><br><span class="line">  <span class="attr">targetcpuutilizationPercentage:</span> <span class="number">90</span></span><br></pre></td></tr></table></figure>

<p><code>CPUUtilizationPercentage</code>是一个算术平均值,即<code>目标Pod</code>所有副本自身的<code>CPU利用率</code>的平均值。一个<code>Pod自身的CPU利用率</code>是该Pod当前CPU的使用量除以它的Pod Request的值,比,如我们定义一个Pod的Pod Request为0.4,而当前Pod的CPU使用量为0.2,则它的CPU使用率为50%</p>
<p>根据上面的定义,我们可以知道这个<code>HPA控制的目标对象为一个名叫php-apache Deployment里的Pod副本,当这些Pod副本的CPUUtilizationPercentage的值超过90%时会触发自动动态扩容行为,扩容或缩容时必须满足的一个约束条件是Pod的副本数要介于1与10之间</code>。</p>
<p>除了可以通过直接定义yaml文件并且调用<code>kubectrl create</code>的命令来创建一个HPA资源对象的方式,我们还能通过下面的简单命令行直接创建等价的<code>HPA对象</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl autoscale deployment php-apache --cpu-percent=90--min-1 --max=10</span><br></pre></td></tr></table></figure>

<h3 id="1-4-8-StatefulSet"><a href="#1-4-8-StatefulSet" class="headerlink" title="1.4.8 StatefulSet"></a><font color=blue>1.4.8 StatefulSet</font></h3><p><strong><font color=brown>在Kubernetes系统中, Pod的管理对象RC， Deployment, DaemonSet和Job都是面向无状态的服务。</font></strong> 但现实中有很多服务是有状态的,特别是一些复杂的中间件集群,例如MysQL集·群、MongoDB集群、Akka集群、ZooKeeper集群等,这些应用集群有以下一些共同点:</p>
<table>
<thead>
<tr>
<th>共同點</th>
</tr>
</thead>
<tbody><tr>
<td>每个节点都有固定的身份ID,通过这个ID,集群中的成员可以相互发现并且通信。</td>
</tr>
<tr>
<td>集群的规模是比较固定的,集群规模不能随意变动。</td>
</tr>
<tr>
<td>集群里的每个节点都是有状态的,通常会持久化数据到永久存储中。</td>
</tr>
<tr>
<td>如果磁盘损坏,则集群里的某个节点无法正常运行,集群功能受损</td>
</tr>
</tbody></table>
<blockquote>
<p>如果用<code>RC/Deployment控制Pod副本数</code>的方式来实现上述<code>有状态的集群</code>,则我们会发现第1点是无法满足的,因为Pod的名字是随机产生的, <code>Pod的IP地址也是在运行期才确定且可能有变动的</code>,我们事先无法为每个Pod确定唯一不变的ID,</p>
</blockquote>
<p>为了能够在其他节点上恢复某个失败的节点,<strong><font color=chocolate>这种集群中的Pod需要挂接某种共享存储</font></strong>,为了解决这个问题, Kubernetes从v1.4版本开始引入了<code>PetSet这个新的资源对象</code>,并且在v1.5版本时更名为<code>StatefulSet</code>, <code>StatefulSet从本质上来说,可以看作DeploymentRC的一个特殊变种,它有如下一些特性。)</code> </p>
<table>
<thead>
<tr>
<th>特性</th>
</tr>
</thead>
<tbody><tr>
<td><code>StatefulSet</code>里的每个Pod都有<code>稳定、唯一的网络标识</code>,可以用来发现集群内的其他成员。假设<code>StatefulSet</code>的名字叫kafka,那么第1个Pod 叫 kafka-0,第2个叫kafk-1,以此类推。)</td>
</tr>
<tr>
<td><code>StatefulSet控制的Pod副本的启停顺序是受控的</code>,操作第n个Pod时,前n-1个Pod已经是运行且准备好的状态)</td>
</tr>
<tr>
<td><code>StatefulSet里的Pod采用稳定的持久化存储卷</code>,通过PV&#x2F;PVC来实现,删除Pod时默认不会删除与StatefulSet相关的存储卷(为了保证数据的安全)。</td>
</tr>
</tbody></table>
<p><code>statefulSet除了要与PV卷捆绑使用以存储Pod的状态数据</code>,还要与<code>Headless Service</code>配合使用,<strong><font color=yellowgreen>即在每个<code>StatefulSet</code>的定义中要声明它属于哪个Headless Service</font></strong>. <strong><font color=tomato>Headless Service与普通Service的关键区别在于,它没有Cluster IP</font></strong>,如果解析Headless Service的DNS域名,则返回的是该Service对应的全部Pod的Endpoint列表。StatefulSet在Headless <code>Service的基础上又为StatefulSet控制的每个Pod实例创建了一个DNS域名</code>,这个域名的格式为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(podname).$(headless service name) </span><br></pre></td></tr></table></figure>
<h3 id="1-4-9-Service-服务"><a href="#1-4-9-Service-服务" class="headerlink" title="1.4.9 Service (服务)"></a><font color=yellowgreen>1.4.9 Service (服务)</font></h3><p><code>Service也是Kubernetes里的最核心的资源对象之一</code>, **<font color=amber>Kubernetes里的每个Service其实就是我们经常提起的微服务架构中的一个“微服务”,之前我们所说的Pod, RC等资源对象其实都是为这节所说的“服务”-Kubernetes Service作“嫁衣”的</font><strong>。</strong><font color=camel>Pod,RC与Service的逻辑关系</font>**。 </p>
<p><img src="https://img-blog.csdnimg.cn/d70972961a1b46efa3ceb309cd602967.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGx5rKz5bey5peg5oGZ,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p><strong><font color=seagreen> <code>Kubernetes的Service定义了一个服务的访问入口地址</code>,<code>前端的应用(Pod)</code>通过这个入口地址访问其背后的一组由Pod副本组成的集群实例, Service与其后端Pod副本集群之间则是通过Label Selector来实现“无缝对接”的。而RC的作用实际上是保证Service的服务能力和服务质量始终处干预期的标准。 </font></strong></p>
<p>每个Pod都会被分配一个单独的IP地址,而且每个Pod都提供了一个独立的<code>Endpoint(Pod IP+ContainerPort)</code>以被客户端访问,现在多个Pod副本组成了一个集群来提供服务.客户端如何来访问它们呢?一般的做法是部署一个负载均衡器(软件或硬件),</p>
<p>**<font color=seagreen><code>Kubernetes</code>中运行在每个<code>Node</code>上的<code>kube-proxy</code>进程其实就是一个<code>智能的软件负载均衡器</code>,它负责把对Service的请求转发到后端的某个Pod实例上,并在内部实现服务的负载均衡与会话保持机制</font>**。</p>
<p>Kubernetes发明了一种很巧妙又影响深远的设计: </p>
<p>Service不是共用一个负载均衡器的IP地址,而是每个<code>Service</code>分配了一个全局唯一的虚拟IP地址,这个虚拟IP被称为<code>Cluster IP</code>,这样一来,<code>每个服务就变成了具备唯一IP地址的“通信节点”</code>,<code>服务调用就变成了最基础的TCP网络通信问题</code>。</p>
<p>我们知道, Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变,因为新Pod的IP地址与之前旧Pod的不同。而 **<font color=seagreen>Service一旦被创建, Kubernetes就会自动为它分配一个可用的Cluster IP,而且在Service的整个生命周期内,它的Cluster IP不会发生改变</font>**。于是,服务发现这个棘手的问题在Kubernetes的架构里也得以轻松解决:只要用Service的Name与Service的Cluster IP地址做一个DNS域名映射即可完美解决问题。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-pod-create]</span><br><span class="line">└─<span class="variable">$kubectl</span> get svc myweb -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: <span class="string">&quot;2021-10-16T14:25:08Z&quot;</span></span><br><span class="line">  name: myweb</span><br><span class="line">  namespace: liruilong-pod-create</span><br><span class="line">  resourceVersion: <span class="string">&quot;339816&quot;</span></span><br><span class="line">  uid: 695aa461-166c-4937-89ed-7b16ac49c96b</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.109.233.35</span><br><span class="line">  clusterIPs:</span><br><span class="line">  - 10.109.233.35</span><br><span class="line">  externalTrafficPolicy: Cluster</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv4</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ports:</span><br><span class="line">  - nodePort: 30001</span><br><span class="line">    port: 8080</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: myweb</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">status:</span><br><span class="line">  loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure>


<p>Kubernetes Service支持多个Endpoint(端口),**<font color=royalblue>在存在多个Endpoint的情况下,要求每个Endpoint定义一个名字来区分</font>**。下面是Tomcat多端口的Service定义样例:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">service-port</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8005</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">shutdown-port</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>多端口为什么需要给每个端口命名呢?这就涉及Kubernetes的服务发现机制了</p>
</blockquote>
<h4 id="Kubernetes-的服务发现机制"><a href="#Kubernetes-的服务发现机制" class="headerlink" title="Kubernetes 的服务发现机制"></a><strong><font color=brown>Kubernetes 的服务发现机制</font></strong></h4><table>
<thead>
<tr>
<th>Kubernetes 的服务发现机制</th>
</tr>
</thead>
<tbody><tr>
<td>最早时Kubernetes采用了Linux环境变量的方式解决这个问题,即每个Service生成一些对应的Linux环境变量(ENV),并在每个Pod的容器在启动时,自动注入这些环境变量</td>
</tr>
<tr>
<td>后来Kubernetes通过Add-On增值包的方式引入了DNS系统,把服务名作为DNS域名,这样一来,程序就可以直接使用服务名来建立通信连接了。目前Kubernetes上的大部分应用都已经采用了DNS这些新兴的服务发现机制</td>
</tr>
</tbody></table>
<h4 id="外部系统访问-Service-的问题"><a href="#外部系统访问-Service-的问题" class="headerlink" title="外部系统访问 Service 的问题"></a><font color=blue>外部系统访问 Service 的问题</font></h4><table>
<thead>
<tr>
<th><font color=orange>Kubernetes里的“三种IP”</font></th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=green>Node IP</font></strong></td>
<td>Node 节点的IP地址,Node IP是Kubernetes集群中每个节点的物理网卡的IP地址,这是一个真实存在的物理网络,所有属于这个网络的服务器之间都能通过这个网络直接通信,不管它们中是否有部分节点不属于这个Kubernetes集群。**<font color=brown>这也表明了Kubernetes集群之外的节点访问Kubernetes集群之内的某个节点或者TCP&#x2F;IP服务时,必须要通过Node IP进行通信</font>**。</td>
</tr>
<tr>
<td><strong><font color=plum>Pod IP </font></strong></td>
<td>Pod 的 IP 地址:Pod IP是每个Pod的IP地址,它是<code>Docker Engine</code>根据dockero网桥的IP地址段进行分配的,通常是一个虚拟的二层网络,前面我们说过,<strong><font color=green> Kubernetes要求位于不同Node上的Pod能够彼此直接通信,所以Kubernetes里一个Pod里的容器访问另外一个Pod里的容器,就是通过Pod IP所在的虚拟二层网络进行通信的,而真实的TCP&#x2F;IP流量则是通过Node IP所在的物理网卡流出的。</font></strong></td>
</tr>
<tr>
<td><strong><font color=green>Cluster IP</font></strong></td>
<td>Service 的IP地址,<strong><font color=brown>Cluster IP仅仅作用于Kubernetes Service这个对象,并由Kubernetes管理和分配IP地址(来源于Cluster IP地址池)。Cluster IP无法被Ping,因为没有一个“实体网络对象”来响应。Cluster IP只能结合Service Port组成一个具体的通信端口,单独的Cluster IP不具备TCPIP通信的基础,并且它们属于Kubernetes集群这样一个封闭的空间,集群之外的节点如果要访问这个通信端口,则需要做一些额外的工作。在Kubernetes集群之内, Node IP网、Pod IP网与Cluster IP网之间的通信,采用的是Kubermetes自己设计的一种编程方式的特殊的路由规则,与我们所熟知的IP路由有很大的不同。</font></strong></td>
</tr>
</tbody></table>
<blockquote>
<p>外部系统访问 Service,采用NodePort是解决上述问题的最直接、最有效、最常用的做法。具体做法如下,以tomcat-service为例,我们在Service的定义里做如下扩展即可:</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="string">posts：</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">     <span class="attr">nodePort:</span> <span class="number">31002</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span>   </span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p><strong><font color=orange>即这里我们可以通过nodePort:31002 来访问Service,NodePort的实现方式是在Kubernetes集群里的每个Node上为需要外部访问的Service开启个对应的TCP监听端口,外部系统只要用任意一个Node的IP地址+具体的NodePort端口即可访问此服务,在任意Node上运行netstat命令,我们就可以看到有NodePort端口被监听:</font></strong></p>
<p><strong><font color=amber>Service 负载均衡问题</font></strong></p>
<p>但<code>NodePort</code>还没有完全解决外部访问<code>Service</code>的所有问题,比如<code>负载均衡</code>问题,假如我们的<code>集群中有10个Node</code>,则此时最好有一个<code>负载均衡器</code>,外部的请求只需访问此<code>负载均衡器的IP地址</code>,由负载均衡器负责转发流量到后面某个Node的NodePort上。如图</p>
<table>
<thead>
<tr>
<th>NodePort的负载均衡</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/2d9e7e7523af4399b773e2fa61cca095.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><code>Load balancer</code>组件独立于<code>Kubernetes集群</code>之外,通常是一个<code>硬件的负载均衡器</code>,或者是以<code>软件方式实现</code>的,例如<code>HAProxy</code>或者<code>Nginx</code>。对于每个Service,我们通常需要配置一个对应的Load balancer实例来转发流量到后端的Node上</td>
</tr>
<tr>
<td><code>Kubernetes</code>提供了<code>自动化的解决方案</code>,如果我们的集群运行在<code>谷歌的GCE公有云</code>上,那么只要我们把<code>Service的type-NodePort改为type-LoadBalancer</code>,此时<code>Kubernetes</code>会自动创建一个对应的<code>Load balancer</code>实例并返回它的<code>IP地址供外部客户端使用</code>。</td>
</tr>
</tbody></table>
<h3 id="10-Volume-存储卷"><a href="#10-Volume-存储卷" class="headerlink" title="10 Volume (存储卷)"></a><font color=chocolate>10 Volume (存储卷)</font></h3><p>Volume是Pod中能够被多个容器访问的共享目录。<code>Kuberetes的Volume概念、用途和目的与Docker的Volume比较类似,但两者不能等价</code>。</p>
<table>
<thead>
<tr>
<th>Volume (存储卷)</th>
</tr>
</thead>
<tbody><tr>
<td>Kubernetes中的<code>Volume定义在Pod上</code>,然后被一个Pod里的多个容器挂载到具体的文件目录下;</td>
</tr>
<tr>
<td>Kubernetes中的<code>Volume与Pod的生命周期相同</code>,但与<code>容器的生命周期不相关</code>,<code>当容器终止或者重启时, Volume中的数据也不会丢失。</code></td>
</tr>
<tr>
<td>Kubernetes支持<code>多种类型的Volume</code>,例如<code>GlusterFS, Ceph</code>等先进的<code>分布式文件系统</code>。</td>
</tr>
</tbody></table>
<blockquote>
<p><code>Volume</code>的使用也比较简单,在大多数情况下,我们先在<code>Pod</code>上声明一个<code>Volume</code>,然后在容器里引用该<code>Volume</code>并<code>Mount</code>到容器里的某个目录上。举例来说,我们要给之前的<code>Tomcat Pod</code>增加一个名字为<code>datavol</code>的<code>Volume</code>,并且<code>Mount</code>到容器的<code>/mydata-data</code>目录上,则只要对Pod的定义文件做如下修正即可(注意黑体字部分):</p>
</blockquote>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">template:</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">app-demo</span></span><br><span class="line">      <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">spec:</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">datavol</span></span><br><span class="line">        <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat-demo</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">tomcat</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/myddata-data</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">datavol</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>除了可以让一个<code>Pod</code>里的<code>多个容器共享文件、让容器的数据写到宿主机的磁盘上或者写文件到网络存储中</code>, <code>Kubernetes的Volume</code>还扩展出了一种非常有实用价值的功能,即</p>
</blockquote>
<p><strong><font color=camel>容器配置文件集中化定义与管理</font></strong>,这是通过<code>ConfigMap</code>这个新的资源对象来实现的.</p>
<p><font color=purple>Kubernetes提供了非常丰富的<code>Volume类型</code>,下面逐一进行说明。</font></p>
<h4 id="1-emptyDir"><a href="#1-emptyDir" class="headerlink" title="1. emptyDir"></a><font color=red>1. emptyDir</font></h4><p>**<font color=orange>一个emptyDir Volume是在Pod分配到Node时创建的</font>**。从它的名称就可以看出,它的<code>初始内容为空</code>,并且无须指定宿主机上对应的目录文件,因为这是 <strong><font color=seagreen>Kubernetes自动分配的一个目录</font></strong>,<code>当Pod从Node上移除时, emptyDir中的数据也会被永久删除</code>。emptyDir的一些用途如下。</p>
<table>
<thead>
<tr>
<th>emptyDir的一些用途</th>
</tr>
</thead>
<tbody><tr>
<td>临时空间,例如用于某些应用程序运行时所需的临时目录,且无须永久保留。</td>
</tr>
<tr>
<td>长时间任务的中间过程CheckPoint的临时保存目录。</td>
</tr>
<tr>
<td>一个容器需要从另一个容器中获取数据的目录(多容器共享目录)</td>
</tr>
</tbody></table>
<h4 id="2-hostPath"><a href="#2-hostPath" class="headerlink" title="2. hostPath"></a><font color=yellowgreen>2. hostPath</font></h4><p><code>hostPath为在Pod上挂载宿主机上的文件或目录</code>,它通常可以用于以下几方面。</p>
<p>|容器应用程序生成的日志文件需要永久保存时,可以使用宿主机的高速文件系统进行存储。|</p>
<p>需要访问宿主机上<code>Docker</code>引擎内部数据结构的容器应用时,可以通过定义<code>hostPath</code>为宿主机<code>/var/lib/docker</code>目录,使容器内部应用可以直接访问<code>Docker</code>的文件系统。</p>
<p>在使用这种类型的<code>Volume</code>时,需要注意以下几点。</p>
<p>在不同的Node上具有相同配置的<code>Pod</code>可能会因为宿主机上的目录和文件不同而导致对<code>Volume</code>上目录和文件的访问结果不一致。)</p>
<p>如果使用了资源配额管理,则Kubernetes无法将hostPath在宿主机上使用的资源纳入管理。在下面的例子中使用宿主机的&#x2F;data目录定义了一个<code>hostPath</code>类型的<code>Volume</code>:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;persistent-storage&quot;</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">&quot;/data&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="3-gcePersistentDisk"><a href="#3-gcePersistentDisk" class="headerlink" title="3. gcePersistentDisk"></a><font color=camel>3. gcePersistentDisk</font></h4><p>使用这种类型的Volume表示使用谷歌公有云提供的永久磁盘(PersistentDisk, PD)存放Volume的数据,它与emptyDir不同, PD上的内容会被永久存,当Pod被删除时, PD只是被卸载(Unmount),但不会被删除。需要注意是,你需要先创建一个永久磁盘(PD),才能使用gcePersistentDisk.</p>
<h4 id="4-awsElasticBlockStore"><a href="#4-awsElasticBlockStore" class="headerlink" title="4. awsElasticBlockStore"></a><font color=camel>4. awsElasticBlockStore</font></h4><p>与GCE类似,该类型的Volume使用亚马逊公有云提供的EBS Volume存储数据,需要先创建一个EBS Volume才能使用awsElasticBlockStore. </p>
<h4 id="5-NFS"><a href="#5-NFS" class="headerlink" title="5. NFS"></a><font color=yellowgreen>5. NFS</font></h4><p>使用NFS网络文件系统提供的共享目录存储数据时,我们需要在系统中部署一个NFSServer,定义NES类型的Volume的示例如下<br><code>yum -y install nfs-utils</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">server:</span> <span class="string">nfs.server.locathost</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line"><span class="string">....</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="1-4-11-Persistent-Volume"><a href="#1-4-11-Persistent-Volume" class="headerlink" title="1.4.11 Persistent Volume"></a><font color=seagreen>1.4.11 Persistent Volume</font></h3><p><code>Volume</code>是定义在<code>Pod</code>上的,属于“<code>计算资源</code>”的一部分,而实际上, “<code>网络存储</code>”是相对独立于“<code>计算资源</code>”而存在的一种<code>实体资源</code>。比如在使用<code>虚拟机</code>的情况下,我们通常会先定义一个网络存储,然后从中划出一个“网盘”并挂接到<code>虚拟机</code>上</p>
<p><code>Persistent Volume(简称PV)</code>和与之相关联的<code>Persistent Volume Claim (简称PVC)</code>也起到了类似的作用。<code>PV</code>可以理解成 <strong><font color=tomato>Kubernetes集群中的某个网络存储中对应的一块存储</font></strong>,它与Volume很类似,但有以下区别。</p>
<table>
<thead>
<tr>
<th>Persistent Volume与Volume的区别</th>
</tr>
</thead>
<tbody><tr>
<td>PV只能是网络存储,不属于任何Node,但可以在每个Node上访问。</td>
</tr>
<tr>
<td>PV并不是定义在Pod上的,而是独立于Pod之外定义。</td>
</tr>
<tr>
<td>PV目前支持的类型包括: gcePersistentDisk、 AWSElasticBlockStore, AzureFileAzureDisk, FC (Fibre Channel). Flocker, NFS, isCSI, RBD (Rados Block Device)CephFS. Cinder, GlusterFS. VsphereVolume. Quobyte Volumes, VMware Photon.PortworxVolumes, ScalelO Volumes和HostPath (仅供单机测试)。</td>
</tr>
</tbody></table>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiversion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv0003</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span> </span><br><span class="line">  <span class="attr">nfs:</span> </span><br><span class="line">    <span class="attr">path:</span> <span class="string">/somepath</span> </span><br><span class="line">    <span class="attr">server:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure>
<p><strong><font color=purple>PV的accessModes属性</font></strong>, 目前有以下类型:</p>
<p>ReadWriteOnce:读写权限、并且只能被单个Node挂载。<br>ReadOnlyMany:只读权限、允许被多个Node挂载。<br>ReadWriteMany:读写权限、允许被多个Node挂载。</p>
<p><strong><font color=purple>如果某个Pod想申请某种类型的PV,则首先需要定义一个PersistentVolumeClaim (PVC)对象:</font></strong> </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Persistentvolumeclaim</span> </span><br><span class="line"><span class="attr">apiversion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">myclaim</span> </span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Readwriteonce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">BGi</span> </span><br></pre></td></tr></table></figure>
<p>引用PVC</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mypd</span> </span><br><span class="line">    <span class="attr">persistentvolumeclaim:</span> </span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">myclaim</span></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th align="left"><code>PV</code>是有状态的对象,它有以下几种状态。</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>Available</code>:空闲状态。</td>
</tr>
<tr>
<td align="left"><code>Bound</code>:已经绑定到某个Pvc上。</td>
</tr>
<tr>
<td align="left"><code>Released</code>:对应的PVC已经删除,但资源还没有被集群收回。</td>
</tr>
<tr>
<td align="left"><code>Failed</code>: PV自动回收失败。</td>
</tr>
</tbody></table>
<h3 id="1-4-12-Namespace-命名空间"><a href="#1-4-12-Namespace-命名空间" class="headerlink" title="1.4.12 Namespace (命名空间)"></a><font color=tomato>1.4.12 Namespace (命名空间)</font></h3><p><strong><font color=purple>Namespace (命名空间)是Kubernetes系统中非常重要的概念</font></strong>, Namespace在很多情况下用于实现 **<font color=orange>多租户的资源隔离</font>**。Namespace通过将集群内部的资源对象“分配”到不同的Namespace 中,形成逻辑上分组的不同项目、小组或用户组,便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。Kubernetes集群在启动后,会创建一个名为<code>&quot;default&quot;</code>的<code>Namespace</code>,通过<code>kubectl</code>可以查看到:</p>
<p>|不同的namespace之间互相隔离|<br>|–|–|<br>|查看所有命名空间|kubectl get ns|<br>|查看当前命名空间|kubectl config get-contexts|<br>|设置命名空间|kubectl config set-context 集群名 –namespace&#x3D;命名空间|</p>
<p><strong><font color=yellowgreen>kub-system 本身的各种 pod，是kubamd默认的空间。pod使用命名空间相互隔离</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> get namespaces</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   13h</span><br><span class="line">kube-node-lease   Active   13h</span><br><span class="line">kube-public       Active   13h</span><br><span class="line">kube-system       Active   13h</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   13h</span><br><span class="line">kube-node-lease   Active   13h</span><br><span class="line">kube-public       Active   13h</span><br><span class="line">kube-system       Active   13h</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─$</span><br></pre></td></tr></table></figure>
<p><strong><font color=yellowgreen>命名空间基本命令</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> create ns liruilong</span><br><span class="line">namespace/liruilong created</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   13h</span><br><span class="line">kube-node-lease   Active   13h</span><br><span class="line">kube-public       Active   13h</span><br><span class="line">kube-system       Active   13h</span><br><span class="line">liruilong         Active   4s</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> create ns k8s-demo</span><br><span class="line">namespace/k8s-demo created</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   13h</span><br><span class="line">k8s-demo          Active   3s</span><br><span class="line">kube-node-lease   Active   13h</span><br><span class="line">kube-public       Active   13h</span><br><span class="line">kube-system       Active   13h</span><br><span class="line">liruilong         Active   20s</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> delete ns  k8s-demo</span><br><span class="line">namespace <span class="string">&quot;k8s-demo&quot;</span> deleted</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─<span class="variable">$kubectl</span> get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   13h</span><br><span class="line">kube-node-lease   Active   13h</span><br><span class="line">kube-public       Active   13h</span><br><span class="line">kube-system       Active   13h</span><br><span class="line">liruilong         Active   54s</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible]</span><br><span class="line">└─$</span><br></pre></td></tr></table></figure>
<p><strong><font color=plum>命名空间切换</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/.kube]</span><br><span class="line">└─<span class="variable">$vim</span> config</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/.kube]</span><br><span class="line">└─<span class="variable">$kubectl</span> config get-contexts</span><br><span class="line">CURRENT   NAME       CLUSTER    AUTHINFO            NAMESPACE</span><br><span class="line">*         context1   cluster1   kubernetes-admin1</span><br><span class="line">          context2   cluster2   kubernetes-admin2</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/.kube]</span><br><span class="line">└─<span class="variable">$kubectl</span> config set-context context2 --namespace=kube-system</span><br><span class="line">Context <span class="string">&quot;context2&quot;</span> modified.</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/.kube]</span><br><span class="line">└─<span class="variable">$kubectl</span> config get-contexts</span><br><span class="line">CURRENT   NAME       CLUSTER    AUTHINFO            NAMESPACE</span><br><span class="line">*         context1   cluster1   kubernetes-admin1</span><br><span class="line">          context2   cluster2   kubernetes-admin2   kube-system</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/.kube]</span><br><span class="line">└─<span class="variable">$kubectl</span> config set-context context1 --namespace=kube-public</span><br><span class="line">Context <span class="string">&quot;context1&quot;</span> modified.</span><br></pre></td></tr></table></figure>
<p><strong><font color=purple>或者可以这样切换名称空间</font></strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-context $(kubectl config current-context) --namespace=&lt;namespace&gt;</span><br><span class="line">kubectl config view | grep namespace</span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure>
<p><strong><font color=yellowgreen>创建pod时指定命名空间</font></strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">pod-static</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-static</span></span><br><span class="line">  <span class="attr">namespeace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pod-demo</span></span><br><span class="line">    <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>当我们给每个租户创建一个Namespace来实现多租户的资源隔离时,还能<code>结合Kubernetes&quot;的资源配额管理,限定不同租户能占用的资源,例如CPU使用量、内存使用量</code>等。</p>
<h4 id="Annotation-注解"><a href="#Annotation-注解" class="headerlink" title="Annotation (注解)"></a><font color=plum>Annotation (注解)</font></h4><p><strong><font color=royalblue>Annotation与Label类似,也使用<code>key/value键值</code>对的形式进行定义。</font></strong></p>
<p><strong><font color=red>不同的是Label具有严格的命名规则,它定义的是Kubernetes对象的元数据(Metadata),并且用于Label Selector.</font></strong></p>
<p><strong><font color=green>Annotation则是用户任意定义的“附加”信息,以便于外部工具进行查找, Kubernetes的模块自身会通过Annotation的方式标记资源对象的一些特殊信息。</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-pod-create]</span><br><span class="line">└─<span class="variable">$kubectl</span> annotate nodes vms82.liruilongs.github.io <span class="string">&quot;dest=这是一个工作节点&quot;</span></span><br><span class="line">node/vms82.liruilongs.github.io annotated</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-pod-create]</span><br><span class="line">└─<span class="variable">$kubectl</span> describe nodes vms82.liruilongs.github.io</span><br><span class="line">Name:               vms82.liruilongs.github.io</span><br><span class="line">Roles:              worker1</span><br><span class="line">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    disktype=node1</span><br><span class="line">                    kubernetes.io/arch=amd64</span><br><span class="line">                    kubernetes.io/hostname=vms82.liruilongs.github.io</span><br><span class="line">                    kubernetes.io/os=linux</span><br><span class="line">                    node-role.kubernetes.io/worker1=</span><br><span class="line">Annotations:        dest: 这是一个工作节点</span><br><span class="line">                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock</span><br><span class="line">                    node.alpha.kubernetes.io/ttl: 0</span><br><span class="line">                    projectcalico.org/IPv4Address: 192.168.26.82/24</span><br><span class="line">                    projectcalico.org/IPv4IPIPTunnelAddr: 10.244.171.128</span><br><span class="line">                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="literal">true</span></span><br><span class="line">.....................                    </span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>通常来说,用Annotation来记录的信息如下</th>
</tr>
</thead>
<tbody><tr>
<td>build信息、 release信息、Docker镜像信息等,例如时间戳、release id号、PR号、镜像hash值、 docker registry地址等。</td>
</tr>
<tr>
<td>日志库、监控库、分析库等资源库的地址信息。</td>
</tr>
<tr>
<td>程序调试工具信息,例如工具名称、版本号等。</td>
</tr>
<tr>
<td>团队的联系信息,例如电话号码、负责人名称、网址等。</td>
</tr>
</tbody></table>
<h1 id="第2章Kubernetes实践指南"><a href="#第2章Kubernetes实践指南" class="headerlink" title="第2章Kubernetes实践指南"></a><font color="009688">第2章Kubernetes实践指南</font></h1><h2 id="3-8-Pod健康检查和服务可用性检查"><a href="#3-8-Pod健康检查和服务可用性检查" class="headerlink" title="3.8 Pod健康检查和服务可用性检查"></a><font color=seagreen>3.8 Pod健康检查和服务可用性检查</font></h2><p><strong><font color=green><code>Kubernetes</code> 对 <code>Pod</code> 的健康状态可以通过两类探针来检查:<code>LivenessProbe </code>和<code>ReadinessProbe</code>, kubelet定期执行这两类探针来诊断容器的健康状况。</font></strong></p>
<table>
<thead>
<tr>
<th>探针类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=amber>LivenessProbe探针</font></strong></td>
<td><strong><font color=seagreen> 用于判断容器是否存活(Running状态) ,如果LivenessProbe探针探测到容器不健康,则kubelet将杀掉该容器,并根据容器的重启策略做相应的处理。如果一个容器不包含LivenesspProbe探针,那么kubelet认为该容器的LivenessProbe探针返回的值永远是Success。</font></strong></td>
</tr>
<tr>
<td><strong><font color=amber>ReadinessProbe探针</font></strong></td>
<td><strong><font color=seagreen>用于判断容器服务是否可用(Ready状态) ,达到Ready状态的Pod才可以接收请求。对于被Service管理的Pod, Service与Pod Endpoint的关联关系也将基于Pod是否Ready进行设置。如果在运行过程中Ready状态变为False,则系统自动将其从Service的后端Endpoint列表中隔离出去,后续再把恢复到Ready状态的Pod加回后端Endpoint列表。这样就能保证客户端在访问Service时不会被转发到服务不可用的Pod实例上。 </font></strong></td>
</tr>
</tbody></table>
<p><strong><font color=chocolate><code>LivenessProbe</code>和<code>ReadinessProbe</code>均可配置以下三种实现方式。</font></strong></p>
<table>
<thead>
<tr>
<th>方式</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=plum>ExecAction</font></strong></td>
<td>在容器内部执行一个命令,如果该命令的返回码为0,则表明容器健康。</td>
</tr>
<tr>
<td><strong><font color=purple> TCPSocketAction</font></strong></td>
<td>通过容器的IP地址和端口号执行TC检查,如果能够建立TCP连接,则表明容器健康。</td>
</tr>
<tr>
<td><strong><font color=amber>HTTPGetAction</font></strong></td>
<td>通过容器的IP地址、端口号及路径调用HTTP Get方法,如果响应的状态码大于等于200且小于400,则认为容器健康。</td>
</tr>
</tbody></table>
<p><strong><font color=purple>对于每种探测方式，都需要设置<code>initialDelaySeconds</code>和<code>timeoutSeconds</code>两个参数，它们的含义分别如下。</font></strong></p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=amber>initialDelaySeconds：</font></strong></td>
<td>启动容器后进行首次健康检查的等待时间，单位为s。</td>
</tr>
<tr>
<td><strong><font color=plum>timeoutSeconds:</font></strong></td>
<td>健康检查发送请求后等待响应的超时时间,单位为s。当超时发生时, kubelet会认为容器已经无法提供服务,将会重启该容器。</td>
</tr>
</tbody></table>
<p><strong><font color=yellowgreen>Kubernetes的ReadinessProbe机制可能无法满足某些复杂应用对容器内服务可用状态的判断</font></strong></p>
<blockquote>
<p>所以Kubernetes从1.11版本开始,引入PodReady++特性对Readiness探测机制进行扩展,在1.14版本时达到GA稳定版,称其为Pod Readiness Gates。</p>
</blockquote>
<blockquote>
<p>通过Pod Readiness Gates机制,用户可以将自定义的ReadinessProbe探测方式设置在Pod上,辅助Kubernetes设置Pod何时达到服务可用状态(Ready) 。为了使自定义的ReadinessProbe生效,用户需要提供一个外部的控制器(Controller)来设置相应的Condition状态。</p>
</blockquote>
<p><strong><font color=yellowgreen>Pod的Readiness Gates在Pod定义中的ReadinessGate字段进行设置。下面的例子设置了一个类型为<a target="_blank" rel="noopener" href="http://www.example.com/feature-1%E7%9A%84%E6%96%B0ReadinessGate">www.example.com/feature-1的新ReadinessGate</a>:</font></strong></p>
<table>
<thead>
<tr>
<th>–</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/92bcd18c1e1d45b894c798a1ee66856d.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><strong><font color=green>新增的自定义Condition的状态(status)将由用户自定义的外部控·制器设置,默认值为False. Kubernetes将在判断全部readinessGates条件都为True时,才设置Pod为服务可用状态(Ready为True) 。</font></strong></td>
</tr>
</tbody></table>
<h2 id="3-9-pod-调度"><a href="#3-9-pod-调度" class="headerlink" title="3.9 pod 调度"></a><font color=camel>3.9 pod 调度</font></h2><h3 id="3-9-8-Job：批处理调度"><a href="#3-9-8-Job：批处理调度" class="headerlink" title="3.9.8 Job：批处理调度"></a><font color=tomato>3.9.8 Job：批处理调度</font></h3><p><strong><font color=purple>Kubernetes从1.2版本开始支持批处理类型的应用,我们可以通过<code>Kubernetes Job</code>资源对象来定义并启动一个批处理任务。</font></strong></p>
<p><strong><font color=yellowgreen>批处理任务通常<code>并行(或者串行)</code>启动多个计算进程去处理一批<code>工作项(work item)</code>处理完成后,整个批处理任务结束。</font></strong></p>
<p>按照<code>批处理任务实现方式</code>的不同,批处理任务可以分为的几种模式。</p>
<table>
<thead>
<tr>
<th>–</th>
<th>–</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=yellowgreen>Job Template Expansion模式</font></strong></td>
<td>一个Job对象对应一个待处理的Work item,有几个Work item就产生几个独立的Job,通常适合Workitem数量少、每个Work item要处理的数据量比较大的场景,比如有一个100GB的文件作为一个Work item,总共有10个文件需要处理。</td>
</tr>
<tr>
<td><strong><font color=yellowgreen> Queue with Pod Per Work Item模式</font></strong></td>
<td>采用一个<code>任务队列存放Work item</code>,一个Job对象作为消费者去完成这些Work item,在这种模式下, Job会启动N个Pod,每个Pod都对应一个Work item。</td>
</tr>
<tr>
<td><strong><font color=seagreen> Queue with Variable Pod Count模式</font></strong></td>
<td>也是采用一个<code>任务队列存放Work item</code>,一个Job对象作为消费者去完成这些Work item,但与上面的模式不同, **<font color=purple>Job启动的Pod数量是可变的</font>**。</td>
</tr>
<tr>
<td><strong><font color=green>Single Job with Static Work Assignment的模式</font></strong></td>
<td>一个Job产生多个Pod，采用程序静态方式分配任务项</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>–</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/f63d1b9f0db147f598d8e3b5eae1933c.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/03f58f40be0a4d3295b6722a07003e8b.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/ac42ec0d6d414773926177142f008a8e.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/a548d8af45da46808f33d303e2d3d9ef.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<p>考虑到批处理的并行问题, Kubernetes将Job分以下三种类型。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=tomato>Non-parallel Jobs</font></strong></td>
<td>通常<code>一个Job只启动一个Pod</code>,除非<code>Pod异常,才会重启该Pod</code>,一旦此<code>Pod正常结束, Job将结束</code>。</td>
</tr>
<tr>
<td><strong><font color=blue>Parallel Jobs with a fixed completion count</font></strong></td>
<td><code>并行Job会启动多个Pod</code>,此时需要设定<code>Job的.spec.completions</code>参数为一个正数,当正常结束的Pod数量达至此参数设定的值后, <code>Job结束</code>。此外, <code>Job的.spec.parallelism参数用来控制并行度</code>,即<code>同时启动几个Job来处理Work Item</code>.</td>
</tr>
<tr>
<td><strong><font color=purple>Parallel Jobs with a work queue</font></strong></td>
<td><code>任务队列方式的并行Job</code>需要一个独立的<code>Queue</code>, <code>Work item都在一个Queue中存放</code>,不能设置<code>Job的.spec.completions参数</code>,此时Job有以下特性。<br>每个Pod都能独立判断和决定是否还有任务项需要处理。<br>如果某个Pod正常结束,则Job不会再启动新的Pod. <br> 如果一个Pod成功结束,则此时应该不存在其他Pod还在工作的情况,它们应该都处于即将结束、退出的状态。 <br>如果所有Pod都结束了,且至少有一个Pod成功结束,则整个Job成功结束。</td>
</tr>
</tbody></table>
<h3 id="3-9-9-Cronjob：定时任务"><a href="#3-9-9-Cronjob：定时任务" class="headerlink" title="3.9.9 Cronjob：定时任务"></a><font color=camel>3.9.9 Cronjob：定时任务</font></h3><p><strong><font color=tomato><code>Kubernetes从1.5</code>版本开始增加了一种新类型的Job,即类似LinuxCron的定时任务<code>Cron Job</code>,下面看看如何定义和使用这种类型的Job首先,确保<code>Kubernetes的版本为1.8及以上</code>。 </font></strong></p>
<p><strong><font color=purple>运行下面的命令,可以更直观地了解Cron Job定期触发任务执行的历史和现状:</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-jobs-create]</span><br><span class="line">└─<span class="variable">$kubectl</span>  apply  -f jobcron.yaml</span><br><span class="line">cronjob.batch/test-job created</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-jobs-create]</span><br><span class="line">└─<span class="variable">$kubectl</span>  get cronjobs</span><br><span class="line">NAME       SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">test-job   */1 * * * *   False     0        &lt;none&gt;          12s</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-jobs-create]</span><br><span class="line">└─<span class="variable">$kubectl</span>  get <span class="built_in">jobs</span> --watch</span><br><span class="line">NAME                COMPLETIONS   DURATION   AGE</span><br><span class="line">test-job-27336917   0/1                      0s</span><br><span class="line">test-job-27336917   0/1           0s         0s</span><br><span class="line">test-job-27336917   1/1           25s        25s</span><br><span class="line">test-job-27336918   0/1                      0s</span><br><span class="line">test-job-27336918   0/1           0s         0s</span><br><span class="line">test-job-27336918   1/1           26s        26s</span><br><span class="line">^C┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-jobs-create]</span><br><span class="line">└─<span class="variable">$kubectl</span>  get <span class="built_in">jobs</span> -o wide</span><br><span class="line">NAME                COMPLETIONS   DURATION   AGE    CONTAINERS   IMAGES    SELECTOR</span><br><span class="line">test-job-27336917   1/1           25s        105s   test-job     busybox   controller-uid=35e43bbc-5869-4bda-97db-c027e9a36b97</span><br><span class="line">test-job-27336918   1/1           26s        45s    test-job     busybox   controller-uid=82d2e4a5-716c-42bf-bc7d-3137dd0e50e8</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~/ansible/k8s-jobs-create]</span><br><span class="line">└─$</span><br></pre></td></tr></table></figure>
<p><strong><font color=blue>在<code>Kubernetes 1.9</code>版本后，<code>kubectl</code>命令增加了别名<code>cj</code>来表示<code>cronjob</code>，同时<code>kubectl set image/env</code>命令也可以作用在<code>CronJob</code>对象上了。</font></strong></p>
<h1 id="第4章-深入掌握Service"><a href="#第4章-深入掌握Service" class="headerlink" title="第4章 深入掌握Service"></a><font color=seagreen>第4章 深入掌握Service</font></h1><p><strong><font color=seagreen><code>Service</code>是<code>Kubernetes</code>的核心概念,可以为一组具有相同功能的容器应用提供<code>一个统一的入口地址</code>,并且将请求负载分发到后端的各个容器应用上。具体涉及service的负载均衡机制、如何访问<code>Service</code>、 <code>Headless Service</code>, <code>DNS服务</code>的机制和实践、<code>Ingress 7层路由机制</code>等。 </font></strong></p>
<blockquote>
<p>通过Service的定义, Kubernetes实现了一种分布式应用统一入口的定义和负载均衡机制。Service还可以进行其他类型的设置,例如设置多个端口号、直接设置为集群外部服务,或实现为Headless Service (无头服务)模式</p>
</blockquote>
<h2 id="4-1-Service定义详解"><a href="#4-1-Service定义详解" class="headerlink" title="4.1 Service定义详解"></a><font color=amber>4.1 Service定义详解</font></h2><table>
<thead>
<tr>
<th>配置文件相关</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/cad706c5f70646f78855c51256174b64.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<p><strong><font color=seagreen>Service的类型type,指定Service的访间方式,默认值为ClusterlP.</font></strong></p>
<table>
<thead>
<tr>
<th>方式</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>ClusterlP</td>
<td>虚拟的服务IP地址,该地址用于Kubernetes集群内部的Pod访问,在Node上kube-proxy通过设置的iptables规则进行转发</td>
</tr>
<tr>
<td>NodePort</td>
<td>使用宿主机的端口,使能够访问各Node的外部客户端通过Node的IP地址和端口号就能访问服务。</td>
</tr>
<tr>
<td>LoadBalancer</td>
<td>使用外接负载均衡器完成到服务的负奉分发,需要在spec.status.loadBalancer字段指定外部负载均衡器的IP地址,并同时定义nodePort和clusterlp,用于公有云环境</td>
</tr>
</tbody></table>
<h2 id="4-2-Service的基本用法"><a href="#4-2-Service的基本用法" class="headerlink" title="4.2 Service的基本用法"></a><font color=red>4.2 Service的基本用法</font></h2><p><strong><font color=red>一般来说,对外提供服务的应用程序需要通过某种机制来实现,对于容器应用最简便的方式就是通过TCP&#x2F;IP机制及监听IP和端口号来实现。即PodIP+容器端口的方式</font></strong></p>
<p><strong><font color=yellowgreen>直接通过Pod的IP地址和端口号可以访问到容器应用内的服务,但是<code>Pod的IP地址是不可靠的</code>,如果容器应用本身是分布式的部署方式,通过多个实例共同提供服务,就需要在这些实例的前端设置一个负载均衡器来实现请求的分发。</font></strong></p>
<p><strong><font color=camel>Kubernetes中的Service就是用于解决这些问题的核心组件。通过kubectl expose命令来创建Service </font></strong></p>
<p><strong><font color=blue>新创建的Service,系统为它分配了一个虚拟的IP地址(ClusterlP) , Service所需的端口号则从Pod中的containerPort复制而来: </font></strong></p>
<p><strong><font color=yellowgreen>除了使用<code>kubectl expose</code>命令创建<code>Service</code>，我们也可以通过配置文件定义<code>Service</code>，再通过<code>kubectl create</code>命令进行创建</font></strong></p>
<p><strong><font color=brown>Service定义中的关键字段是ports和selector</font></strong> 。**<font color=royalblue>ports定义部分指定了Service所需的虚拟端口号为8081,如果与Pod容器端口号8080不一样,所以需要再通过targetPort来指定后端Pod的端口号。selector定义部分设置的是后端Pod所拥有的label: </font>**</p>
<h3 id="4-2-0负载分发策略"><a href="#4-2-0负载分发策略" class="headerlink" title="4.2.0负载分发策略"></a><font color=royalblue>4.2.0负载分发策略</font></h3><p><strong><font color=red>基于 ClusterlP 提供的两种负载分发策略</font></strong><br><strong>目前 <code>Kubernetes</code> 提供了两种负载分发策略：<code>RoundRobin和SessionAffinity</code></strong></p>
<p>|负载分发策略<br>|–|<br>|<strong><font color=green>RoundRobin</font></strong>|轮询模式,即轮询将请求转发到后端的各个Pod上。|<br>|<strong><font color=yellowgreen>SessionAffinity</font></strong>|基于客户端IP地址进行会话保持的模式,|</p>
<p><strong><font color=royalblue>在默认情况下, Kubernetes采用RoundRobin模式对客户端请求进行,负载分发,但我们也可以通过设置<code>service.spec.sessionAffinity=ClientIP</code>来启用<code>SessionAffinity</code>策略。</font></strong></p>
<h3 id="4-2-1-多端口Service"><a href="#4-2-1-多端口Service" class="headerlink" title="4.2.1 多端口Service"></a><font color=royalblue>4.2.1 多端口Service</font></h3><p><strong><font color=green>一个容器应用也可能提供多个端口的服务,那么在Service的定义中也可以相应地设置为将多个端口对应到多个应用服务。</font></strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web1</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8008</span></span><br><span class="line">  <span class="attr">targetPort:</span> <span class="number">90</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web2</span></span><br></pre></td></tr></table></figure>
<p><strong><font color=chocolate>可以两个端口号使用了不同的4层协议—TCP和UDP：</font></strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dns</span> </span><br><span class="line">  <span class="attr">port:</span> <span class="number">53</span> </span><br><span class="line">  <span class="attr">protocol:</span> <span class="string">UDP</span> </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dns-tcp</span> </span><br><span class="line">  <span class="attr">port:</span> <span class="number">53</span> </span><br><span class="line">  <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<h3 id="4-2-2-外部服务Service"><a href="#4-2-2-外部服务Service" class="headerlink" title="4.2.2 外部服务Service"></a><font color=blue>4.2.2 外部服务Service</font></h3><p><strong><font color=red>在某些环境中,应用系统需要将一个外部数据库作为后端服务进行连接,或将另一个集群或Namespace中的服务作为服务的后端,这时可.以通过创建一个无<code>Label Selector的Service</code>来实现:</font></strong> </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiversion:</span> <span class="string">v1</span> </span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">80</span> </span><br><span class="line">  <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p><strong><font color=blue>通过该定义创建的是一个<code>不带标签选择器的Service</code>,即无法选择后端的<code>Pod</code>,系统不会自动创建<code>Endpoint</code>,因此需要手动创建一个和该<code>Service同名的Endpoint</code>,用于指向实际的后端访问地址。创建Endpoint的配置文件内容如下:</font></strong> </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Endpoint</span></span><br><span class="line"><span class="attr">sapiVersion:</span> <span class="string">v1</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">addresses:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">IP:</span> <span class="number">1.2</span><span class="number">.3</span><span class="number">.4</span> </span><br><span class="line">  <span class="attr">ports:</span> </span><br><span class="line">  <span class="string">-port:</span> <span class="number">80</span> </span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>外部服务Service</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/9a01ebbbdcd645f28f09083f85d34e59.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<h2 id="4-3-Headless-Service"><a href="#4-3-Headless-Service" class="headerlink" title="4.3 Headless Service"></a><font color=chocolate>4.3 Headless Service</font></h2><p><strong><font color=seagreen>在某些应用场景中,开发人员希望自己控制负载均衡的策略,不使用Service提供的默认负载均衡的功能,或者应用程序希望知道属于同组服务的其他实例。Kubernetes提供了Headless Service来实现这种功能,即<code>不为Service设置ClusterlP (入口IP地址) ,仅通过Label Selector将后端的Pod列表返回给调用的客户端</code>。</font></strong> </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> </span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span> </span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span> </span><br></pre></td></tr></table></figure>
<p><strong><font color=seagreen>Service就不再具有一个特定的ClusterIP地址,<code>StatefulSet</code>就是使用<code>Headless Service</code>为客户端返回多个服务地址的,对于“去中心化”类的应用集群，Headless Service将非常有用</font></strong></p>
<h2 id="4-4-从集群外部访问Pod或Service-服务的发布"><a href="#4-4-从集群外部访问Pod或Service-服务的发布" class="headerlink" title="4.4 从集群外部访问Pod或Service(服务的发布)"></a><font color=orange>4.4 从集群外部访问Pod或Service(服务的发布)</font></h2><p><strong><font color=green>由于Pod和Service都是Kubernetes集群范围内的虚拟概念，所以集群外的客户端系统无法通过Pod的IP地址或者Service的虚拟IP地址和虚拟端口号访问它们。为了让外部客户端可以访问这些服务，可<code>以将Pod或Service的端口号映射到宿主机，以使客户端应用能够通过物理机访问容器应用。</code></font></strong></p>
<h4 id="4-4-1-将容器应用的端口号映射到物理机"><a href="#4-4-1-将容器应用的端口号映射到物理机" class="headerlink" title="4.4.1 将容器应用的端口号映射到物理机"></a><font color=camel>4.4.1 将容器应用的端口号映射到物理机</font></h4><p><strong><font color=amber>宿主机映射，当pod发生调度后，节点没法办运行</font></strong></p>
<p><strong><font color=red>通过设置容器级别的<code>hostPort</code>，将容器应用的端口号映射到物理机上：</font></strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">hsotPort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure>

<p><strong><font color=royalblue>通过设置<code>Pod级别</code>的<code>hostNetwork=true</code>，该Pod中所有容器的端口号都将被直接映射到物理机上。</font></strong> 在设置<code>hostNetwork=true</code>时需要注意，在容器的ports定义部分如果不指定hostPort，则默认hostPort等于containerPort，如果指定了hostPort，则hostPort必须等于containerPort的值：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">spec</span></span><br><span class="line">  <span class="attr">nostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">webapp</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">tomcat</span> </span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Never</span> </span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span> </span><br></pre></td></tr></table></figure>
<h3 id="4-4-2-将Service的端口号映射到物理机"><a href="#4-4-2-将Service的端口号映射到物理机" class="headerlink" title="4.4.2 将Service的端口号映射到物理机"></a><font color=chocolate>4.4.2 将Service的端口号映射到物理机</font></h3><p><strong><font color=amber>通过设置nodePort映射到物理机，同时设置Service的类型为NodePort：</font></strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiversion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">webapp</span> </span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> </span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">port：</span> <span class="number">808</span> </span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">8080</span> </span><br><span class="line">    <span class="attr">selector:app:</span> <span class="string">webapp</span> </span><br></pre></td></tr></table></figure>
<p>**<font color=orange>通过设置LoadBalancer映射到云服务商提供的LoadBalancer地址</font>**。</p>
<h2 id="4-5-DNS服务搭建和配置指南"><a href="#4-5-DNS服务搭建和配置指南" class="headerlink" title="4.5 DNS服务搭建和配置指南"></a><font color=brown>4.5 DNS服务搭建和配置指南</font></h2><p>**<font color=red>作为服务发现机制的基本功能,在集群内需要能够通过服务名对服务进行访问,这就需要一个集群范围内的DNS服务来完成从服务名到ClusterlP的解析</font>**。</p>
<table>
<thead>
<tr>
<th>阶段</th>
<th>DNS服务在Kubernetes的发展过程中经历了3个阶段</th>
</tr>
</thead>
<tbody><tr>
<td>在Kubernetes 1.2版本时</td>
<td>DNS服务是由SkyDNS提供的,它由4个容器组成: kube2sky、skydns, etcd和healthz, kube2sky容器监控Kubernetes中Service资源的变化,根据Service的名称和P地址信息生成DNS记录,并将其保存到etcd中; skydns容器从etcd中读取DNS记录,并为客户端容器应用提供DNS查询服务; healthz容器提供对skydns服务的建康检查功能。图4.3展现了SkyDNS的总体架构。</td>
</tr>
<tr>
<td>从Kubernetes 1.4版本开始</td>
<td>SkyDNS组件便被KubeDNS替换,主要考虑是SkyDNS组件之间通信较多,整体性能不高。KubeDNS由3个容器组成: kubedns、 dnsmasq和sidecar,去掉了SkyDNS中的etcd存储,将DNS记录直接保存在内存中,以提高查询性能。kubedns容器监控Kubernetes中Service资源的变化,根据Service的名称和IP地址生成DNS记录,并将DNS记录保存在内存中; dnsmasq容器从kubedns中获取DNS记录,提供DNS缓存,为客户端容器应用提供DNS查询服务; sidecar提供对kubedns和dnsmasq服务的健康检查功能。</td>
</tr>
<tr>
<td>从Kubernetes 1.11版本开始</td>
<td>Kubernetes集群的DNS服务由CoreDNS提供。CoreDNS是CNCF基金会的一个项目,是用Go语言实现的高性能、插件式、易扩展的DNS服务端。CoreDNS解决了KubeDNS的一些问题,例如dnsmasq的安全漏洞、externalName不能使用stubDomains设置,等等。CoreDNS支持自定义DNS记录及配置upstream DNS Server,可以统一管理Kubernetes基于服务的内部DNS和数据中心的物理DNS</td>
</tr>
</tbody></table>
<h2 id="4-6-Ingress：HTTP-7层路由机制"><a href="#4-6-Ingress：HTTP-7层路由机制" class="headerlink" title="4.6 Ingress：HTTP 7层路由机制"></a><font color=brown>4.6 Ingress：HTTP 7层路由机制</font></h2><p><strong><font color=camel>Service的表现形式为<code>IP:Port</code>,即工作在<code>TCP/IP</code>层。</font></strong></p>
<p><strong><font color=orange>对于基于<code>HTTP</code>的服务来说,不同的<code>URL</code>地址经常对应到不同的后端服务或者<code>虚拟服务器(Virtual Host)</code>这些应用层的转发机制仅通过<code>Kubernetes</code>的<code>Service</code>机制是无法实现的。</font></strong></p>
<p><strong><font color=green>从<code>Kubernetes 1.1</code>版本开始新增<code>Ingress资源对象</code>,用于将<code>不同URL</code>的访问请求转发到后端不同的<code>Service</code>,以实现<code>HTTP层的业务路由机制</code>。但是并不是说只能做7层路由，四层负载也可以</font></strong></p>
<p><strong><font color=chocolate>Kubernetes使用了一个Ingress策略定义和一个具体的Ingress Controller,两者结合并实现了一个完整的Ingress负载均衡器。</font></strong></p>
<blockquote>
<p><font color=blue>使用Ingress进行负载分发时是不是和kube-proxy没啥关系，直接分发到pod上了，使用Load Balancer和nodeport才会使用kube-proxy ?</font></p>
</blockquote>
<p><strong><font color=amber>使用<code>Ingress</code>进行负载分发时, <code>Ingress Controller</code>基于<code>Ingress规则</code>将客户端请求直接转发到<code>Service对应的后端Endpoint (Pod)</code>上,这样会跳过<code>kube-proxy</code>的转发功能, <code>kube-proxy</code>不再起作用。如果<code>IngressController</code>提供的是对外服务,则实际上实现的是边缘路由器的功能。   《Kubernetes权威指南》中的描述</font></strong></p>
<blockquote>
<p><strong><font color=purple>控制器通过svc获取endpoints并获取对应的pod信息，然后通过nginx内部的lua代码进行处理</font></strong></p>
</blockquote>
<p><strong><font color=tomato>为使用Ingress，需要创建<code>Ingress Controller</code>(带一个默认<code>backend</code>服务)和<code>Ingress策略</code>设置来共同完成。下面通过一个例子分三步说明<code>Ingress Controller和Ingress策略的配置方法</code>，以及<code>客户端如何访问Ingress提供的服务</code>。</font></strong></p>
<h3 id="4-6-1-创建Ingress-Controller和默认的backend服务"><a href="#4-6-1-创建Ingress-Controller和默认的backend服务" class="headerlink" title="4.6.1 创建Ingress Controller和默认的backend服务"></a><font color=brown>4.6.1 创建Ingress Controller和默认的backend服务</font></h3><p><strong><font color=purple>在定义<code>Ingress策略</code>之前,需要先<code>部署Ingress Controller</code>,以实现为所有<code>后端Service</code>都提供一个<code>统一的入口</code>。<code>Ingress Controller</code>需要实现基于不同<code>HTTP URL</code>向后转发的负载分发规则,并可以灵活<code>设置7层负载分发策略</code>。</font></strong></p>
<p>如果公有云服务商能够提供该类型的<code>HTTP路由LoadBalancer</code>,则也可设置其为<code>Ingress Controller</code>。在<code>Kubernetes</code>中, <code>Ingress Controller</code>将以<code>Pod</code>的形式运行,监控<code>APIServer的/ingress接口后端的backend services</code>,如果<code>Service</code>发生变化,则<code>Ingress Controller</code>应自动更新其转发规则。</p>
<h1 id="第3章Kubernetes核心原理"><a href="#第3章Kubernetes核心原理" class="headerlink" title="第3章Kubernetes核心原理"></a><font color="009688">第3章Kubernetes核心原理</font></h1><h2 id="3-1-Kubernetes-API-Server原理分析"><a href="#3-1-Kubernetes-API-Server原理分析" class="headerlink" title="3.1 Kubernetes API Server原理分析"></a><font color=seagreen>3.1 Kubernetes API Server原理分析</font></h2><p>官网很详细，小伙伴系统学习可以到官网：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/tasks/administer-cluster/access-cluster-api/">https://kubernetes.io/zh/docs/tasks/administer-cluster/access-cluster-api/</a></p>
<p><strong><font color=purple> <code>Kubernetes API Server</code>的核心功能是提供了Kubernetes各类资源对象(如Pod,RC, Service等)的增、删、改、查及Watch等HTTP Rest接口,成为集群内各个功能模块之间数据交互和通信的中心枢纽,是整个系统的数据总线和数据中心。除此之外,它还有以下一些功能特性。</font></strong></p>
<p><strong><font color=orange>(1)是集群管理的API入口。</font></strong></p>
<p><strong><font color=tomato>(2)是资源配额控制的入口。</font></strong></p>
<p><strong><font color=royalblue>(3)提供了完备的集群安全机制。</font></strong></p>
<h3 id="3-1-1-Kubernetes-API-Server-概述"><a href="#3-1-1-Kubernetes-API-Server-概述" class="headerlink" title="3.1.1 Kubernetes API Server 概述"></a><font color=green>3.1.1 Kubernetes API Server 概述</font></h3><p><strong><font color=purple><code>Kubernetes API Server</code>通过一个名为<code>kube-apiserver</code>的进程提供服务,该进程运行在<code>Master节点</code>上,如果小伙伴使用二进制方式安装k8s，会发现，kube-apiserver是docker之后第一个要启动的服务</font></strong></p>
<p><strong><font color=chocolate>旧版本中<code>kube-apiserver</code>进程在本机的<code>8080</code>端口(对应参数<code>-insecure-port</code>)提供REST服务。</font></strong></p>
<p><strong><font color=orange>新版本中启动HTTPS安全端口(<code>--secure-port=6443</code>)来启动安全机制,加强REST API访问的安全性。这里需要说明的是，好像是从1.20开始就不支持了，在apiserver配置文件里添加 –insecure-port&#x3D;8080会导致启动不了，所以不在支持直接http的方式访问(可以用代理)</font></strong></p>
<p><strong><font color=amber>在高版本的环境中，有时候环境起不来，会报错说6443端口没有开放</font></strong></p>
<p><strong><font color=tomato>通常我们可以通过命令行工具<code>kubectl</code>来与<code>Kubernetes API Server</code>交互,它们之间的接口是<code>REST</code>调用。</font></strong></p>
<h4 id="使用-kubectl-代理"><a href="#使用-kubectl-代理" class="headerlink" title="使用 kubectl 代理"></a><font color=brown>使用 kubectl 代理</font></h4><p><strong><font color=chocolate>如果我们只想对外暴露部分<code>REST</code>服务,则可以在<code>Master</code>或其他任何节点上通过运行<code>kubect proxy</code>进程启动一个内部代理来实现。</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$kubectl</span> proxy --port=8080 &amp;</span><br><span class="line">[1] 43454</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$Starting</span> to serve on 127.0.0.1:8080</span><br><span class="line"></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$curl</span> http://localhost:8080/api/ &gt; kubeapi</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100   185  100   185    0     0   2863      0 --:--:-- --:--:-- --:--:--  2936</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$head</span> -20 kubeapi</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;APIVersions&quot;</span>,</span><br><span class="line">  <span class="string">&quot;versions&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;v1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;serverAddressByClientCIDRs&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;clientCIDR&quot;</span>: <span class="string">&quot;0.0.0.0/0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;serverAddress&quot;</span>: <span class="string">&quot;192.168.26.81:6443&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$jobs</span></span><br><span class="line">[1]+  Running                 kubectl proxy --port=8080 &amp;</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$fg</span></span><br><span class="line">kubectl proxy --port=8080</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>
<p><strong><font color=red>当然,我们也可以拒绝访问某一资源，比如pod</font></strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$kubectl proxy  --reject-paths=&quot;^/api/v1/pod&quot; --port=8080 --v=1 &amp;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$curl http://localhost:8080/api/v1/pods</span><br><span class="line">Forbidden</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$curl http://localhost:8080/api/v1/configmaps &gt; $(mktemp kube.XXXXXX)</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 25687    0 25687    0     0   644k      0 --:--:-- --:--:-- --:--:--  660k</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$head  -5 kube.zYxKiH</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;ConfigMapList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;81890&quot;</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$curl http://localhost:8080/api/v1/secrets | head -5</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;SecretList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;82039&quot;</span><br><span class="line">100 65536    0 65536    0     0  1977k      0 --:--:-- --:--:-- --:--:-- 2064k</span><br><span class="line">curl: (23) Failed writing body (0 != 16378)</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$</span><br></pre></td></tr></table></figure>
<p><strong><font color=green>kubectl proxy具有很多特性,最实用的一个特性是提供简单有效的安全机制,比如采用白名单来限制非法客户端访问时,只要增加下面这个参数即可:</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--accept-hosts=<span class="string">&quot;^localhost$, ^127\\.0\\.0\\.1$,^\\[::1\\]$&quot;</span></span><br></pre></td></tr></table></figure>


<h4 id="不使用-kubectl-代理"><a href="#不使用-kubectl-代理" class="headerlink" title="不使用 kubectl 代理"></a><font color=seagreen>不使用 kubectl 代理</font></h4><p><strong><font color=tomato>通过将身份认证令牌直接传给 API 服务器，可以避免使用 kubectl 代理，像这样：</font></strong></p>
<p>使用 grep&#x2F;cut 方式：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有的集群，因为你的 .kubeconfig 文件中可能包含多个上下文</span></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$kubectl</span> config view -o jsonpath=<span class="string">&#x27;&#123;&quot;Cluster name\tServer\n&quot;&#125;&#123;range .clusters[*]&#125;&#123;.name&#125;&#123;&quot;\t&quot;&#125;&#123;.cluster.server&#125;&#123;&quot;\n&quot;&#125;&#123;end&#125;&#x27;</span></span><br><span class="line">Cluster name    Server</span><br><span class="line">kubernetes      https://192.168.26.81:6443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从上述命令输出中选择你要与之交互的集群的名称</span></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$export</span> CLUSTER_NAME=kubernetes</span><br><span class="line"><span class="comment"># 指向引用该集群名称的 API 服务器</span></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$APISERVER</span>=$(kubectl config view -o jsonpath=<span class="string">&quot;&#123;.clusters[?(@.name==\&quot;<span class="variable">$CLUSTER_NAME</span>\&quot;)].cluster.server&#125;&quot;</span>)</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$echo</span> <span class="variable">$APISERVER</span></span><br><span class="line">https://192.168.26.81:6443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得令牌</span></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$TOKEN</span>=$(kubectl  get secret  default-token-xg77h -o jsonpath=<span class="string">&#x27;&#123;.data.token&#125;&#x27;</span> -n kube-system | base64 -d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用令牌玩转 API</span></span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$curl</span> -X GET <span class="variable">$APISERVER</span>/api --header <span class="string">&quot;Authorization: Bearer <span class="variable">$TOKEN</span>&quot;</span> --insecure</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;APIVersions&quot;</span>,</span><br><span class="line">  <span class="string">&quot;versions&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;v1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;serverAddressByClientCIDRs&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;clientCIDR&quot;</span>: <span class="string">&quot;0.0.0.0/0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;serverAddress&quot;</span>: <span class="string">&quot;192.168.26.81:6443&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="编程方式访问-API"><a href="#编程方式访问-API" class="headerlink" title="编程方式访问 API"></a><font color=seagreen>编程方式访问 API</font></h4><h5 id="python"><a href="#python" class="headerlink" title="python"></a><font color=chocolate>python</font></h5><p><strong><font color=plum>要使用 Python 客户端，运行下列命令： pip install kubernete</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PS E:\docker&gt; pip install kubernetes</span><br><span class="line">Collecting kubernetes</span><br><span class="line">  Using cached kubernetes-21.7.0-py2.py3-none-any.whl (1.8 MB)</span><br><span class="line">  ............</span><br></pre></td></tr></table></figure>
<p><strong><font color=green>将 ~&#x2F;.kube 的config文件的内容复制到本地目录，保存为文件kubeconfig.yaml</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$cp</span> .kube/config    kubeconfig.yaml</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>python</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/8aaf37331ff4433a9fd59bab6085fd1c.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@File    :   k8s_api.py</span></span><br><span class="line"><span class="string">@Time    :   2021/12/16 23:05:02</span></span><br><span class="line"><span class="string">@Author  :   Li Ruilong</span></span><br><span class="line"><span class="string">@Version :   1.0</span></span><br><span class="line"><span class="string">@Contact :   1224965096@qq.com</span></span><br><span class="line"><span class="string">@Desc    :   K8s Demo</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here put the import lib</span></span><br><span class="line"><span class="keyword">from</span> kubernetes <span class="keyword">import</span> client, config</span><br><span class="line"></span><br><span class="line">config.kube_config.load_kube_config(config_file=<span class="string">&quot;kubeconfig.yaml&quot;</span>)</span><br><span class="line"></span><br><span class="line">v1=client.CoreV1Api()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Listing pods with their IPs:&quot;</span>)</span><br><span class="line">ret = v1.list_pod_for_all_namespaces(watch=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ret.items:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s\t%s&quot;</span> % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))</span><br></pre></td></tr></table></figure>
<p><strong><font color=royalblue>输出所有的pod和对应的node IP</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PS D:\code\blogger\blogger\资源&gt; python .\k8s_api.py</span><br><span class="line">Listing pods with their IPs:</span><br><span class="line">10.244.88.67    kube-system     calico-kube-controllers-78d6f96c7b-85rv9</span><br><span class="line">192.168.26.81   kube-system     calico-node-6nfqv</span><br><span class="line">192.168.26.83   kube-system     calico-node-fv458</span><br><span class="line">192.168.26.82   kube-system     calico-node-h5lsq</span><br><span class="line">.................</span><br></pre></td></tr></table></figure>
<h5 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 克隆 Java 库</span></span><br><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/kubernetes-client/java</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>java的客户端</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/a75a5340152e491b98e429b336a38fec.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.kubernetes.client.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.ApiClient;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.ApiException;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.Configuration;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.apis.CoreV1Api;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.models.V1Pod;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.openapi.models.V1PodList;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.util.ClientBuilder;</span><br><span class="line"><span class="keyword">import</span> io.kubernetes.client.util.KubeConfig;</span><br><span class="line"><span class="keyword">import</span> java.io.FileReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A simple example of how to use the Java API from an application outside a kubernetes cluster</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;Easiest way to run this: mvn exec:java</span></span><br><span class="line"><span class="comment"> * -Dexec.mainClass=&quot;io.kubernetes.client.examples.KubeConfigFileClientExample&quot;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;From inside $REPO_DIR/examples</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KubeConfigFileClientExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ApiException </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// file path to your KubeConfig</span></span><br><span class="line">    String kubeConfigPath = <span class="string">&quot;D:\\code\\k8s\\java\\examples\\examples-release-10\\src\\main\\java\\io\\kubernetes\\client\\examples\\config&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// loading the out-of-cluster config, a kubeconfig from file-system</span></span><br><span class="line">    ApiClient client =</span><br><span class="line">        ClientBuilder.kubeconfig(KubeConfig.loadKubeConfig(<span class="keyword">new</span> FileReader(kubeConfigPath))).build();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set the global default api-client to the in-cluster one from above</span></span><br><span class="line">    Configuration.setDefaultApiClient(client);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the CoreV1Api loads default api-client from global configuration.</span></span><br><span class="line">    CoreV1Api api = <span class="keyword">new</span> CoreV1Api();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// invokes the CoreV1Api client</span></span><br><span class="line">    V1PodList list =</span><br><span class="line">        api.listPodForAllNamespaces(<span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">for</span> (V1Pod item : list.getItems()) &#123;</span><br><span class="line">      System.out.println(item.getMetadata().getName());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong><font color=purple>输出所有pod</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">D:\Java\jdk1.8.0_251\bin\java.exe 。。。</span><br><span class="line">SLF4J: Failed to load class <span class="string">&quot;org.slf4j.impl.StaticLoggerBinder&quot;</span>.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#StaticLoggerBinder for further details.</span></span><br><span class="line">Bad level value <span class="keyword">for</span> property: .level</span><br><span class="line">Bad level value <span class="keyword">for</span> property: java.util.logging.ConsoleHandler.level</span><br><span class="line">calico-kube-controllers-78d6f96c7b-85rv9</span><br><span class="line">calico-node-6nfqv</span><br><span class="line">calico-node-fv458</span><br><span class="line">calico-node-h5lsq</span><br><span class="line">coredns-7f6cbbb7b8-ncd2s</span><br><span class="line">coredns-7f6cbbb7b8-pjnct</span><br><span class="line">etcd-vms81.liruilongs.github.io</span><br><span class="line">。。。。。。。。。</span><br></pre></td></tr></table></figure>
<h5 id="node"><a href="#node" class="headerlink" title="node"></a>node</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">const k8s = require(<span class="string">&#x27;@kubernetes/client-node&#x27;</span>);</span><br><span class="line"></span><br><span class="line">const kc = new k8s.KubeConfig();</span><br><span class="line">kc.loadFromDefault();</span><br><span class="line"></span><br><span class="line">const k8sApi = kc.makeApiClient(k8s.CoreV1Api);</span><br><span class="line"></span><br><span class="line">k8sApi.listNamespacedPod(<span class="string">&#x27;default&#x27;</span>).<span class="keyword">then</span>((res) =&gt; &#123;</span><br><span class="line">    console.log(res.body);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-独特的Kubernetes-Proxy-API接口"><a href="#3-1-2-独特的Kubernetes-Proxy-API接口" class="headerlink" title="3.1.2 独特的Kubernetes Proxy API接口"></a><font color=chocolate>3.1.2 独特的Kubernetes Proxy API接口</font></h3><p><strong><font color=camel><code>Kubernetes Proxy API</code>接口,作用是代理REST请求,即<code>Kubernetes API Server</code>把收到的<code>REST</code>请求转发到某个<code>Node</code>上的<code>kubelet·</code>守护进程的<code>REST</code>端口上,由该<code>kubelet</code>进程负责响应。</font></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$kubectl</span>  proxy  8080 &amp;</span><br><span class="line">[1] 76543</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$Starting</span> to serve on 127.0.0.1:8001</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$kubectl</span>  get nodes</span><br><span class="line">NAME                         STATUS     ROLES                  AGE   VERSION</span><br><span class="line">vms81.liruilongs.github.io   Ready      control-plane,master   4d    v1.22.2</span><br><span class="line">vms82.liruilongs.github.io   Ready      &lt;none&gt;                 4d    v1.22.2</span><br><span class="line">vms83.liruilongs.github.io   NotReady   &lt;none&gt;                 4d    v1.22.2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$curl</span> http://localhost:8001/api/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;APIVersions&quot;</span>,</span><br><span class="line">  <span class="string">&quot;versions&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;v1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;serverAddressByClientCIDRs&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;clientCIDR&quot;</span>: <span class="string">&quot;0.0.0.0/0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;serverAddress&quot;</span>: <span class="string">&quot;192.168.26.81:6443&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─$</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$curl</span> http://localhost:8001/api/v1/namespaces/default/pods</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;PodList&quot;</span>,</span><br><span class="line">  <span class="string">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,</span><br><span class="line">  <span class="string">&quot;metadata&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;resourceVersion&quot;</span>: <span class="string">&quot;92086&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;items&quot;</span>: []</span><br><span class="line">&#125;</span><br><span class="line">┌──[root@vms81.liruilongs.github.io]-[~]</span><br><span class="line">└─<span class="variable">$curl</span> http://localhost:8080/api/v1/nodes/vms82.liruilongs.github.io/</span><br></pre></td></tr></table></figure>

<p><strong><font color=green>需要说明的是:这里获取的Pod的信息数据来自Node而非etcd数据库,所以两者可能在·某些时间点会有偏差。此外,如果kubelet进程在启动时包含<code>-enable-debugging-handlers=true</code>参数,那么<code>Kubernetes Proxy API</code>还会增加其他的接口信息 </font></strong></p>
<h3 id="3-1-3-集群功能模块之间的通信"><a href="#3-1-3-集群功能模块之间的通信" class="headerlink" title="3.1.3 集群功能模块之间的通信"></a><font color=tomato>3.1.3 集群功能模块之间的通信</font></h3><p><strong><font color=red>Kubernetes API Server</font></strong> 作为集群的核心,负责集群各功能模块之间的通信。集群内的各个功能模块通过API Server将信息存入etcd,当需要获取和操作这些数据时,则通过<code>API Server</code>提供的<code>REST接口</code>(用GET, LIST或WATCH方法)来实现,从而实现各模块之间的信息交互。</p>
<h4 id="交互场景"><a href="#交互场景" class="headerlink" title="交互场景:"></a><font color=orange>交互场景</font>:</h4><p><strong><font color=amber><code>kubelet</code>进程与<code>API Server</code>的交互</font></strong> <code>每个Node节点上的kubelet每隔一个时间周期,就会调用一次API Server的REST接口报告自身状态</code>, <strong><font color=yellowgreen>API Server接收到这些信息后,将节点状态信息更新到etcd中。</font></strong> , <strong><font color=tomato>kubelet也通过API Server的<code>Watch接口监听Pod信息</code>,如果监听到新的Pod副本被调度绑定到本节点,则执行Pod对应的容器的创建和启动逻辑;如果监听到Pod对象被删除,则删除本节点上的相应的Pod容器;如果监听到修改Pod信息,则kubelet监听到变化后,会相应地修改本节点的Pod容器。</font></strong></p>
<p><strong><font color=amber><code>kube-controller-manager</code>进程与<code>API Server</code>的交互。</font></strong> <strong><font color=tomato><code>kube-controller-manager</code>中的<code>Node Controller</code>模块通过<code>API Sever</code>提供的<code>Watch</code>接口,实时监控<code>Node</code>的信息,并做相应处理</font></strong></p>
<p><strong><font color=amber><code>kube-scheduler</code>与<code>API Server</code>的交互</font><strong>。</strong><font color=tomato>当Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后,它会检索所有符合该Pod要求的Node列表,开始执行Pod调度逻辑,调度成功后将Pod绑定到目标节点上。</font></strong></p>
<p><strong><font color=orange>为了缓解集群各模块对API Server的访问压力,各功能模块都采用缓存机制来缓存数据。各功能模块定时从API Server获取指定的资源对象信息(通过<code>LIST</code>及<code>WATCH</code>方法),然后将这些信息保存到本地缓存,功能模块在某些情况下不直接访问API Server,而是通过访问缓存数据来间接访问API Server.</font></strong></p>
<h2 id="3-2-Controller-Manager-原理分析"><a href="#3-2-Controller-Manager-原理分析" class="headerlink" title="3.2 Controller Manager 原理分析"></a><font color=amber>3.2 Controller Manager 原理分析</font></h2><p><strong><font color=purple><code>Controller Manager</code>作为集群内部的<code>管理控制中心</code>,负责集群内的<code>Node,Pod副本</code>、<code>服务端点(Endpoint)</code>、<code>命名空间(Namespace)</code>、服<code>务账号(ServiceAccount)</code>、资<code>源定额(ResourceQuota)</code>等的管理,当某个<code>Node意外宕机</code>时, Controller Manager会及时发现此故障并执行<code>自动化修复流程</code>,确保集群始终处于<code>预期的工作状态</code>。</font></strong></p>
<p><strong><font color=yellowgreen><code>Controller Manager</code>内部包含<code>Replication Controller</code>, <code>Node Controller</code>, <code>ResourceQuota Controller</code>, <code>Namespace Controller</code>, <code>ServiceAccount Controller</code>, <code>Token Controller</code>,<code>Service Controller</code>及<code>Endpoint Controller</code>等多个Controller,每种Controller都负责一种具体的控制流程,而<code>Controller Manager</code>正是这些Controller的核心管理者。</font></strong></p>
<h3 id="3-2-1-Replication-Controller"><a href="#3-2-1-Replication-Controller" class="headerlink" title="3.2.1 Replication Controller"></a><font color=chocolate>3.2.1 Replication Controller</font></h3><p>在新版的K8s中,RC用的相对来说少了,更多是用deploy来创建多个pod副本,这里我们也简单学习下.</p>
<p><strong><font color=yellowgreen><code>Replication Controller</code>的核心作用是确保在任何时候集群中<code>一个RC所关联的Pod副本数量保持预设值</code>。</font></strong></p>
<p><strong><font color=yellowgreen>需要注意的一点是:</font></strong> 只有当Pod的重启策略是Always时(RestartPolicy&#x3D;Always), Replication Controller才会管理该Pod的操作(例如创建、销毁、重启等)</p>
<p><strong><font color=blue><code>RC </code>中的<code>pod模板</code>一旦创建完成，就和RC中的模板没有任何关系。</font></strong>,Pod可以通过修改标签来实现脱离RC的管控。可以用于 **<font color=blue>将Pod从集群中迁移、数据修复等调试</font>**。</p>
<p><strong><font color=amber>对于被迁移的<code>Pod</code>副本, <code>RC</code>会自动创建一个新的,副本替换被迁移的副本。需要注意的是,删除一个RC不会影响它所创建的Pod,如果想删除一个RC所控制的Pod,则需要将该RC的副本数(Replicas)属性设置为0,这样所有的Pod副本都会被自动删除。</font></strong></p>
<h4 id="Replication-Controller的职责"><a href="#Replication-Controller的职责" class="headerlink" title="Replication Controller的职责:"></a><code>Replication Controller</code>的职责:</h4><table>
<thead>
<tr>
<th><code>Replication Controller</code>的职责</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=purple>确保当前集群中有且仅有N个Pod实例, N是RC中定义的Pod副本数量。</font></strong></td>
</tr>
<tr>
<td><strong><font color=yellowgreen>通过调整RC的spec.replicas属性值来实现系统扩容或者缩容。</font></strong></td>
</tr>
<tr>
<td><strong><font color=royalblue>通过改变RC中的Pod模板(主要是镜像版本)来实现系统的滚动升级。</font></strong></td>
</tr>
</tbody></table>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a><font color=amber>使用场景</font></h4><table>
<thead>
<tr>
<th>使用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong><font color=yellowgreen>重新调度(Rescheduling)：副本控制器都能确保指定数量的副本存在于集群中</font></strong></td>
</tr>
<tr>
<td><strong><font color=purple>弹性伸缩(Scaling),手动或者通过自动扩容代理修改副本控制器的spec.replicas属性值,非常容易实现扩大或缩小副本的数量。</font></strong></td>
</tr>
<tr>
<td><strong><font color=yellowgreen>滚动更新(Rolling Updates),副本控制器被设计成通过逐个替换Pod的方式来辅助服务的滚动更新。即现在的deployment资源的作用，通过新旧两个RC 实现滚动更新</font></strong></td>
</tr>
</tbody></table>
<h3 id="3-2-2-Node-Controller"><a href="#3-2-2-Node-Controller" class="headerlink" title="3.2.2 Node Controller"></a><font color=yellowgreen>3.2.2 Node Controller</font></h3><p><strong><font color=yellowgreen><code>kubelet</code>进程在启动时通过<code>API Server</code>注册自身的节点信息,并定时向<code>API Server</code>汇报状态信息, <code>API Server</code>接收到这些信息后,将这些信息更新到<code>etcd</code>中, <code>etcd</code>中存储的节点信息包括<code>节点健康状况</code>、<code>节点资源</code>、<code>节点名称</code>、<code>节点地址信息</code>、<code>操作系统版本</code>、<code>Docker版本</code>、<code>kubelet版本等</code>。</font></strong></p>
<p><strong><font color=yellowgreen>节点健康状况包含<code>“就绪” (True)</code> <code>“未就绪” (False)</code>和<code>“未知&quot; (Unknown)</code>三种。</font></strong></p>
<p><strong><font color=yellowgreen><code>Node Controller</code>通过<code>API Server</code>实时获取<code>Node</code>的相关信息,实现管理和监控集群中的各个Node节点的相关控制功能, Node Controller的核心工作流程如图。</font></strong></p>
<table>
<thead>
<tr>
<th><font color=blue>Node Controller的核心工作流程如图</font></th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/b94176e1e73f4bc194ef27fbefab55dc.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<p><strong><font color=tomato><code>Controller Manager</code>在启动时如果设置了<code>-cluster-cidr</code>参数,那么为每个没有设置<code>Spec.PodCIDR</code>的Node节点生成一个<code>CIDR</code>地址,并用该<code>CIDR</code>地址设置节点的<code>Spec.PodCIDR</code>属性,这样做的目的是防止不同节点的<code>CIDR</code>地址发生冲突。</font></strong></p>
<p><strong><font color=royalblue>逐个读取节点信息,多次尝试修改<code>nodestatusMap</code>中的节点状态信息,将该节点信息和<code>Node Controller</code>的<code>nodeStatusMap</code>中保存的节点信息做比较。</font></strong></p>
<table>
<thead>
<tr>
<th>节点状态</th>
</tr>
</thead>
<tbody><tr>
<td>如果判断出<code>没有收到kubelet发送的节点信息</code>、第1次收到节点<code>kubelet</code>发送的节点信息,或在该处理过程中节点状态变成非“健康”状态</td>
</tr>
<tr>
<td>则在nodeStatusMap中<code>保存该节点的状态信息</code>,并用Node Controller所在节点的系统时间作为探测时间和节点状态变化时间。</td>
</tr>
<tr>
<td>如果判断出在指定时间内<code>收到新的节点信息</code>,且<code>节点状态发生变化</code></td>
</tr>
<tr>
<td>则在nodeStatusMap中<code>保存该节点的状态信息</code>,并用NodeController所在节点的系统时间作为探测时间和节点状态变化时间。</td>
</tr>
<tr>
<td>如果判断出在指定时间内<code>收到新的节点信息</code>,但<code>节点状态没发生变化</code></td>
</tr>
<tr>
<td>则在nodeStatusMap中<code>保存该节点的状态信息</code>,并用Node Controller所在节点的系统时间作为探测时间,用上次节点信息中的节点状态变化时间作为该节点的状态变化时间。</td>
</tr>
<tr>
<td>如果判断出在某一段时间(gracePeriod)内<code>没有收到节点状态信息</code></td>
</tr>
<tr>
<td>则<code>设置节点状态为“未知” (Unknown),并且通过API Server保存节点状态</code>。</td>
</tr>
</tbody></table>
<p><strong><font color=amber>如果节点状态变为<code>非“就绪”状态</code>,则将<code>节点加入待删除队列</code>,,否则将<code>节点从该队列中删除</code>。</font></strong></p>
<p><strong><font color=green>如果节点状态为<code>非“就绪”状态</code>,且系统指定了<code>Cloud Provider</code>,则<code>Node Controller </code>调用<code>Cloud Provider</code>查看节点,若发现节点故障,则删除etcd中的节点信息,并删除和该节点相关的Pod等资源的信息。<br></font></strong></p>
<h3 id="3-2-3-ResourceQuota-Controller"><a href="#3-2-3-ResourceQuota-Controller" class="headerlink" title="3.2.3 ResourceQuota Controller"></a><font color=orange>3.2.3 ResourceQuota Controller</font></h3><p> <strong><font color=green><code>Kubernetes</code>提供了资源配额管理( <code>ResourceQuotaController</code>),确保了指定的资源对象在任何时候都不会超量占用系统物理资源,导致整个系统运行紊乱甚至意外宕机,对整个集群的平稳运行和稳定性有非常重要的作用。</font></strong></p>
<h4 id="Kubernetes支持资源配额管理。"><a href="#Kubernetes支持资源配额管理。" class="headerlink" title="Kubernetes支持资源配额管理。"></a><font color=tomato>Kubernetes支持资源配额管理。</font></h4><p><strong><font color=plum> <code>容器级别</code>,可以对CPU和Memory进行限制。</font></strong></p>
<p><strong><font color=orange> <code>Pod级别</code>,可以对一个Pod内所有容器的可用资源进行限制。</font></strong></p>
<p><strong><font color=plum><code>Namespace</code>级别,为Namespace (多租户)级别的资源限制,Pod数量;Replication Controller数量; Service数量;ResourceQuota数量;Secret 数量;可持有的PV (Persistent Volume)数量。 </font></strong></p>
<p><strong><font color=green>Kubernetes的配额管理是通过<code>Admission Control (准入控制)</code>来控制的,<code> Admission Control</code>当前提供了两种方式的配额约束，分别是<code>LimitRanger</code>与<code>ResourceQuota</code>。其中</font></strong></p>
<ul>
<li><strong><font color=orange><code>LimitRanger</code>作用于<code>Pod和Container</code>上,</font></strong></li>
<li><strong><font color=blue><code>ResourceQuota</code>则作用于<code>Namespace</code>上,限定一个<code>Namespace</code>里的各类资源的使用总额。</font></strong></li>
</ul>
<blockquote>
<p>如果在<code>Pod定义</code>中同时声明了<code>LimitRanger</code>,则用户通过<code>API Server</code>请求创建或修改资源时, <code>Admission Control</code>会计算当前配额的使用情况,如果不符合配额约束,则创建对象失败。</p>
</blockquote>
<blockquote>
<p>对于定义了<code>ResourceQuota</code>的<code>Namespace</code>, <code>ResourceQuota Controller</code>组件则负责<code>定期统计和生成该Namespace下</code>的各类对象的资源使用总量,统计结果包括<code>Pod, Service,RC、Secret和Persistent Volume</code>等对象实例个数,以及该<code>Namespace</code>下所有<code>Container</code>实例所使用的<code>资源量(目前包括CPU和内存)</code>,然后将这些统计结果写入<code>etcd</code>的<code>resourceQuotaStatusStorage</code>目录(<code>resourceQuotas/status</code>)中。</p>
</blockquote>
<table>
<thead>
<tr>
<th>ResourceQuota Controller 流程圖</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/392c0879011a4819b4ea3dc3f97eb5b5.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<h3 id="3-2-4-Namespace-Controller"><a href="#3-2-4-Namespace-Controller" class="headerlink" title="3.2.4 Namespace Controller"></a><font color=green>3.2.4 Namespace Controller</font></h3><p><strong><font color=blue>通过API Server可以创建新的Namespace并保存在etcd中, <code>Namespace Controller</code>定时通过<code>API Server</code>读取这些Namespace信息。</font></strong></p>
<table>
<thead>
<tr>
<th><strong><font color=brown>删除步骤</font></strong></th>
</tr>
</thead>
<tbody><tr>
<td>如果Namespace被API标识为<code>优雅删除</code>(<code>通过设置删除期限,即DeletionTimestamp属性被设置</code>),则将该NameSpace的状态设置成”<code>Terminating</code>“并保存到<code>etcd</code>中。同时Namespace Controller删除该Namespace下的ServiceAccount, RC, Pod.Secret, PersistentVolume, ListRange, ResourceQuota和Event等 **<font color=purple>资源对象</font>**。</td>
</tr>
<tr>
<td>当<code>Namespace</code>的状态被设置成”<code>Terminating</code>“后,由<code>Admission Controller</code>的<code>NamespaceLifecycle</code>插件来 <strong><font color=purple>阻止</font></strong> 为该<code>Namespace</code>创建新的资源。</td>
</tr>
<tr>
<td>在<code>Namespace Controller</code>删除完该<code>Namespace</code>中的所有<code>资源对象</code>后, <code>Namespace Controller</code>对该<code>Namespace</code>执行<code>finalize</code>操作,删除<code>Namespace</code>的<code>spec.finalizers域</code>中的信息</td>
</tr>
<tr>
<td>如果<code>Namespace Controller</code>观察到Namespace<code>设置了删除期限</code>,同时<code>Namespace的spec.finalizers域值是空</code>的,那么<code>Namespace Controller</code>将通过<code>API Server删除该Namespace资源</code>。</td>
</tr>
</tbody></table>
<h3 id="3-2-5-Service-Controller与Endpoint-Controller"><a href="#3-2-5-Service-Controller与Endpoint-Controller" class="headerlink" title="3.2.5 Service Controller与Endpoint Controller"></a><font color=tomato>3.2.5 Service Controller与Endpoint Controller</font></h3><p><strong><font color=yellowgreen>Service, Endpoints与Pod的关系</font></strong></p>
<p><strong><font color=orange><code>Endpoints</code>表示一个<code>Service对应的所有Pod副本的访问地址</code>,而<code>EndpointsController</code>就是负责生成和维护所有<code>Endpoints</code>对象的控制器。</font></strong></p>
<table>
<thead>
<tr>
<th>–</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://img-blog.csdnimg.cn/406f766b5b144b70a0fcf4daf4d142ea.png" alt="在这里插入图片描述"></td>
</tr>
</tbody></table>
<p><strong><font color=seagreen>Endpoint Controller负责监听Service和对应的Pod副本的变化,如果监测到Service被删除,则删除和该Service同名的Endpoints对象。如果监测到新的Service被创建或者修改,则根据该Service信息获得相关的Pod列表,然后创建或者更新Service对应的Endpoints对象。如果监测到Pod的事件,则更新它所对应的Service的Endpoints对象(增加、删除或者修改对应的Endpoint条目)</font></strong></p>
<p><strong><font color=green>Endpoints对象是在哪里被使用的呢?</font></strong></p>
<blockquote>
<p>每个<code>Node</code>上的<code>kube-proxy</code>进程,<code>kube-proxy</code>进程获取每个<code>Service</code>的<code>Endpoints</code>,实现了<code>Service</code>的<code>负载均衡</code>功能。</p>
</blockquote>
<p><strong><font color=brown><code>Service Controller</code>的作用,它其实是属于<code>Kubernetes集群与外部的云平台之间的一个接口控制器</code>。</font></strong></p>
<p><strong><font color=royalblue>Service Controller监听Service的变化,如果是一个<code>LoadBalancer</code>类型的<code>Service (externalLoadBalancers-true)</code>,则<code>Service Controller</code>确保外部的云平台上该Service对应的LoadBalancer实例被相应地创建、删除及更新路由转发表(根据Endpoints的条目)。</font></strong></p>
<h2 id="5-4-kubelet运行机制解析"><a href="#5-4-kubelet运行机制解析" class="headerlink" title=" 5.4 kubelet运行机制解析"></a><font color=red> 5.4 kubelet运行机制解析</font></h2><p>在Kubernetes集群中,在每个<code>Node (又称Minion)上都会启动一个kubelet服务进程</code>。该进程用于<code>处理Master下发到本节点的任务(调度器调度这个节点的pod)</code>,管理<code>Pod及Pod中的容器</code>。</p>
<p>每个<code>kubelet</code>进程都会在<code>API Server</code>上注册节点自身的信息,<code>定期向Master汇报节点资源的使用情况</code>,并通过<code>cAdvisor监控容器和节点资源</code>。</p>
<p>嗯，可以这样理解，k8s中，master节点相当于总经理在总部,node节点相当于省市区域,kubelet相当于区域经理，负责处理总经理的指示和要求，同时管理省市公司的多个员工pod,这里总公司有一个OA系统，叫APIService，<code>kubelet</code>会在OA发布信息，定期的通过oA向master汇报区域员工的工作，同时通过cAdvisor对员工起一个监督作用</p>
<h3 id="5-4-1-节点管理"><a href="#5-4-1-节点管理" class="headerlink" title="5.4.1 节点管理"></a>5.4.1 节点管理</h3><p>节点通过设置kubelet的启动参数“<code>--register-node</code>”，来决定是否向API Server注册自己。如果该参数的值为<code>true</code>，那么<code>kubelet</code>将试着通过<code>API Server</code>注册自己。在自注册时，kubelet启动时还包含下列参数。</p>
<ul>
<li><code>--api-servers</code>:API Server的位置。</li>
<li><code>--kubeconfig:kubeconfig文件</code>，用于访问API Server的安全配置文件。</li>
<li><code>--cloud-provider</code>：云服务商(IaaS)地址，仅用于公有云环境。</li>
</ul>
<p>当前每个<code>kubelet</code>都被授予<code>创建和修改任何节点的权限</code>。但是在实践中，它仅仅创建和修改自己。将来，我们计划限制kubelet的权限，仅允许它修改和创建所在节点的权限。如果在集群运行过程中遇到<code>集群资源不足</code>的情况，用户就很容易通过<code>添加机器及运用kubelet的自注册模式来实现扩容</code>。</p>
<p>在某些情况下，Kubernetes集群中的某些kubelet没有选择自注册模式，用户需要自己去配置Node的资源信息，同时告知Node上Kubelet API Server的位置。</p>
<p>集群管理者能够创建和修改节点信息。如果管理者希望手动创建节点信息，则通过设置kubelet的启动参数“<code>--register-node=false</code>”即可完成。</p>
<p><code>kubelet</code>在启动时通过<code>API Server</code>注册节点信息，并<code>定时</code>向<code>API Server</code>发送节点的新消息，<code>API Server</code>在接收到这些信息后，将这些信息写入<code>etcd</code>。通过<code>kubelet</code>的启动参数“<code>-node-status-update-frequency</code>”设置<code>kubelet</code>每隔多长时间向<code>API Server</code>报告节点状态，默认为10s。</p>
<h3 id="5-4-2-Pod管理"><a href="#5-4-2-Pod管理" class="headerlink" title="5.4.2 Pod管理"></a>5.4.2 Pod管理</h3><p>kubelet通过以下几种方式<code>获取自身Node上要运行的Pod清单</code>。</p>
<ul>
<li><code>文件</code>：kubelet启动参数 <code>--config</code> 指定的配置文件目录下的文件(默认目录为“<code>/etc/kubernetes/manifests/</code>”)。通过<code>--file-check-frequency</code>设置检查该文件目录的时间间隔，默认为20s。</li>
<li><code>HTTP端点(URL)</code>：通过“<code>-manifest-url</code>”参数设置。通过<code>--http-check-frequency</code>设置检查该<code>HTTP端点数据的时间间隔</code>，默认为20s。</li>
<li><code>API Server</code>:<code>kubelet</code>通过<code>API Server监听etcd目录</code>，<code>同步Pod列表</code>。</li>
</ul>
<p>所有以非<code>API Server方式创建的Pod都叫作Static Pod</code>。kubelet将<code>Static Pod</code>的状态汇报给<code>API Server</code>，<code>API Server</code>为该<code>Static Pod</code>创建一个<code>Mirror Pod</code>和其相匹配。<code>Mirror Pod</code>的状态将真实反映<code>Static Pod</code>的状态。</p>
<p><code>当Static Pod被删除时，与之相对应的Mirror Pod也会被删除</code>。</p>
<p>在本章中只讨论通过API Server获得Pod清单的方式。kubelet通过<code>API Server Client</code>使用<code>Watch加List</code>的方式监听“<code>/registry/nodes/$</code>”当前节点的名称和“<code>registry/pods</code>”目录，将获取的信息同步到本地缓存中。</p>
<p><code>kubelet监听etcd</code>，所有针对Pod的操作都会被kubelet监听。如果发现有新的绑定到本节点的Pod，则按照Pod清单的要求创建该Pod。</p>
<p>如果发现<code>本地的Pod被修改</code>，则kubelet会做出相应的修改，比如在删除Pod中的某个容器时，会通过Docker Client删除该容器。</p>
<p>如果发现<code>删除本节点的Pod</code>，则删除相应的Pod，并通过Docker Client删除Pod中的容器。</p>
<p>kubelet读取监听到的信息，如果是<code>创建和修改Pod任务</code>，则做如下处理。</p>
<ul>
<li>为该Pod创建一个数据目录。</li>
<li>从API Server读取该Pod清单。</li>
<li>为该Pod挂载外部卷(External Volume)。</li>
<li>下载Pod用到的<code>Secret</code>。</li>
<li>检查已经运行在节点上的Pod，如果该Pod没有<code>容器</code>或<code>Pause</code>容器(“kubernetes&#x2F;pause”镜像创建的容器)没有启动，则先停止<code>Pod</code>里<code>所有容器的进程</code>。如果在Pod中有需要<code>删除的容器</code>，则删除这些容器。</li>
<li>用<code>“kubernetes/pause”</code>镜像为每个Pod都创建一个容器。该<code>Pause容器</code>用于接管<code>Pod</code>中所有其他<code>容器的网络</code>。每创建一个<code>新的Pod</code>，kubelet都会先创建一个<code>Pause容器</code>，然后创建其他容器。“kubernetes&#x2F;pause”镜像大概有200KB，是个非常小的容器镜像。</li>
<li>为Pod中的每个容器做如下处理。<ul>
<li>为容器计算一个Hash值，然后用容器的名称去查询对应Docker容器的Hash值。若查找到容器，且二者的Hash值不同，则停止Docker中容器的进程，并停止与之关联的Pause容器的进程；若二者相同，则不做任何处理。</li>
<li>如果容器被终止了，且容器没有指定的restartPolicy(重启策略)，则不做任何处理。</li>
<li>调用Docker Client下载容器镜像，调用Docker Client运行容<br>器。</li>
</ul>
</li>
</ul>
<h3 id="5-4-3-容器健康检查"><a href="#5-4-3-容器健康检查" class="headerlink" title="5.4.3 容器健康检查"></a>5.4.3 容器健康检查</h3><p>Pod通过两类探针来检查容器的健康状态。</p>
<h4 id="LivenessProbe探针"><a href="#LivenessProbe探针" class="headerlink" title="LivenessProbe探针"></a>LivenessProbe探针</h4><p>一类是LivenessProbe探针，用于判断容器是否健康并反馈给kubelet。如果LivenessProbe探针探测到容器不健康，则kubelet将删除该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含LivenessProbe探针，那么kubelet认为该容器的LivenessProbe探针返回的值永远是Success；</p>
<h4 id="ReadinessProbe探针"><a href="#ReadinessProbe探针" class="headerlink" title="ReadinessProbe探针"></a>ReadinessProbe探针</h4><p>另一类是ReadinessProbe探针，用于判断容器是否启动完成，且准备接收请求。如果ReadinessProbe探针检测到容器启动失败，则Pod的状态将被修改，Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的IP地址的Endpoint条目。</p>
<p>kubelet定期调用容器中的LivenessProbe探针来诊断容器的健康状况。LivenessProbe包含以下3种实现方式。</p>
<ul>
<li>ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为0，则表明容器健康。</li>
<li>TCPSocketAction：通过容器的IP地址和端口号执行TCP检查，如果端口能被访问，则表明容器健康。</li>
<li>HTTPGetAction：通过容器的IP地址和端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于等于400，则认为容器状态健康。</li>
</ul>
<p>  关于更多小伙伴们可以看看我之前的博文关于 <a target="_blank" rel="noopener" href="https://blog.csdn.net/sanhewuyang/article/details/122020019">Kubernetes中Pod健康检测和服务可用性检查的一些笔记</a></p>
<h3 id="资源监控"><a href="#资源监控" class="headerlink" title="资源监控"></a>资源监控</h3><p>在新的Kubernetes监控体系中，MetricsServer用于提供Core Metrics(核心指标)，包括Node和Pod的CPU和内存使用数据。其他Custom Metrics(自定义指标)则由第三方组件(如Prometheus)采集和存储。</p>
<h1 id="第6章-深入分析集群安全机制"><a href="#第6章-深入分析集群安全机制" class="headerlink" title="第6章 深入分析集群安全机制"></a><font color=tomato>第6章 深入分析集群安全机制</font></h1><p><strong><font color=orange><code>Kubernetes</code>通过一系列机制来实现集群的安全控制,其中包括<code>API Server</code>的认证授权、准入控制机制及保护敏感信息的Secret机制等。集群的安全性必须考虑如下几个目标。</font></strong></p>
<table>
<thead>
<tr>
<th>安全目标</th>
</tr>
</thead>
<tbody><tr>
<td>保证容器与其所在宿主机的隔离。</td>
</tr>
<tr>
<td>限制容器给基础设施或其他容器带来的干扰。</td>
</tr>
<tr>
<td>最小权限原则一合理限制所有组件的权限,确保组件只执行它被授权的行为,通过限制单个组件的能力来限制它的权限范围。</td>
</tr>
<tr>
<td>明确组件间边界的划分。</td>
</tr>
<tr>
<td>划分普通用户和管理员的角色。</td>
</tr>
<tr>
<td>在必要时允许将管理员权限赋给普通用户。</td>
</tr>
<tr>
<td>允许拥有Secret数据(Keys, Certs, Passwords)的应用在集群中运行。</td>
</tr>
</tbody></table>
<p>下面分别从Authentication,Authorization, AdmissionControl,Secret和Service Account等方面来说明集群的安全机制。</p>
<h2 id="6-1-API-Server认证管理"><a href="#6-1-API-Server认证管理" class="headerlink" title="6.1 API Server认证管理"></a><font color=red>6.1 API Server认证管理</font></h2><p>我们知道, Kubernetes集群中所有资源的访问和变更都是通过Kubernetes API Server的REST API来实现的,所以集群安全的关键点就在于如何鉴权和授权</p>
<p>Kubernetes集群提供了3种级别的客户端身份认证方式</p>
<ul>
<li>最严格的HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式</li>
<li>HTTP Token认证：通过一个Token来识别合法用户。</li>
<li>HTTP Base认证：通过用户名+密码的方式认证，这个只有1.19之前的版本适用，之后的版本不在支持</li>
</ul>
<p>HTTPS证书认证的原理。</p>
<p>CA认证涉及诸多概念,比如根证书、自签名证书、密钥、私钥、·加密算法及HTTPS等,</p>
<p>(1) HTTPS通信双方的服务器端向CA机构申请证书, CA机构是可信的第三方机构,它可以是一个公认的权威企业,也可以是企业自身。企业内部系统一般都用企业自身的认证系统。CA机构下发根证书、服务端证书及私钥给申请者。</p>
<p>(2) HTTPS通信双方的客户端向CA机构申请证书, CA机构下发根证书、客户端证书及私钥给申请者。</p>
<p>(3)客户端向服务器端发起请求,服务端下发服务端证书给客户端。客户端接收到证书后,通过私钥解密证书,并利用服务器端证书中的公钥认证证书信息比较证书里的消息,例如,比较域名和公钥与服务器刚刚发送的相关消息是否一致,如果一致,则客户端认可这个服务器的合法身份。</p>
<p>(4)客户端发送客户端证书给服务器端,服务端在接收到证书后,通过私钥解密证书,获得客户端证书公钥,并用该公钥认证证书信息,确认客户端是否合法。</p>
<p>(5)客户端通过随机密钥加密信息,并发送加密后的信息给服务端。在服务器端和客户端协商好加密方案后,客户端会产生一个随机的密钥,客户端通过协商好的加密方案加密该随机密钥,并发送该随机密钥到服务器端。服务器端接收这个密钥后,双方通信的所有内容都通过该随机密钥加密。</p>
<p>上述是双向认证SSL协议的具体通信过程,这种情况要求服务器和用户双方都有证书。单向认证SSL协议则不需要客户端拥有CA证书,对于上面的步骤,只需将服务器端验证客户证书的过程去掉,之后协商对 </p>
<p>HTTP Token的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串-Token来表明客户身份的一种方式。在通常情况下, Token是一个很复杂的字符串,比如我们用私钥签名一个字符串后的数据就可以被当作一个Token。此外,每个Token对应一个用户名,存储在APIServer能访问的一个文件中。当客户端发起API调用请求时,需要在HTTP Header里放入Token,这样一来, API Server就能识别合法用户和非法用户了。</p>
<h2 id="6-2-API-Server授权管理"><a href="#6-2-API-Server授权管理" class="headerlink" title="6.2 API Server授权管理"></a><font color=tomato>6.2 API Server授权管理</font></h2><p><strong><font color=purple>当客户端发起API Server调用时, API Server内部要先进行用户认证,然后执行用户鉴权流程,即通过鉴权策略来决定一个API调用是否合法。想来对于开发的小伙伴并不陌生，常用的<code>Spring Security</code>等安全框架，都会涉及认证和鉴权的过程。</font></strong></p>
<blockquote>
<p>既然鉴权，那必有授权的过程，简单地说,授权就是授予不同的用户不同的访问权限。<code>API Server</code>目前支持以下几种授权策略(通过API Server的启动参数”<code>--authorization-mode</code>“设置)。 </p>
</blockquote>
<table>
<thead>
<tr>
<th align="left">策略</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">AlwaysDeny</td>
<td align="left">表示拒绝所有请求,一般用于测试。</td>
</tr>
<tr>
<td align="left">AlwaysAllow</td>
<td align="left">允许接收所有请求,如果集群不需要授权流程,则可以采用该策略,这也是Kubernetes的默认配置。</td>
</tr>
<tr>
<td align="left">ABAC (Attribute-Based Access Control)</td>
<td align="left">基于属性的访问控制,表示使用用户配置的授权规则对用户请求进行匹配和控制。</td>
</tr>
<tr>
<td align="left">Webhook</td>
<td align="left">通过调用外部REST服务对用户进行授权。</td>
</tr>
<tr>
<td align="left">RBAC</td>
<td align="left">Role-Based Access Control,基于角色的访问控制。</td>
</tr>
<tr>
<td align="left">Node</td>
<td align="left">是一种专用模式,用于对kubelet发出的请求进行访问控制。</td>
</tr>
</tbody></table>
<h3 id="6-2-3-RBAC授权模式详解"><a href="#6-2-3-RBAC授权模式详解" class="headerlink" title="6.2.3 RBAC授权模式详解"></a><font color=orange>6.2.3 RBAC授权模式详解</font></h3><p>RBAC(Role-Based Access Control，基于角色的访问控制)在Kubernetes的1.5版本中引入，在1.6版本时升级为Beta版本，在1.8版本时升级为GA。作为kubeadm安装方式的默认选项，足见其重要程度。相对于其他访问控制方式，新的RBAC具有如下优势。</p>
<ul>
<li>对集群中的资源和非资源权限均有完整的覆盖。</li>
<li>整个RBAC完全由几个API对象完成，同其他API对象一样，可以用kubectl或API进行操作。</li>
<li>可以在运行时进行调整，无须重新启动API Server。</li>
</ul>
<p>要使用RBAC授权模式，需要在API Server的启动参数中加上–authorization-mode&#x3D;RBAC</p>
<p><strong><font color=brown>1.RBAC的API资源对象说明RBAC引入了4个新的顶级资源对象:</font></strong></p>
<blockquote>
<p><code>Role</code>, <code>ClusterRole</code>,<code>RoleBinding</code>和<code>ClusterRoleBinding</code></p>
</blockquote>
<p><strong><font color=camel>同其他API资源对象一样,用户可以使用kubectl或者API调用等方式操作这些资源对象。 </font></strong></p>
<h4 id="资源文件属性"><a href="#资源文件属性" class="headerlink" title="资源文件属性"></a><font color=royalblue>资源文件属性</font></h4><ul>
<li>apiGroups：支持的API组列表，例如“apiVersion:batch&#x2F;v1”,“apiVersion: extensions:v1beta1”,“apiVersion: apps&#x2F;v1beta1”等</li>
<li>resources：支持的资源对象列表，例如pods、deployments、jobs等。</li>
<li>verbs：对资源对象的操作方法列表，例如get、watch、list、delete、replace、patch等</li>
</ul>
<h4 id="RBAC的API资源对象说明"><a href="#RBAC的API资源对象说明" class="headerlink" title="RBAC的API资源对象说明"></a><font color=yellowgreen>RBAC的API资源对象说明</font></h4><ul>
<li>角色(Role)<code>一个角色就是一组权限的集合</code>,这里的权限都是许可形式的,不存在拒绝的规则。在一个命名空间中,可以用角色来定义一个角色,如果是集群级别的,就需要使用ClusterRole了。角色只能对命名空间内的资源进行授权</li>
<li>集群角色(ClusterRole)集群角色除了具有和角色一致的命名空间内资源的管理能力,因其集群级别的范围,还可以用于以下特殊元素的授权。<ul>
<li>集群范围的资源,例如Node.</li>
<li>非资源型的路径,例如“&#x2F;api”</li>
<li>包含全部命名空间的资源,例如pods (用于kubectl get pods -all-namespaces这样的操作授权)。</li>
</ul>
</li>
<li>角色绑定(RoleBinding)和集群角色绑定ClusterRoleBinding)角色绑定或集群角色绑定用来把一个角色绑定到一个目标上,绑定目标可以是User (用户) 、Group (组)或者Service Account。<ul>
<li>使用RoleBinding为某个命名空间授权,</li>
<li>使用ClusterRoleBinding为集群范围内授权。</li>
</ul>
</li>
</ul>
<p>RoleBinding可以引用Role进行授权。RoleBinding也可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权</p>
<p>集群角色绑定中的角色只能是集群角色，用于进行集群级别或者对所有命名空间都生效的授权</p>
<h3 id="6-4-Service-Account"><a href="#6-4-Service-Account" class="headerlink" title="6.4 Service Account"></a>6.4 Service Account</h3><p>Service Account也是一种账号，但它并不是给Kubernetes集群的用户<br>(系统管理员、运维人员、租户用户等)用的，而是给运行在Pod里的<br>进程用的，它为Pod里的进程提供了必要的身份证明。</p>
<h1 id="第七章-网络原理"><a href="#第七章-网络原理" class="headerlink" title="第七章 网络原理"></a><font color=seagreen>第七章 网络原理</font></h1><h2 id="7-1-Kubernetes网络模型"><a href="#7-1-Kubernetes网络模型" class="headerlink" title="7.1 Kubernetes网络模型"></a>7.1 <font color=red>Kubernetes网络模型</font></h2><p>Kubernetes网络模型设计的一个基础原则是:</p>
<p>每个Pod都拥有一个独立的IP地址,并假定所有Pod都在一个可以直接连通的、扁平的网络空间中。</p>
<p>所以不管它们是否运行在同一个Node (宿主机)中,都要求它们可以直接通过对方的IP进行访问。</p>
<p>设计这个原则的原因是,<code>用户不需要额外考虑如何建立Pod之间的连接,也不需要考虑如何将容器端口映射到主机端口等问题</code>。</p>
<p>在Kubernetes的世界里, IP是以Pod为单位进行分配的。<code>Pod内部的所有容器共享一个网络堆栈(相当于一个网络命名空间,它们的IP地址、网络设备、配置等都是共享的) </code></p>
<p>按照这个网络原则抽象出来的为每个Pod都设置一个IP地址的模型也被称作<code>IP-per-Pod模型</code>。</p>
<p>由于Kubernetes的网络模型假设<code>Pod之间访问时使用的是对方Pod的实际地址</code>,所以一个<code>Pod内部的应用程序</code>看到的自己的<code>IP地址和端口</code>与集<code>群内其他Pod</code>看到的一样。</p>
<p>它们都是Pod实际分配的IP地址。将IP地址和端口在Pod内部和外部都保持一致,也就不需要使用NAT来进行地址转换了。Kubernetes的网络之所以这么设计,主要原因就是可以兼容过去的应用。</p>
<p>当然,我们使用Linux命令”ip addr show”也能看到这些地址,和程序看到的没有什么区别。所以这种IP-per-Pod的方案很好地利用了现有的各种域名解析和发现机制。</p>
<p>为每个Pod都设置一个IP地址的模型还有另外一层含义,那就是同一个Pod内的不同容器会共享同一个网络命名空间,也就是同一个Linux网络协议栈。这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口。这种关系和同一个VM内的进程之间的关系是一样的,看起来Pod内容器之间的隔离性减小了,而且Pod内不同容器之间的端口是共享的,就没有所谓的私有端口的概念了。</p>
<p>如果你的应用必须要使用一些特定的端口范围,那么你也可以为这些应用单独创建一些Pod。</p>
<p>对那些没有特殊需要的应用,由于Pod内的容器是共享部分资源的,所以可以通过共享资源互相通信,这显然更加容易和高效。针对这些应用,虽然损失了可接受范围内的部分隔离性,却也是值得的。</p>
<blockquote>
<p>IP-per-Pod模式和Docker原生的通过动态端口映射方式实现的多节点访问模式有什么区别呢?</p>
</blockquote>
<p>Docker的动态端口映射会引入<code>端口管理的复杂性</code>,而且<code>访问者看到的IP地址和端口与服务提供者实际绑定的不同(因为NAT的缘故,它们都被映射成新的地址或端口了)</code> ,这也会引起<code>应用配置的复杂化</code>。,标准的DNS等名字解析服务也不适用了,甚至服务注册和发现机制都将迎来挑战,因为在端口映射情况下,服务自身很难知道自己对外暴露的真实的服务IP和端口,外部应用也无法通过服务所在容器的私有IP地址和端口来访问服务。</p>
<p>P-per-Pod模型是一个简单的兼容性较好的模型。从该模型的网络的端口分配、域名解析、服务发现、负载均衡、应用配置和迁移等角度来看, Pod都能够被看作一台独立的虚拟机或物理机。按照这个网络抽象原则, Kubernetes对网络有什么前提和要求呢?Kubernetes对集群网络有如下要求。<br>(1)所有容器都可以在不用NAT的方式下同别的容器通信。<br>(2)所有节点都可以在不用NAT的方式下同所有容器通信,反之亦然。<br>(3)容器的地址和别人看到的地址是同一个地址。</p>
<p>这些基本要求意味着并不是只要两台机器都运行Docker,Kubernetes就可以工作了。具体的集群网络实现必须满足上述基本要求,原生的Docker网络目前还不能很好地支持这些要求。 </p>
<h2 id="7-7-Kubernetes网络策略"><a href="#7-7-Kubernetes网络策略" class="headerlink" title="7.7 Kubernetes网络策略"></a><font color=purple>7.7 Kubernetes网络策略</font></h2><blockquote>
<p>为了实现<code>细粒度的容器间网络访问隔离策略</code>, <code>Kubernetes从1.3</code>版本开始,由<code>SIG-Network</code>小组主导研发了<code>Network Policy</code>机制,目前已升级为<code>networking.k8s.io/v1</code>稳定版本。</p>
</blockquote>
<p><code>Network Policy</code>的主要功能是对<code>Pod</code>间的网络通信进行<code>限制和准入控制</code>,</p>
<p>设置方式为将<code>Pod的Label</code>作为查询条件,设置<code>允许访问</code>或<code>禁止访问</code>的<code>客户端Pod列表</code>。查询条件可以作用于<code>Pod</code>和<code>Namespace</code>级别。</p>
<p>为了使用<code>Network Policy</code>, <code>Kubernetes</code>引入了一个新的资源对象<code>NetworkPolicy</code>,供用户设置<code>Pod间网络访问的策略</code>。但仅定义一个<code>网络策略</code>是无法完成实际的<code>网络隔离</code>的,还需要一个<code>策略控制器(PolicyController)进行策略的实现</code>。</p>
<p>策略控制器由第三方网络组件提供,目前<code>Calico, Cilium, Kube-router, Romana, Weave Net</code>等开源项目均支持网络策略的实现。<code>Network Policy</code>的工作原理如图</p>
<p><code>policy controller</code>需要实现一个<code>API Listener</code>,监听用户设置的<code>NetworkPolicy</code>定义,并将网络访问规则通过各Node的<code>Agent</code>进行实际设置(<code>Agent</code>则需要通过CNI网络插件实现)</p>
<h3 id="7-7-1-网络策略配置说明"><a href="#7-7-1-网络策略配置说明" class="headerlink" title="7.7.1 网络策略配置说明"></a><font color=chocolate>7.7.1 网络策略配置说明</font></h3><p><code>网络策略</code>的设置主要用于对<code>目标Pod</code>的网络访问进行限制,在默认·情况下<code>对所有Pod都是允许访问</code>的,在设置了指向Pod的<code>NetworkPolicy网络策略</code>之后,到Pod的访问才会被限制。 </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-network-policy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> <span class="comment">#用于定义该网络策略作用的Pod范围</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">role:</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">policyTypes:</span> <span class="comment">#网络策略的类型，包括ingress和egress两种</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line">  <span class="attr">ingress:</span> <span class="comment">#定义允许访问目标Pod的入站白名单规则</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span> <span class="comment">#满足from 条件的客户端才能访问ports定义的目标Pod端口号。</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">        <span class="attr">except:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">172.17</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">namespaceSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">project:</span> <span class="string">myproject</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">role:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">ports:</span> <span class="comment">#允许访问的目标Pod监听的端口号。</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">  <span class="attr">egress:</span> <span class="comment">#定义目标Pod允许访问的“出站”白名单规则</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">to:</span> <span class="comment">#目标Pod仅允许访问满足to条件的服务端IP范围和ports定义的端口号</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="attr">ports:</span>  <span class="comment">#允许访问的服务端的端口号。</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">5978</span></span><br></pre></td></tr></table></figure>
<h3 id="7-7-2在Namespace级别设置默认的网络策略"><a href="#7-7-2在Namespace级别设置默认的网络策略" class="headerlink" title="7.7.2在Namespace级别设置默认的网络策略"></a><font color=seagreen>7.7.2在Namespace级别设置默认的网络策略</font></h3><blockquote>
<p>在Namespace级别还可以设置一些默认的全局网络策略,以方便管理员对整个Namespace进行统一的网络策略设置。</p>
</blockquote>
<h3 id="默认拒绝所有入站流量"><a href="#默认拒绝所有入站流量" class="headerlink" title="默认拒绝所有入站流量"></a><font color=blue>默认拒绝所有入站流量</font></h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default-deny-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="默认允许所有入站流量"><a href="#默认允许所有入站流量" class="headerlink" title="默认允许所有入站流量"></a><font color=camel>默认允许所有入站流量</font></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">allow-all-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="默认拒绝所有出站流量"><a href="#默认拒绝所有出站流量" class="headerlink" title="默认拒绝所有出站流量"></a><font color=red>默认拒绝所有出站流量</font></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default-deny-egress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="默认允许所有出站流量"><a href="#默认允许所有出站流量" class="headerlink" title="默认允许所有出站流量"></a><font color=tomato>默认允许所有出站流量</font></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">allow-all-egress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="默认拒绝所有入口和所有出站流量"><a href="#默认拒绝所有入口和所有出站流量" class="headerlink" title="默认拒绝所有入口和所有出站流量"></a><font color=brown>默认拒绝所有入口和所有出站流量</font></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default-deny-all</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="7-7-3-NetworkPolicy的发展"><a href="#7-7-3-NetworkPolicy的发展" class="headerlink" title="7.7.3 NetworkPolicy的发展"></a>7<font color=seagreen>.7.3 NetworkPolicy的发展</font></h3><blockquote>
<p>作为一个稳定特性，<code>SCTP </code>支持默认是被启用的。 要在集群层面禁用 <code>SCTP</code>，你(或你的集群管理员)需要为<code>API</code>服务器指定 <code>--feature-gates=SCTPSupport=false</code>,… 来禁用 <code>SCTPSupport </code>特性门控。 启用该特性门控后，用户可以将 <code>NetworkPolicy</code> 的<code>protocol</code>字段设置为 <code>SCTP</code>(不同版本略有区别)</p>
</blockquote>
<h2 id="10-12-Helm：Kubernetes应用包管理工具"><a href="#10-12-Helm：Kubernetes应用包管理工具" class="headerlink" title="10.12 Helm：Kubernetes应用包管理工具"></a><font color=plum>10.12 Helm：Kubernetes应用包管理工具</font></h2><blockquote>
<p>复杂的应用中间件,在<code>Kubernetes</code>上进行容器化部署并非易事,通常需要先研究<code>Docker</code>镜像的运行需求、环境变量等内容,并能为这些容器定制存储、网络等设置,最后设计和编写Deployment. ConfigMap. Service及Ingress等相关<code>YAML配置文件</code>,再提交给<code>Kubernetes部署</code>。这些复杂的过程将逐步被<code>Helm应用包管理工具</code>实现。 </p>
</blockquote>
<h3 id="10-12-1-Helm概述"><a href="#10-12-1-Helm概述" class="headerlink" title="10.12.1 Helm概述"></a><font color=brown>10.12.1 Helm概述</font></h3><p><code>Helm</code>是一个由<code>CNCF</code>孵化和管理的项目,用于对需要在<code>Kubernetes</code>上部署的复杂应用进行定义、安装和更新。<code>Helm以Chart</code>的方式对应用软件进行描述,可以方便地创建、版本化、共享和发布复杂的应用软件。</p>
<h3 id="10-12-2-Helm的主要概念"><a href="#10-12-2-Helm的主要概念" class="headerlink" title="10.12.2 Helm的主要概念"></a><font color=blue>10.12.2 Helm的主要概念</font></h3><p>Helm的主要概念如下。</p>
<p><strong><font color=brown>Chart</font></strong>:一个Helm包,其中包含运行一个应用所需要的<code>工具和资源定义</code>,还可能包含<code>Kubernetes集群</code>中的<code>服务定义</code>,类似于<code>Homebrew</code>中的<code>formula</code>, <code>APT</code>中的<code>dpkg</code>或者<code>Yum</code>中的<code>RPM</code>文件。</p>
<p><strong><font color=royalblue>Release</font></strong>: 在<code>Kubernetes</code>集群上运行的一个<code>Chart</code>实例。在同一个集群上,一个<code>Chart</code>可以被安装多次。例如有一个<code>MySQL Chart</code>。</p>
<p><strong><font color=red>Repository</font></strong>:用于<code>存放和共享Chart仓库</code>。**<font color=blue>简单来说, Helm整个系统的主要任务就是,在仓库中查找需要的Chart,然后将Chart以Release的形式安装到Kubernetes集群中。</font>**</p>
<h3 id="10-12-4-Helm的常见用法"><a href="#10-12-4-Helm的常见用法" class="headerlink" title="10.12.4 Helm的常见用法"></a><font color=camel>10.12.4 Helm的常见用法</font></h3><p>搜索Chart,安装Chart,自定义Chart配置、更新或回滚Release、删除Release、创建自定义Chart、搭建私有仓库等。</p>
<h3 id="第11章-Trouble-Shooting指导"><a href="#第11章-Trouble-Shooting指导" class="headerlink" title="第11章 Trouble Shooting指导"></a><font color=tomato>第11章 Trouble Shooting指导</font></h3><p>Kubernetes集群中常见问题的排查方法进行说明</p>
<p>为了跟踪和发现在Kubernetes集群中运行的容器应用出现的问题,我们常用如下查错方法。</p>
<p><strong><font color=blue>(1)查看Kubernetes对象的当前运行时信息,特别是与对象关联的<code>Event事件</code>。这些事件记录了<code>相关主题</code>、<code>发生时间</code>、<code>最近发生时间</code>、<code>发生次数</code>及<code>事件原因</code>等,对排查故障非常有价值。通过查看对象的<code>运行时数据</code>,我们还可以发现<code>参数错误</code>、<code>关联错误</code>、<code>状态异常</code>等明显问题。由于在Kubernetes中多种对象相互关联,因此这一步可能会涉及多·个相关对象的排查问题。</font></strong></p>
<p><strong><font color=blue>(2)对于<code>服务、容器</code>方面的问题,可能需要深入容<code>器内部</code>进行<code>故障诊断</code>,此时可以通过查看<code>容器的运行日志</code>来定位具体问题。</font></strong></p>
<p><strong><font color=amber>(3)对于某些复杂问题,例如<code>Pod调度这种全局性</code>的问题,可能需要结合<code>集群中每个节点上的Kubernetes服务日志</code>来排查。比如搜集<code>Master</code>上的<code>kube-apiserver, kube-schedule, kube-controler-manager</code>服务日志,以及各个<code>Node</code>上的<code>kubelet, kube-proxy</code>服务日志. </font></strong></p>
<h4 id="11-1查看系统Event"><a href="#11-1查看系统Event" class="headerlink" title="11.1查看系统Event"></a><strong><font color=royalblue>11.1查看系统Event</font></strong></h4><p><strong><font color=amber>在<code>Kubernetes集群</code>中<code>创建Pod</code>后,我们可以<code>通过kubectl get pods命令</code>查看<code>Pod列表</code>,但通过该命令显示的信息有限。Kubernetes提供了<code>kubectl describe pod</code>命令来查看一个<code>Pod</code>的详细信息,例如:</font></strong></p>
<p>通过<code>kubectl describe pod</code>命令,可以显示<code>Pod创建</code>时的<code>配置定义、状态等信息</code>,还可以显示与该<code>Pod</code>相关的最近的<code>Event</code>事件,事件信息对于查错非常有用。</p>
<p>如果<code>某个Pod一直处于Pending状态</code>,我们就可以通过<code>kubectl describe</code>了解具体的原因：</p>
<ul>
<li>没有可用的<code>Node以供调度</code>。</li>
<li>开启了<code>资源配额管理</code>，但在当前调度的目标节点上<code>资源不足</code>。</li>
<li><code>镜像下载失败</code>。</li>
</ul>
<h4 id="11-2-查看容器日志"><a href="#11-2-查看容器日志" class="headerlink" title="11.2 查看容器日志"></a><font color=seagreen>11.2 查看容器日志</font></h4><p>在需要排查容器内部应用程序生成的日志时，我们可以使用<code>kubectl  logs &lt;pod_name&gt;</code>命令</p>
<h4 id="11-3-查看Kubernetes服务日志"><a href="#11-3-查看Kubernetes服务日志" class="headerlink" title="11.3 查看Kubernetes服务日志"></a><font color=seagreen>11.3 查看Kubernetes服务日志</font></h4><p>如果在<code>Linux</code>系统上安装<code>Kubernetes</code>,并且使用<code>systemd</code>系统管理<code>Kubernetes</code>服务,那么<code>systemd</code>的<code>journal</code>系统会接管服务程序的输出日志。在这种环境中,可以通过使用<code>systemd status</code>或<code>journalct</code>具来查看系统服务的日志。例如,使用<code>systemctl status</code>命令查看<code>kube-controller-manager</code>服务的日志:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl status kubelet.service</span><br><span class="line">journalctl -u kubelet</span><br></pre></td></tr></table></figure>


<p><strong><font color=yellowgreen>如果不使用<code>systemd</code>系统接管<code>Kubernetes</code>服务的标准输出，则也可以通过日志相关的启动参数来指定日志的存放目录。</font></strong></p>
<p><strong><font color=brown>Pod对象相关的问题</font></strong>,比如无法创建<code>Pod</code>, <code>Pod</code>启动后就停止或者<code>Pod</code>副本无法增加,等等。此时,可以先确定<code>Pod</code>在哪个节点上,然后登录这个节点,从<code>kubelet</code>的日志中查询该<code>Pod</code>的完整日志,然后进行问题排查。</p>
<p><strong><font color=brown>对于与Pod扩容相关或者与RC相关的问题</font></strong>,则很可能在<code>kube-controller-manager</code>及<code>kube-scheduler</code>的日志中找出问题的关键点。</p>
<p><strong><font color=tomato><code>kube-proxy</code>经常被我们忽视,因为即使它意外停止</font></strong>, <code>Pod</code>的状态也是正常的,但会导致某些服务访问异常。这些错误通常与每个节点上的<code>kube-proxy</code>服务有着密切的关系。遇到这些问题时,首先要排查<code>kube-proxy</code>服务的日志,同时排查防火墙服务,要特别留意在防火墙中是否有人为添加的可疑规则。 </p>
<p><strong><font color=yellowgreen>11.4常见问题</font></strong></p>
<p><strong><font color=purple>11.4.1 由于无法下载pause镜像导致Pod一直处于Pending状态</font></strong></p>
<p><strong><font color=yellowgreen>11.4.2 Pod创建成功，但RESTARTS数量持续增加</font></strong></p>
<p>容器的启动命令不能保持在前台运行。</p>
<p><strong><font color=brown>11.4.3 通过服务名无法访问服务</font></strong></p>
<p>在<code>Kubernetes</code>集群中应尽量使用服务名访问正在运行的微服务,但有时会访问失败。由于<code>服务涉及服务名的DNS域名解析</code>、<code>kube-proxy组件的负载分发</code>、<code>后端Pod列表的状态</code>等,所以可通过以下几方面排查问题。 </p>
<p>1.查看<code>Service</code>的<code>后端Endpoint</code>是否正常</p>
<p>可以通过<code>kubectl get endpoints &lt;service name&gt;</code>命令查看某个服务的后端<code>Endpoint</code>列表,如果列表为空,则可能因为:</p>
<ul>
<li><code>Service</code>的<code>Label Selector</code>与<code>Pod的Label不匹配</code>,沒有相关的pod可以提供能力</li>
<li>后端<code>Pod</code>一直没有达到<code>Ready</code>状态(通过<code>kubectl get pods</code>进一步查看<code>Pod的状态</code>)</li>
<li>**<font color=chocolate>Service的targetPort端口号与Pod的containerPort不一致等</font>**。即容器暴露的端口不是SVC暴露的端口，需要使用targetPort来转发</li>
</ul>
<p>2·查看Service的名称能否被正确解析为ClusterIP地址</p>
<p>可以通过在客户端容器中ping <servicename>.<namespace>.svc进行检查,如果能够得到<code>Service</code>的<code>ClusterlP</code>地址,则说明<code>DNS服务</code>能够<code>正确解析Service</code>的名称;如果不能得到<code>Service</code>的<code>ClusterlP地址</code>,则可能是因为<code>Kubernetes集群</code>的<code>DNS服务工作异常</code>。</p>
<p>3·查看<code>kube-proxy</code>的<code>转发规则</code>是否正确</p>
<p>我们可以将<code>kube-proxy</code>服务设置为<code>IPVS或iptables负载分发模式</code>。</p>
<ul>
<li><p>对于<code>IPVS负载分发模式</code>,可以通过<code>ipvsadm</code>工具查看<code>Node上的IPVS规则</code>,查看是否正确设置<code>Service ClusterlP</code>的相关规则。</p>
</li>
<li><p>对于<code>iptables负载分发模式</code>,可以通过查看<code>Node上的iptables规则</code>,查看是否正确设置<code>Service ClusterlP</code>的相关规则。</p>
</li>
</ul>
<h4 id="11-5-寻求帮助"><a href="#11-5-寻求帮助" class="headerlink" title="11.5 寻求帮助"></a><font color=yellowgreen>11.5 寻求帮助</font></h4><table>
<thead>
<tr>
<th>网站和社区</th>
</tr>
</thead>
<tbody><tr>
<td><code>Kubernetes</code>官网中监控、记录和调试相关问题: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/debug-application-cluster/">https://kubernetes.io/docs/tasks/debug-application-cluster/</a></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/96fb379fe6d9499da0b85bb1b09d71be.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><code>Kubernetes</code>官方论坛: <a target="_blank" rel="noopener" href="https://discuss.kubernetes.io/">https://discuss.kubernetes.io/</a>(这个需要科学上网)</td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/2630a47aea9f41299dca9ced5b2654b8.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><code>GitHub</code>库关于<code>Kubernetes</code>问题列表:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues">https://github.com/kubernetes/kubernetes/issues</a></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/e7a34c8d752c4177a319240ff356274a.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><code>StackOverflow</code>网站上关于<code>Kubernetes</code>的问题讨论：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/tagged/kubernetes">https://stackoverflow.com/questions/tagged/kubernetes</a></td>
</tr>
<tr>
<td><img src="https://img-blog.csdnimg.cn/5de69263cac44aa798dd1c1e99476ee0.png" alt="在这里插入图片描述"></td>
</tr>
<tr>
<td><code>Kubernetes Slack</code>聊天群组: <a target="_blank" rel="noopener" href="https://kubernetes.slack.com/">https://kubernetes.slack.com/</a>(需要谷歌账号)</td>
</tr>
</tbody></table>
</div><div class="article-licensing box"><div class="licensing-title"><p>《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记</p><p><a href="https://liruilongs.github.io/2021/08/27/K8s/读书笔记/《Kubernetes权威指南-从Docker到Kubernetes实践全接触》读书笔记/">https://liruilongs.github.io/2021/08/27/K8s/读书笔记/《Kubernetes权威指南-从Docker到Kubernetes实践全接触》读书笔记/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://liruilongs.github.io"><p>山河已无恙</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-08-27</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-21</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2024/06/04/K8s/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2-%E8%BF%90%E7%BB%B4/K8s-%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8master%E8%8A%82%E7%82%B9ETCDCD%E6%95%85%E9%9A%9C%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/" target="_blank">K8s 集群高可用master节点ETCD全部挂掉如何恢复?</a><br></span><span>  2.<a class="is-size-6" href="/2024/03/16/K8s/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2-%E8%BF%90%E7%BB%B4/K8s%20%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8master%E8%8A%82%E7%82%B9%E6%8C%82%E6%8E%89%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/" target="_blank">K8s 集群高可用master节点故障如何恢复?</a><br></span><span>  3.<a class="is-size-6" href="/2024/02/28/K8s/%E6%8F%92%E4%BB%B6/K8s-%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86-kube-fledged-%E8%AE%A4%E7%9F%A5/" target="_blank">K8s 镜像缓存管理 kube-fledged 认知</a><br></span><span>  4.<a class="is-size-6" href="/2024/02/09/K8s/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2-%E8%BF%90%E7%BB%B4/K8s%E9%9B%86%E7%BE%A4%E6%95%85%E9%9A%9C(The%20connection%20to%20the%20server%20%20was%20refused%20-%20did%20you%20specify%20the%20right%20host%20or%20port)%E8%A7%A3%E5%86%B3/" target="_blank">K8s集群故障(The connection to the server &lt;host&gt;:&lt;port&gt; was refused - did you specify the right host or port)解决</a><br></span><span>  5.<a class="is-size-6" href="/2023/11/14/K8s/API%20%E5%AD%A6%E4%B9%A0/%E5%85%B3%E4%BA%8E-Kubernetes%E4%B8%ADAdmission-Controllers-%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于 Kubernetes中Admission Controllers(准入控制器) 认知的一些笔记</a><br></span><span>  6.<a class="is-size-6" href="/2023/11/14/K8s/API%20%E5%AD%A6%E4%B9%A0/K8s%20Pod%20%E5%88%9B%E5%BB%BA%E5%9F%8B%E7%82%B9%E5%A4%84%E7%90%86(Mutating%20%20Admission%20Webhook)/" target="_blank">K8s Pod 创建埋点处理(Mutating  Admission Webhook)</a><br></span><span>  7.<a class="is-size-6" href="/2023/10/26/AI-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/%E5%85%B3%E4%BA%8EAI(%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE%20K8s%20%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/" target="_blank">关于AI(深度学习)相关项目 K8s 部署的一些思考</a><br></span><span>  8.<a class="is-size-6" href="/2023/08/27/K8s/API%20%E5%AD%A6%E4%B9%A0/K8s-Pod-%E5%AE%89%E5%85%A8%E8%AE%A4%E7%9F%A5%EF%BC%8C%E4%BB%8Eopenshift-SCC-%E5%88%B0PSP-%E5%BC%83%E7%94%A8%E4%BB%A5%E5%8F%8A%E7%8E%B0%E5%9C%A8%E7%9A%84PSA/" target="_blank">K8s Pod 安全认知：从openshift SCC 到 PSP 弃用以及现在的 PSA</a><br></span></div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 推荐文章</span><br><span>  1.<a class="is-size-6" href="/2021/08/27/K8s/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8AKubernetes%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E4%BB%8EDocker%E5%88%B0Kubernetes%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%8E%A5%E8%A7%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" target="_blank">《Kubernetes权威指南:从Docker到Kubernetes实践全接触》读书笔记</a><br></span><span>  2.<a class="is-size-6" href="/2024/10/10/Git/Git-%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81-reference-broken-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/" target="_blank">Git 提交代码 reference broken 问题处理</a><br></span><span>  3.<a class="is-size-6" href="/2022/11/19/Git/%E5%85%B3%E4%BA%8E-Git-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于 Git 重写历史的一些笔记</a><br></span><span>  4.<a class="is-size-6" href="/2022/08/02/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%8F%98%E5%9F%BA%E6%93%8D%E4%BD%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支变基操作的一些笔记</a><br></span><span>  5.<a class="is-size-6" href="/2022/07/26/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支基础知识的一些笔记</a><br></span><span>  6.<a class="is-size-6" href="/2022/08/02/Git/%E5%85%B3%E4%BA%8EGit%E5%88%86%E6%94%AF%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/" target="_blank">关于Git分支工作流的一些笔记</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay%EF%BF%A5.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat%EF%BF%A5.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/08/30/docker/%E5%9F%BA%E4%BA%8EDocker%E9%83%A8%E7%BD%B2%20Tomcat%E9%9B%86%E7%BE%A4%E3%80%81%20Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">基于Docker部署 Tomcat集群、 Nginx负载均衡</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/08/18/%E5%8D%8E%E4%B8%BA%E4%BA%91/%E5%8D%8E%E4%B8%BAHCIP%20R&amp;S%20%E8%80%83%E8%AF%95%E7%AC%94%E8%AE%B0/"><span class="level-item">华为HCIP R&amp;S 考试笔记</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: '9860c87552756116972caa40ec7ebf6e',
            repo: 'blog_comment',
            owner: 'LIRUILONGS',
            clientID: '9fdc9739266d48d5f62e',
            clientSecret: 'c1cc33697d099a2197650ec9dadcb16bd4904655',
            admin: ["LIRUILONGS"],
            createIssueManually: true,
            distractionFreeMode: true,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><ul class="menu-list"><ul class="menu-list"><li><a class="is-flex is-mobile" href="#写在前面"><span class="mr-2">1.1.1</span><span>写在前面</span></a></li></ul></ul><li><a class="is-flex is-mobile" href="#第1章Kubernetes入门"><span class="mr-2">2</span><span>第1章Kubernetes入门</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-1-Kubernetes是什么"><span class="mr-2">2.1</span><span>1.1 Kubernetes是什么?</span></a></li><li><a class="is-flex is-mobile" href="#1-2-为什么要用-Kubernetes"><span class="mr-2">2.2</span><span>1.2 为什么要用 Kubernetes</span></a></li><li><a class="is-flex is-mobile" href="#1-3-从一个简单的例子开始"><span class="mr-2">2.3</span><span>1.3 从一个简单的例子开始</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-3-1环境准备"><span class="mr-2">2.3.1</span><span>1.3.1环境准备</span></a></li><li><a class="is-flex is-mobile" href="#1-3-2启动MySQL服务"><span class="mr-2">2.3.2</span><span>1.3.2启动MySQL服务</span></a></li><li><a class="is-flex is-mobile" href="#1-3-3启动Tomcat应用"><span class="mr-2">2.3.3</span><span>1.3.3启动Tomcat应用</span></a></li><li><a class="is-flex is-mobile" href="#1-3-4通过浏览器访问网页"><span class="mr-2">2.3.4</span><span>1.3.4通过浏览器访问网页 </span></a></li></ul></li><li><a class="is-flex is-mobile" href="#1-4-Kubernetes基本概念和术语"><span class="mr-2">2.4</span><span>1.4 Kubernetes基本概念和术语</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-4-1-Master"><span class="mr-2">2.4.1</span><span>1.4.1 Master</span></a></li><li><a class="is-flex is-mobile" href="#1-4-2-Node"><span class="mr-2">2.4.2</span><span>1.4.2 Node</span></a></li><li><a class="is-flex is-mobile" href="#1-4-3-Pod"><span class="mr-2">2.4.3</span><span>1.4.3 Pod</span></a></li><li><a class="is-flex is-mobile" href="#1-4-4-Lable-标签"><span class="mr-2">2.4.4</span><span>1.4.4 Lable 标签</span></a></li><li><a class="is-flex is-mobile" href="#1-4-5-Replication-Controller"><span class="mr-2">2.4.5</span><span>1.4.5 Replication Controller</span></a></li><li><a class="is-flex is-mobile" href="#1-4-6-Deployment"><span class="mr-2">2.4.6</span><span>1.4.6 Deployment</span></a></li><li><a class="is-flex is-mobile" href="#1-4-7-Horizontal-Pod-Autoscaler"><span class="mr-2">2.4.7</span><span>1.4.7 Horizontal Pod Autoscaler</span></a></li><li><a class="is-flex is-mobile" href="#1-4-8-StatefulSet"><span class="mr-2">2.4.8</span><span>1.4.8 StatefulSet</span></a></li><li><a class="is-flex is-mobile" href="#外部系统访问-Service-的问题"><span class="mr-2">2.4.9</span><span>外部系统访问 Service 的问题</span></a></li><li><a class="is-flex is-mobile" href="#5-NFS"><span class="mr-2">2.4.10</span><span>5. NFS</span></a></li><li><a class="is-flex is-mobile" href="#1-4-11-Persistent-Volume"><span class="mr-2">2.4.11</span><span>1.4.11 Persistent Volume</span></a></li><li><a class="is-flex is-mobile" href="#Annotation-注解"><span class="mr-2">2.4.12</span><span>Annotation (注解)</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#第2章Kubernetes实践指南"><span class="mr-2">3</span><span>第2章Kubernetes实践指南</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#3-8-Pod健康检查和服务可用性检查"><span class="mr-2">3.1</span><span>3.8 Pod健康检查和服务可用性检查</span></a></li><li><a class="is-flex is-mobile" href="#3-9-pod-调度"><span class="mr-2">3.2</span><span>3.9 pod 调度</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#3-9-8-Job：批处理调度"><span class="mr-2">3.2.1</span><span>3.9.8 Job：批处理调度</span></a></li><li><a class="is-flex is-mobile" href="#3-9-9-Cronjob：定时任务"><span class="mr-2">3.2.2</span><span>3.9.9 Cronjob：定时任务</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#第4章-深入掌握Service"><span class="mr-2">4</span><span>第4章 深入掌握Service</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-1-Service定义详解"><span class="mr-2">4.1</span><span>4.1 Service定义详解</span></a></li><li><a class="is-flex is-mobile" href="#4-2-Service的基本用法"><span class="mr-2">4.2</span><span>4.2 Service的基本用法</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-2-0负载分发策略"><span class="mr-2">4.2.1</span><span>4.2.0负载分发策略</span></a></li><li><a class="is-flex is-mobile" href="#4-2-1-多端口Service"><span class="mr-2">4.2.2</span><span>4.2.1 多端口Service</span></a></li><li><a class="is-flex is-mobile" href="#4-2-2-外部服务Service"><span class="mr-2">4.2.3</span><span>4.2.2 外部服务Service</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-3-Headless-Service"><span class="mr-2">4.3</span><span>4.3 Headless Service</span></a></li><li><a class="is-flex is-mobile" href="#4-4-从集群外部访问Pod或Service-服务的发布"><span class="mr-2">4.4</span><span>4.4 从集群外部访问Pod或Service(服务的发布)</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-4-1-将容器应用的端口号映射到物理机"><span class="mr-2">4.4.1</span><span>4.4.1 将容器应用的端口号映射到物理机</span></a></li><li><a class="is-flex is-mobile" href="#4-4-2-将Service的端口号映射到物理机"><span class="mr-2">4.4.2</span><span>4.4.2 将Service的端口号映射到物理机</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-5-DNS服务搭建和配置指南"><span class="mr-2">4.5</span><span>4.5 DNS服务搭建和配置指南</span></a></li><li><a class="is-flex is-mobile" href="#4-6-Ingress：HTTP-7层路由机制"><span class="mr-2">4.6</span><span>4.6 Ingress：HTTP 7层路由机制</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-6-1-创建Ingress-Controller和默认的backend服务"><span class="mr-2">4.6.1</span><span>4.6.1 创建Ingress Controller和默认的backend服务</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#第3章Kubernetes核心原理"><span class="mr-2">5</span><span>第3章Kubernetes核心原理</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#3-1-Kubernetes-API-Server原理分析"><span class="mr-2">5.1</span><span>3.1 Kubernetes API Server原理分析</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#node"><span class="mr-2">5.1.1</span><span>node</span></a></li><li><a class="is-flex is-mobile" href="#3-1-2-独特的Kubernetes-Proxy-API接口"><span class="mr-2">5.1.2</span><span>3.1.2 独特的Kubernetes Proxy API接口</span></a></li><li><a class="is-flex is-mobile" href="#交互场景"><span class="mr-2">5.1.3</span><span>交互场景:</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#3-2-Controller-Manager-原理分析"><span class="mr-2">5.2</span><span>3.2 Controller Manager 原理分析</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#使用场景"><span class="mr-2">5.2.1</span><span>使用场景</span></a></li><li><a class="is-flex is-mobile" href="#3-2-2-Node-Controller"><span class="mr-2">5.2.2</span><span>3.2.2 Node Controller</span></a></li><li><a class="is-flex is-mobile" href="#Kubernetes支持资源配额管理。"><span class="mr-2">5.2.3</span><span>Kubernetes支持资源配额管理。</span></a></li><li><a class="is-flex is-mobile" href="#3-2-4-Namespace-Controller"><span class="mr-2">5.2.4</span><span>3.2.4 Namespace Controller</span></a></li><li><a class="is-flex is-mobile" href="#3-2-5-Service-Controller与Endpoint-Controller"><span class="mr-2">5.2.5</span><span>3.2.5 Service Controller与Endpoint Controller</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#5-4-kubelet运行机制解析"><span class="mr-2">5.3</span><span> 5.4 kubelet运行机制解析</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#5-4-1-节点管理"><span class="mr-2">5.3.1</span><span>5.4.1 节点管理</span></a></li><li><a class="is-flex is-mobile" href="#5-4-2-Pod管理"><span class="mr-2">5.3.2</span><span>5.4.2 Pod管理</span></a></li><li><a class="is-flex is-mobile" href="#ReadinessProbe探针"><span class="mr-2">5.3.3</span><span>ReadinessProbe探针</span></a></li><li><a class="is-flex is-mobile" href="#资源监控"><span class="mr-2">5.3.4</span><span>资源监控</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#第6章-深入分析集群安全机制"><span class="mr-2">6</span><span>第6章 深入分析集群安全机制</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#6-1-API-Server认证管理"><span class="mr-2">6.1</span><span>6.1 API Server认证管理</span></a></li><li><a class="is-flex is-mobile" href="#6-2-API-Server授权管理"><span class="mr-2">6.2</span><span>6.2 API Server授权管理</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#RBAC的API资源对象说明"><span class="mr-2">6.2.1</span><span>RBAC的API资源对象说明</span></a></li><li><a class="is-flex is-mobile" href="#6-4-Service-Account"><span class="mr-2">6.2.2</span><span>6.4 Service Account</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#第七章-网络原理"><span class="mr-2">7</span><span>第七章 网络原理</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-1-Kubernetes网络模型"><span class="mr-2">7.1</span><span>7.1 Kubernetes网络模型</span></a></li><li><a class="is-flex is-mobile" href="#7-7-Kubernetes网络策略"><span class="mr-2">7.2</span><span>7.7 Kubernetes网络策略</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-7-1-网络策略配置说明"><span class="mr-2">7.2.1</span><span>7.7.1 网络策略配置说明</span></a></li><li><a class="is-flex is-mobile" href="#7-7-2在Namespace级别设置默认的网络策略"><span class="mr-2">7.2.2</span><span>7.7.2在Namespace级别设置默认的网络策略</span></a></li><li><a class="is-flex is-mobile" href="#默认拒绝所有入口和所有出站流量"><span class="mr-2">7.2.3</span><span>默认拒绝所有入口和所有出站流量</span></a></li><li><a class="is-flex is-mobile" href="#7-7-3-NetworkPolicy的发展"><span class="mr-2">7.2.4</span><span>7.7.3 NetworkPolicy的发展</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10-12-Helm：Kubernetes应用包管理工具"><span class="mr-2">7.3</span><span>10.12 Helm：Kubernetes应用包管理工具</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#10-12-1-Helm概述"><span class="mr-2">7.3.1</span><span>10.12.1 Helm概述</span></a></li><li><a class="is-flex is-mobile" href="#10-12-2-Helm的主要概念"><span class="mr-2">7.3.2</span><span>10.12.2 Helm的主要概念</span></a></li><li><a class="is-flex is-mobile" href="#10-12-4-Helm的常见用法"><span class="mr-2">7.3.3</span><span>10.12.4 Helm的常见用法</span></a></li><li><a class="is-flex is-mobile" href="#11-5-寻求帮助"><span class="mr-2">7.3.4</span><span>11.5 寻求帮助</span></a></li></ul></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class=""><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7.jpg" alt="山河已无恙"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">山河已无恙</p><p class="is-size-6 is-block">爱自己，是终生浪漫的开始</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国·呼和浩特</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">442</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">144</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">191</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://mp.weixin.qq.com/s?__biz=MzkyNjIxNTYwMw==&amp;mid=2247496480&amp;idx=1&amp;sn=a9971fed3962ef2a1aeda1f0bda65f86&amp;chksm=c2380ffcf54f86eaba8daac6caca72a70f38e61a8d25dc2a66d3a17b87c02530e326dcaea14b#rd" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/LIRUILONGS"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="https://liruilong.blog.csdn.net/"><i class="fa fa-code"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:1224965096@qq.com"><i class="fa fa-envelope"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://liruilong.blog.csdn.net/?t=1&amp;type=blog" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">liruilong.blog.csdn.net</span></span></a></li><li><a class="level is-mobile" href="https://www.cnblogs.com/liruilong/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">博客园</span></span><span class="level-right"><span class="level-item tag">www.cnblogs.com</span></span></a></li><li><a class="level is-mobile" href="https://github.com/LIRUILONGS" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Githup</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://gitee.com/liruilonger" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">码云</span></span><span class="level-right"><span class="level-item tag">gitee.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-12T11:03:27.000Z">2025-05-12</time></p><p class="title"><a href="/2025/05/12/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%85%BE%E8%AE%AFAI%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E4%BC%99%E4%BC%B4-CodeBuddy-%E5%B0%9D%E9%B2%9C%EF%BC%8C%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86%E4%B8%AD%E5%9B%BD%E7%89%88-Cursor/">腾讯云代码助手 CodeBuddy 尝鲜，带你认识中国版 Cursor</a></p><p class="categories"><a href="/categories/test3/">test3</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-17T23:32:10.000Z">2025-04-18</time></p><p class="title"><a href="/2025/04/18/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%AE%A4%E8%AF%86%20Linux%20%E5%86%85%E5%AD%98%E6%9E%84%E6%88%90%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E9%A1%B5%E8%A1%A8%E3%80%81TLB%E3%80%81%E5%A4%A7%E9%A1%B5%E8%AE%A4%E7%9F%A5/">认识 Linux 内存构成：Linux 内存调优之页表、TLB、缺页异常、大页认知</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-13T14:50:54.000Z">2025-04-13</time></p><p class="title"><a href="/2025/04/13/%E5%BE%85%E5%8F%91%E5%B8%83/%E8%B0%B7%E6%AD%8C68%E9%A1%B5%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E5%AF%86%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%A6%82%E4%BD%95%E9%87%8D%E5%A1%91AI%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91/">谷歌68页白皮书解密：提示工程如何重塑AI交互逻辑</a></p><p class="categories"><a href="/categories/LLM/">LLM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-11T11:38:12.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%E5%BE%85%E5%8F%91%E5%B8%83/Linux%20%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%EF%BC%9ALinux%20%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E5%85%A8%E9%9D%A2%E7%9B%91%E6%8E%A7/">Linux 系统内存监控：Linux 内存调优之系统内存全面监控</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-11T11:38:12.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%E5%BE%85%E5%8F%91%E5%B8%83/Linux-%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%EF%BC%9ALinux-%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98%E4%B9%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E6%B7%B1%E5%BA%A6%E7%9B%91%E6%8E%A7/">Linux 进程内存监控：Linux 内存调优之进程内存深度监控</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AdaFace/"><span class="level-start"><span class="level-item">AdaFace</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ajax/"><span class="level-start"><span class="level-item">Ajax</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ansible/"><span class="level-start"><span class="level-item">Ansible</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/AppCube/"><span class="level-start"><span class="level-item">AppCube</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/BPF/"><span class="level-start"><span class="level-item">BPF</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Bind9/"><span class="level-start"><span class="level-item">Bind9</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CI-CD/"><span class="level-start"><span class="level-item">CI/CD</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Ceph/"><span class="level-start"><span class="level-item">Ceph</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Kubernetes/"><span class="tag">Kubernetes</span><span class="tag is-grey-lightest">98</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag is-grey-lightest">57</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ansible/"><span class="tag">Ansible</span><span class="tag is-grey-lightest">25</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ceph/"><span class="tag">Ceph</span><span class="tag is-grey-lightest">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JAVA/"><span class="tag">JAVA</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%8E%E4%B8%BA%E4%BA%91/"><span class="tag">华为云</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BPF/"><span class="tag">BPF</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mysql/"><span class="tag">Mysql</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenShift/"><span class="tag">OpenShift</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"><span class="tag">程序人生</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNS/"><span class="tag">DNS</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OKD/"><span class="tag">OKD</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%91%84%E5%BD%B1%E6%9B%9D%E5%85%89/"><span class="tag">摄影曝光</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/selenium/"><span class="tag">selenium</span><span class="tag is-grey-lightest">4</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="山河已无恙" height="28"></a><p class="size-small"><span>&copy; 2025 山河已无恙</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© <a href="http://www.beian.miit.gov.cn/" target="_blank">备案中</a><br></span><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2021/6/26 21:27:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('9fdc9739266d48d5f62e','c1cc33697d099a2197650ec9dadcb16bd4904655','LIRUILONGS','blog_comment',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>